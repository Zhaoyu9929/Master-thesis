{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import gurobipy as gp\n",
    "import os \n",
    "from gurobipy import Model, GRB, quicksum, read\n",
    "import nbformat\n",
    "import nbimporter\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import glob\n",
    "from scipy.sparse import coo_matrix\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we count the number of trips of each day\n",
    "\"\"\"\n",
    "for df_key in dfs.keys():\n",
    "    dfs[df_key]['tpep_pickup_datetime'] = pd.to_datetime(dfs[df_key]['tpep_pickup_datetime'], errors='coerce')\n",
    "    dfs[df_key] = dfs[df_key][dfs[df_key]['tpep_pickup_datetime'].dt.year == 2019]\n",
    "\n",
    "daily_trips = pd.Series(dtype=int)\n",
    "\n",
    "for df_key in dfs.keys():\n",
    "\n",
    "    daily_counts = dfs[df_key]['tpep_pickup_datetime'].dt.date.value_counts()\n",
    "    \n",
    "    daily_trips = daily_trips.add(daily_counts, fill_value=0)\n",
    "\n",
    "daily_trips.index = pd.to_datetime(daily_trips.index)\n",
    "\n",
    "daily_trips = daily_trips.sort_index()\n",
    "\n",
    "daily_trips = daily_trips[(daily_trips.index.year == 2019)]\n",
    "\n",
    "df_total_demand = pd.DataFrame({\n",
    "    'date': daily_trips.index,\n",
    "    'count': daily_trips.values\n",
    "})\n",
    "df_total_demand\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_demand = pd.read_csv('df_total_demand')\n",
    "df_total_demand = df_total_demand.drop(columns=['Unnamed: 0'])\n",
    "df_total_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import poisson, norm\n",
    "\n",
    "sns.histplot(df_total_demand['count'], bins=30, kde=True)\n",
    "plt.title('Histogram of Daily Trips Count')\n",
    "plt.show()\n",
    "\n",
    "mean_count = df_total_demand['count'].mean()\n",
    "var_count = df_total_demand['count'].var()\n",
    "\n",
    "print(f\"Mean: {mean_count}, Variance: {var_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import poisson\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lambda_val = mean_count\n",
    "\n",
    "# Calculate the range, which is approximately with three standard deviations of the mean\n",
    "k_values = np.arange(0, lambda_val * 2) \n",
    "\n",
    "poisson_probs = poisson.pmf(k_values, lambda_val)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.stem(k_values, poisson_probs, linefmt='-', markerfmt='o', basefmt='-')\n",
    "plt.title('Poisson Distribution PDF around Mean')\n",
    "plt.xlabel('Number of Trips (k)')\n",
    "plt.ylabel('Probability')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_counts = [175307, 180186, 202321, 206626, 197662, 182641, 142560]\n",
    "\n",
    "poisson_probs = {k: poisson.pmf(k, lambda_val) for k in trip_counts}\n",
    "\n",
    "poisson_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s = {0: 0.1, 1: 0.1, 2: 0.1, 3: 0.1, 4: 0.2, 5: 0.2, 6: 0.2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2019-6.3_6.9.csv')\n",
    "df['starting_time'] = pd.to_datetime(df['starting_time'])\n",
    "\n",
    "dates = ['2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09']\n",
    "dfs = {}\n",
    "for i, date in enumerate(dates):\n",
    "    dfs[i] = df[df['starting_time'].dt.date == pd.to_datetime(date).date()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of scenarios\n",
    "S = range(7)\n",
    "\n",
    "# number of trips\n",
    "K = range(len(df))\n",
    "\n",
    "# number of poential charging staion locations\n",
    "I = range(65)\n",
    "\n",
    "# number of cars \n",
    "H = range(50)\n",
    "\n",
    "# Time periods from 0h to 23h\n",
    "T = range(24)\n",
    "\n",
    "# fixed cost of each charging station, here we assmue 150000 dollars, but here because we only use 10000 cars, so we need reduce the cost\n",
    "station_cost = 150000\n",
    "\n",
    "# Purchasing cost of each car\n",
    "car_cost = 15000 # Here we use 15000 dollars\n",
    "\n",
    "# Income of each accepted trip\n",
    "income_per_car = 50000 # assume here is 50 dollars\n",
    "\n",
    "# Capacity of each charging station, i.e. number of charging slots can be built at each charging station\n",
    "capacity = 5\n",
    "\n",
    "# Assuming i_k is a dictionary or a function that provides income for each trip k in scenario s ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanzh\\AppData\\Local\\Temp\\ipykernel_35296\\889573524.py:22: FutureWarning: The `precision` parameter is deprecated and will be removed in the v2.0.0 release.\n",
      "  G = ox.add_edge_travel_times(G, precision=1)\n"
     ]
    }
   ],
   "source": [
    "# Import Manhattan network and change node labels to integers\n",
    "G = ox.graph_from_place('Manhattan, New York, USA', network_type='drive')\n",
    "\n",
    "# If a node cannot access at least 10% of other nodes, delete it (isolated points are not considered)\n",
    "remove_list = []\n",
    "num_nodes = len(G.nodes)\n",
    "for node in G.nodes:  \n",
    "    reach = len(nx.descendants(G, node))\n",
    "    if reach < num_nodes / 10:\n",
    "        remove_list.append(node)\n",
    "\n",
    "for node in remove_list:\n",
    "    G.remove_node(node)\n",
    "\n",
    "# The node labels of the graph are converted to integers for easier handling and reference, \n",
    "G = nx.convert_node_labels_to_integers(G, label_attribute='old_node_ID')\n",
    "G = ox.add_edge_speeds(G)\n",
    "\n",
    "speed_df_path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\archive\\nyc_avg_speeds_2019-06.csv\"\n",
    "speed_df = pd.read_csv(speed_df_path)\n",
    "speed_df = speed_df[['osm_way_id', 'hour', 'speed']]\n",
    "G = ox.add_edge_travel_times(G, precision=1)\n",
    "\n",
    "\n",
    "# Load the graphs data with speed in the file\n",
    "def load_graph_from_pkl(file_path):\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "# The graphs holds a list of graph objects for each hour, here is 24 hour\n",
    "graphs = load_graph_from_pkl(\"graphs_list.pkl\")\n",
    "\n",
    "def process_graphs(graphs):\n",
    "    # Verify if each graph is an instance of MultiGraph\n",
    "    for hour, graph in enumerate(graphs):\n",
    "        if isinstance(graph, nx.MultiGraph):\n",
    "            update_graph_edges(graph, hour)\n",
    "        else:\n",
    "            print(f\"Graph for hour {hour} is not a MultiGraph.\")\n",
    "\n",
    "def update_graph_edges(graph, hour):\n",
    "    travel_time_key = f'travel_time_hour_{hour}'\n",
    "    for u, v, key, data in graph.edges(keys=True, data=True):\n",
    "        if travel_time_key not in data:\n",
    "            # Safely access the travel time in a multigraph structure\n",
    "            freeflow_travel_time = graph[u][v][key].get('travel_time', None)\n",
    "            if freeflow_travel_time is not None:\n",
    "                graph[u][v][key][travel_time_key] = freeflow_travel_time\n",
    "\n",
    "process_graphs(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the travel time function using Dijkstra algorithm\n",
    "def travel_time_func(G_hour, point1, point2, hour):\n",
    "    # Define the weight key for the specific hour\n",
    "    weight_key = f'travel_time_hour_{hour}'\n",
    "\n",
    "    # Use Dijkstra's algorithm to find the shortest path length and path\n",
    "    # This function returns both the length of the path and the actual path as a list of nodes\n",
    "    travel_time, path = nx.single_source_dijkstra(G_hour, source=point1, target=point2, weight=weight_key)\n",
    "\n",
    "    # Round the travel time to 2 decimal places\n",
    "    travel_time = round(travel_time, 4)\n",
    "\n",
    "    return travel_time, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-expanded location graphs  G=(V, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nodes in the graph\n",
    "root = 'root'\n",
    "sink = 'sink'\n",
    "\n",
    "# Use numpy to create the 3-d array \n",
    "grid = np.array(np.meshgrid(range(6), range(65), range(24), indexing='ij'))\n",
    "grid_shape = grid.shape[1:]\n",
    "\n",
    "# Convert it to tuple like (s, i, t)\n",
    "V_grid = grid.reshape(3, -1).T\n",
    "V_tuples = [tuple(x) for x in V_grid]\n",
    "\n",
    "# Then add root and sink to node list\n",
    "V = ['root'] + V_tuples + ['sink']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waiting list\n",
    "\n",
    "waiting_arcs = [(s, (i, t), (i, t+1)) for s, i, t in product(range(7), range(65), range(23))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# travel arcs\n",
    "\n",
    "travel_arcs = []\n",
    "\n",
    "# Read the csv file of coordinatate of charging station\n",
    "df_charging_station_location = pd.read_csv('coordinates of charging station.csv')\n",
    "location_id_to_index = df_charging_station_location.set_index('Location_id')['index'].to_dict()\n",
    "\n",
    "df['starting_point'] = df['origin_ID'].map(location_id_to_index)\n",
    "df['ending_point'] = df['destination_ID'].map(location_id_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for s in S:\n",
    "    for k in range(len(dfs[s])):\n",
    "\n",
    "        # Select the specific row\n",
    "        row = dfs[s].iloc[k]\n",
    "        \n",
    "        \n",
    "        # change the starting point id to index (from 0 to 65)\n",
    "        starting_point_id = row['origin_ID']\n",
    "        if starting_point_id in location_id_to_index:\n",
    "            starting_point = location_id_to_index[starting_point_id]\n",
    "\n",
    "        # Convert time to hour    \n",
    "        starting_time = row['hour']\n",
    "        \n",
    "        # Change the destination point id to index (from 0 to 65)\n",
    "        ending_point_id = row['destination_ID']\n",
    "        if ending_point_id in location_id_to_index:\n",
    "            ending_point = location_id_to_index[ending_point_id]\n",
    "\n",
    "        arcs = (s, k, (starting_point, ending_point, starting_time))\n",
    "        travel_arcs.append(arcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial allocation arcs\n",
    "initial_allocation_arcs = [(s, root, (i, 0)) for s in range(7) for i in range(65) ]\n",
    "\n",
    "final_collection_arcs = [(s, (i, 23), sink) for s in range(7) for i in range(65) ]\n",
    "\n",
    "# Define arcs excluding travel arcs\n",
    "arcs_exclduing_travel_arcs = waiting_arcs + initial_allocation_arcs + final_collection_arcs\n",
    "\n",
    "all_arcs = initial_allocation_arcs + waiting_arcs + travel_arcs + final_collection_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Max\\ \\sum_{s\\in S}p_s r \\sum_{k\\in K^s}{ x_k\\ -\\ f \\sum_{i\\in I}{y_i-c\\sum_{i\\in I}L_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First stage variable (Strategical layer)\n",
    "$$\n",
    "y_i=1 \\ \\text{if the charging station is built at $i$ point}, \\forall i \\in I\n",
    "$$\n",
    "$$\n",
    "L_i= \\ \\text{initial number of EVs at station i}, \\forall i \\in I\n",
    "$$\n",
    "\n",
    "Second stage variable(Operational layer)\n",
    "$$\n",
    "x_k=1 \\ \\text{if the $k$ trip is accepted}, k \\in K^s, \\forall s\\in S\n",
    "$$\n",
    "$$\n",
    "x_k^h = 1 \\ \\text{if and only if an accepted trip $k$ of scenario $s$ will be realized by purchased car $h$}\n",
    "$$\n",
    "$$\n",
    "f_a^h = 1 \\ \\text{if the car $h$ travels from station $i$ at time $t$ to station $j$ at time $t^{\\prime}$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# x_hk\u001b[39;00m\n\u001b[0;32m     14\u001b[0m indices_xhk \u001b[38;5;241m=\u001b[39m [(i, k, h) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dfs)) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dfs[i])) \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m30\u001b[39m)]\n\u001b[1;32m---> 15\u001b[0m x_hk \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddVars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_xhk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGRB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBINARY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrealized_by_car\u001b[39;49m\u001b[38;5;132;43;01m{i}\u001b[39;49;00m\u001b[38;5;132;43;01m{k}\u001b[39;49;00m\u001b[38;5;132;43;01m{h}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# flow variable in the second stage\u001b[39;00m\n\u001b[0;32m     18\u001b[0m f_ha \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39maddVars(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_arcs)), vtype\u001b[38;5;241m=\u001b[39mGRB\u001b[38;5;241m.\u001b[39mBINARY, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflow\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\model.pxi:3065\u001b[0m, in \u001b[0;36mgurobipy.Model.addVars\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\attrutil.pxi:26\u001b[0m, in \u001b[0;36mgurobipy._getattrinfo\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "m = Model('CSLP')\n",
    "\n",
    "# First stage decision variable\n",
    "y_i = m.addVars(range(65), vtype=GRB.BINARY, name='build_variable')\n",
    "L_i = m.addVars(range(65), vtype=GRB.INTEGER, name='purchased_car', lb=0, ub=5)\n",
    "\n",
    "# x_k\n",
    "indices_xk = [(i, k) for i in range(len(dfs)) for k in range(len(dfs[i]))]\n",
    "\n",
    "x_k = m.addVars(indices_xk, vtype=GRB.BINARY, name=\"accpted_trip_{s}_{k}\")\n",
    "\n",
    "# x_hk\n",
    "indices_xhk = [(i, k, h) for i in range(len(dfs)) for k in range(len(dfs[i])) for h in range(30)]\n",
    "x_hk = m.addVars(indices_xhk, vtype=GRB.BINARY, name='realized_by_car{i}{k}{h}')\n",
    "\n",
    "# flow variable in the second stage\n",
    "f_ha = m.addVars(range(len(all_arcs)), vtype=GRB.BINARY, name='flow') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function: maximize profit\n",
    "total_income = quicksum(p_s[s] * income_per_car * x_k[(s, k)] for s in S for k in range(len(dfs[s])))\n",
    "\n",
    "total_station_cost = station_cost * quicksum(y_i[i] for i in range(65))\n",
    "\n",
    "total_car_cost = car_cost * quicksum(L_i[i] for i in range(65))\n",
    "\n",
    "m.setObjective(total_income - total_station_cost - total_car_cost, GRB.MAXIMIZE)\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some mandatory requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least 5 stations should be built\n",
    "m.addConstr(quicksum(y_i[i] for i in I) >= 3, name=\"at_least_five_stations\")\n",
    "\n",
    "# Total number of cars should be fixed as 50 cars\n",
    "m.addConstr(quicksum(L_i[i] for i in I) >= 30, name='total_number_of_cars')\n",
    "\n",
    "# If the station is built in i, L_[i] should more than 0.\n",
    "for i in I:\n",
    "    m.addConstr(L_i[i] >= 1 - 1000 * (1 - y_i[i]), name=f'min_cars_if_station_{i}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constarints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraint 1\n",
    "$$\\sum_{i\\in I}{f_i y_i - c\\sum_{i\\in I} L_i} \\leq W$$\n",
    "\n",
    "This is the budget constraint, $W$ is the limited budget for all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Budget constraints\n",
    "budget = 10000000\n",
    "m.addConstr(station_cost * quicksum(y_i[i] for i in range(65)) + \n",
    "            car_cost * quicksum(L_i[i] for i in range(65)) <= budget, \n",
    "            name='budge_constraint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 2\n",
    "\n",
    "$$0< t^s_k x_k \\leq T^{max}\\qquad\\forall s \\in S, k \\in K^s$$\n",
    "\n",
    "The travel time of the $k$ trip should not exceed the maximum travel time of the car due to battery limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m destination_id \u001b[38;5;129;01min\u001b[39;00m location_id_to_networkx_point:\n\u001b[0;32m     23\u001b[0m     destination \u001b[38;5;241m=\u001b[39m location_id_to_networkx_point[destination_id]\n\u001b[1;32m---> 25\u001b[0m hour \u001b[38;5;241m=\u001b[39m \u001b[43mdfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstarting_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhour\u001b[49m\u001b[38;5;241m.\u001b[39miloc[k]\n\u001b[0;32m     26\u001b[0m G_hour \u001b[38;5;241m=\u001b[39m graphs[hour]\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#Calculate travel time for this trip\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\accessor.py:96\u001b[0m, in \u001b[0;36mPandasDelegate._add_delegate_accessors.<locals>._create_delegator_property.<locals>._getter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getter\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_delegate_property_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\accessors.py:93\u001b[0m, in \u001b[0;36mProperties._delegate_property_get\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Series\n\u001b[0;32m     91\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_values()\n\u001b[1;32m---> 93\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(values, name)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# maybe need to upcast (ints)\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mndarray):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\extension.py:68\u001b[0m, in \u001b[0;36m_inherit_from_data.<locals>.fget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfget\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 68\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, name)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arrays\\datetimes.py:152\u001b[0m, in \u001b[0;36m_field_accessor.<locals>.f\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    149\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_mask_results(result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfields\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_date_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_creso\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_mask_results(\n\u001b[0;32m    154\u001b[0m         result, fill_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    155\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Battery limitation\n",
    "\n",
    "# The maximum operational time is 60 minutes\n",
    "T_max = 60 \n",
    "\n",
    "# Create a mapping from Location id to networkx point, here I create a dictionary\n",
    "location_id_to_networkx_point = df_charging_station_location.set_index('Location_id')['networkx_point'].to_dict()\n",
    "\n",
    "for s in S:\n",
    "    for k in range(len(dfs[s])):\n",
    "\n",
    "        # Get the orgin_id value right now\n",
    "        origin_id = dfs[s]['origin_ID'].iloc[k]\n",
    "        \n",
    "\n",
    "        if origin_id in location_id_to_networkx_point:\n",
    "            origin = location_id_to_networkx_point[origin_id]\n",
    "        \n",
    "        # Get the destination_id value right now\n",
    "        destination_id = dfs[s]['destination_ID'].iloc[k]\n",
    "        \n",
    "        if destination_id in location_id_to_networkx_point:\n",
    "            destination = location_id_to_networkx_point[destination_id]\n",
    "\n",
    "        hour = dfs[s]['starting_time'].dt.hour.iloc[k]\n",
    "        G_hour = graphs[hour]\n",
    "\n",
    "        #Calculate travel time for this trip\n",
    "        travel_time, _ = travel_time_func(G_hour, origin, destination, hour)\n",
    "\n",
    "        # # Check for NaN or Inf values\n",
    "        # if np.isnan(travel_time) or np.isinf(travel_time):\n",
    "        #     print(f\"Invalid travel time detected: Scenario {s}, Trip {k}, Origin {origin}, Destination {destination}, Hour {hour}, Travel Time {travel_time}\")\n",
    "        #     continue\n",
    "\n",
    "        # Only apply the constraint if the trip is accepted\n",
    "        m.addConstr(travel_time * x_k[s, k] <= T_max, name=f\"Battery limitation_s{s}_k{k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 3\n",
    "\n",
    "$$\\sum_{h=1}^H x_k^h = x_k, \\qquad\\forall s \\in S, k \\in K^s $$\n",
    "\n",
    "It ensures that exactly one car is assigned to each accepted trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m S:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m)):\n\u001b[0;32m      3\u001b[0m         m\u001b[38;5;241m.\u001b[39maddConstr(quicksum(x_hk[s, k, h] \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m H) \u001b[38;5;241m==\u001b[39m x_k[s, k], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone_car_per_accepted_trip_s\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for s in S:\n",
    "    for k in range(len(df[s])):\n",
    "        m.addConstr(quicksum(x_hk[s, k, h] for h in H) == x_k[s, k], name=f\"one_car_per_accepted_trip_s{s}_k{k}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrain 4\n",
    "\n",
    "$$\\sum_{h=1}^H \\sum_{a \\in \\delta^{+}\\left(i_t\\right) \\cap\\left(A_W^s \\cup A_C^s\\right)} f_a^h \\leq C_i y_i \\qquad \\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that the quantity of vehicles concurrently parked at station $i$ does not surpass the available number of charging slots at said station.\n",
    "Observe that final collection arcs need to be considered on the left-hand side to ensure that the capacity constraints are also met at the end of the planning period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity constraints\n",
    "\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        # Directly handling the final collection arcs to 'sink' \n",
    "        final_arc_key = (s, (i, 23), 'sink')\n",
    "        m.addConstr(quicksum(f_ha[s, h, final_arc_key] for h in H if final_arc_key in f_ha) <= capacity * y_i[i], name=f'final_capacity_s{s}_i{i}')\n",
    "        \n",
    "        for t in T:         \n",
    "            # Filter and append arcs relevant to the current (s, i, t)\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "        \n",
    "            # Add constraint            \n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in outgoing_waiting_arcs if arc in f_ha) <= capacity * y_i[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 5\n",
    "\n",
    "$$    f^h[\\delta^{-}\\left(i_t\\right)] \\leq y_i \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that car can only enter the built station. It includes waiting arcs (cars only car wait at the built station), and traveling arcs (cars can only park at the built station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 5\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific waiting arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_waiting_arcs if arc in f_ha) <= y_i[i])\n",
    "\n",
    "            # Next is travel arc\n",
    "\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_travel_arcs if arc in f_ha) <= y_i[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 6\n",
    "\n",
    "$$f^h\\left[\\delta^{-}\\left(i_t\\right)\\right]=f^h\\left[\\delta^{+}\\left(i_t\\right)\\right] \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad\\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "Flow conservation ensures that the route of each car must correspond to a path through the time-expanded location graph for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific incoming  arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_arcs = incoming_travel_arcs + incoming_waiting_arcs\n",
    "\n",
    "            # Given s, i, t, a specific outgoing  arc can be identified\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_arcs = outgoing_travel_arcs + outgoing_waiting_arcs\n",
    "\n",
    "            for h in H:\n",
    "                # Add constraints\n",
    "                m.addConstr(\n",
    "                    quicksum(f_ha[s, h, arc] for arc in incoming_arcs if arc in f_ha) ==\n",
    "                    quicksum(f_ha[s, h, arc] for arc in outgoing_arcs if arc in f_ha),\n",
    "                    name=f\"flow_conservation_s{s}_i{i}_t{t}_h{h}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 7 \n",
    "\n",
    "$$\\sum_{a \\in A_{T}^s(k)} f_a^h=x_k^h \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall k \\in K^s$$\n",
    "\n",
    "This equation illustrates all action of one car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute travel arcs for each scenario and trip\n",
    "travel_arcs_per_scenario_trip = {\n",
    "    (s, k): [arc for arc in travel_arcs if arc[0] == s and arc[1] == k]\n",
    "    for s in S\n",
    "    for k in range(len(dfs[s]))\n",
    "}\n",
    "\n",
    "# Now add constraints using the precomputed arcs\n",
    "for s in S:\n",
    "    for k in range(len(dfs[s])):\n",
    "        for h in H:\n",
    "            relevant_arcs = travel_arcs_per_scenario_trip[(s, k)]\n",
    "            sum_f_ha_for_travel_arcs = quicksum(f_ha[arc] for arc in relevant_arcs)\n",
    "            m.addConstr(sum_f_ha_for_travel_arcs == x_hk[s, h, k], name=f'all_action_one_car_s{s}_h{h}_k{k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (win64 - Windows 11+.0 (22631.2))\n",
      "\n",
      "CPU model: AMD Ryzen 9 7945HX with Radeon Graphics, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 16 physical cores, 32 logical processors, using up to 32 threads\n",
      "\n",
      "Optimize a model with 87234 rows, 41205201 columns and 87556 nonzeros\n",
      "Model fingerprint: 0x9ecde2e7\n",
      "Variable types: 0 continuous, 41205201 integer (41205136 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 2e+05]\n",
      "  Objective range  [5e+03, 2e+05]\n",
      "  Bounds range     [1e+00, 5e+00]\n",
      "  RHS range        [5e+00, 1e+07]\n",
      "Found heuristic solution: objective 9.049275e+09\n",
      "Presolve removed 0 rows and 41129280 columns (presolve time = 5s) ...\n",
      "Presolve removed 87166 rows and 41205071 columns\n",
      "Presolve time: 5.76s\n",
      "Presolved: 68 rows, 130 columns, 390 nonzeros\n",
      "Variable types: 0 continuous, 130 integer (65 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    9.0504750e+09   3.500000e+01   0.000000e+00     10s\n",
      "\n",
      "Root relaxation: interrupted, 0 iterations, 0.01 seconds (0.00 work units)\n",
      "\n",
      "Explored 1 nodes (0 simplex iterations) in 11.48 seconds (2.74 work units)\n",
      "Thread count was 32 (of 32 available processors)\n",
      "\n",
      "Solution count 1: 9.04928e+09 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 9.049275000000e+09, best bound 9.049725000000e+09, gap 0.0050%\n",
      "Optimization was successful. Printing results.\n",
      "Build a charging station at location 13 with 5.0 cars.\n",
      "Build a charging station at location 15 with 5.0 cars.\n",
      "Build a charging station at location 21 with 5.0 cars.\n",
      "Build a charging station at location 47 with 5.0 cars.\n",
      "Build a charging station at location 49 with 1.0 cars.\n"
     ]
    }
   ],
   "source": [
    "# Solve the model\n",
    "m.optimize()\n",
    "\n",
    "# Directly check the optimization status\n",
    "if m.Status == GRB.OPTIMAL:\n",
    "    print(\"Optimization was successful. Printing results.\")\n",
    "    for i in range(65):  # Ensure n_locations is correctly set\n",
    "        if y_i[i].X > 0.5:\n",
    "            print(f\"Build a charging station at location {i} with {L_i[i].X} cars.\")\n",
    "else:\n",
    "    print(f\"Optimization issue with status code: {m.Status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
