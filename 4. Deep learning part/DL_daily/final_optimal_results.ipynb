{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a04fcb5-c170-42a4-8a13-26e8b59234e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanzh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-07-24 22:59:29,669] A new study created in memory with name: no-name-199f5271-7d6d-4836-b275-1a590717136c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 12.065278995177325, Val Loss: 2.480046590169271\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 5.269897984336405, Val Loss: 2.2261175314585366\n",
      "Window 1 Epoch 10 Train Loss: 0.6877560768407934, Val Loss: 0.934281587600708\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.8935254843094769, Val Loss: 0.723098357518514\n",
      "Window 2 Epoch 10 Train Loss: 0.46331723393762814, Val Loss: 0.037375107407569885\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 2.495619516092188, Val Loss: 1.5685940583546956\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.4489800655140597, Val Loss: 1.5581790606180828\n",
      "Window 4 Epoch 10 Train Loss: 2.4384860171991236, Val Loss: -0.06716323395570119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 22:59:36,473] Trial 0 finished with value: 1.2189618023888518 and parameters: {'lstm_hidden_layer_size': 194, 'mlp_hidden_dim': 15, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 32, 'num_gaussians': 1, 'patience': 5}. Best is trial 0 with value: 1.2189618023888518.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.9503414030636057, Val Loss: 1.2465944290161133\n",
      "Window 0 Epoch 10 Train Loss: 1.098997402752147, Val Loss: 1.0691825151443481\n",
      "Window 0 Epoch 20 Train Loss: 0.7501350136364208, Val Loss: 0.9373474717140198\n",
      "Window 0 Epoch 30 Train Loss: 0.4957001479934244, Val Loss: 0.799892008304596\n",
      "Window 0 Epoch 40 Train Loss: 0.30504812955856325, Val Loss: 0.6557260155677795\n",
      "Window 1 Epoch 0 Train Loss: 1.2484888082392076, Val Loss: 1.106769323348999\n",
      "Window 1 Epoch 10 Train Loss: 0.8335961818695068, Val Loss: 0.9116769433021545\n",
      "Window 1 Epoch 20 Train Loss: 0.5078493763418759, Val Loss: 0.7132792472839355\n",
      "Window 1 Epoch 30 Train Loss: 0.34609751476961026, Val Loss: 0.5338785648345947\n",
      "Window 1 Epoch 40 Train Loss: 0.14171585524783414, Val Loss: 0.3429153859615326\n",
      "Window 2 Epoch 0 Train Loss: 1.267361093969906, Val Loss: 1.0805168151855469\n",
      "Window 2 Epoch 10 Train Loss: 0.7959210143369787, Val Loss: 0.9170886874198914\n",
      "Window 2 Epoch 20 Train Loss: 0.44462594551198625, Val Loss: 0.7487974166870117\n",
      "Window 2 Epoch 30 Train Loss: 0.12386815590016982, Val Loss: 0.5690751671791077\n",
      "Window 2 Epoch 40 Train Loss: -0.09164784326272853, Val Loss: 0.3720061779022217\n",
      "Window 3 Epoch 0 Train Loss: 1.121833146459916, Val Loss: 0.8994331955909729\n",
      "Window 3 Epoch 10 Train Loss: 0.7108610294846928, Val Loss: 0.7718291282653809\n",
      "Window 3 Epoch 20 Train Loss: 0.48845229387283323, Val Loss: 0.6594535708427429\n",
      "Window 3 Epoch 30 Train Loss: 0.3914453551348518, Val Loss: 0.5714607834815979\n",
      "Window 3 Epoch 40 Train Loss: 0.2566080428572262, Val Loss: 0.48126015067100525\n",
      "Window 4 Epoch 0 Train Loss: 1.7915257201475256, Val Loss: 1.211285948753357\n",
      "Window 4 Epoch 10 Train Loss: 1.1500023322946884, Val Loss: 1.040171504020691\n",
      "Window 4 Epoch 20 Train Loss: 0.6118877932604622, Val Loss: 0.8771037459373474\n",
      "Window 4 Epoch 30 Train Loss: 0.2710625418494729, Val Loss: 0.7080809473991394\n",
      "Window 4 Epoch 40 Train Loss: 0.12876902755569009, Val Loss: 0.5464017987251282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 22:59:45,400] Trial 1 finished with value: 0.8010420250892639 and parameters: {'lstm_hidden_layer_size': 106, 'mlp_hidden_dim': 18, 'learning_rate': 0.0001, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 10, 'patience': 8}. Best is trial 1 with value: 0.8010420250892639.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5684029713798973, Val Loss: 1.102925419807434\n",
      "Window 0 Epoch 10 Train Loss: 0.8772550390748417, Val Loss: -0.003983050584793091\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.7970916150597965, Val Loss: 0.8371140360832214\n",
      "Window 1 Epoch 10 Train Loss: 0.7121452335049124, Val Loss: 0.1737527996301651\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.9848991374408498, Val Loss: 0.8312876224517822\n",
      "Window 2 Epoch 10 Train Loss: -0.2613194480012445, Val Loss: -0.305441290140152\n",
      "Window 2 Epoch 20 Train Loss: -0.37228931013275596, Val Loss: -0.5517985224723816\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.7989952711498036, Val Loss: 0.6523415446281433\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.824554484872257, Val Loss: 0.7980413436889648\n",
      "Window 4 Epoch 10 Train Loss: 0.5815075766251367, Val Loss: -0.0352376364171505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 22:59:49,949] Trial 2 finished with value: -0.07837052771910316 and parameters: {'lstm_hidden_layer_size': 153, 'mlp_hidden_dim': 6, 'learning_rate': 0.001, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 5, 'patience': 4}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 20 Train Loss: 0.22670499030281516, Val Loss: -0.3805220127105713\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.6329100981880638, Val Loss: 1.4462239742279053\n",
      "Window 0 Epoch 10 Train Loss: 0.34482625764958996, Val Loss: -0.5323276917139689\n",
      "Window 0 Epoch 20 Train Loss: -0.6406082127374761, Val Loss: -0.9764108061790466\n",
      "Window 0 Epoch 30 Train Loss: -0.5714697666729198, Val Loss: -0.8575505415598551\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.415144317851347, Val Loss: 0.8290998339653015\n",
      "Window 1 Epoch 10 Train Loss: -0.17743979117449593, Val Loss: 0.874819835027059\n",
      "Window 1 Epoch 20 Train Loss: -0.6693309224353117, Val Loss: -0.7266515692075094\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.5895725881352145, Val Loss: 1.0702228148778279\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 2.2307464058258955, Val Loss: 1.8076543807983398\n",
      "Window 3 Epoch 10 Train Loss: -0.14533060242148008, Val Loss: 0.07478729387124379\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 6.065236244762645, Val Loss: 1.508938233057658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:00:00,259] Trial 3 finished with value: 0.6318716612403041 and parameters: {'lstm_hidden_layer_size': 157, 'mlp_hidden_dim': 20, 'learning_rate': 0.01, 'dropout': 0.25, 'batch_size': 32, 'num_gaussians': 9, 'patience': 4}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.0686458312763887, Val Loss: 1.366032600402832\n",
      "Window 0 Epoch 10 Train Loss: 1.0024470629411586, Val Loss: 1.0648996829986572\n",
      "Window 0 Epoch 20 Train Loss: 0.48241901839480683, Val Loss: 0.8357334733009338\n",
      "Window 0 Epoch 30 Train Loss: 0.23415237707250258, Val Loss: 0.42156222462654114\n",
      "Window 0 Epoch 40 Train Loss: -0.12743322270758012, Val Loss: -0.07081226259469986\n",
      "Window 1 Epoch 0 Train Loss: 1.5395548239876242, Val Loss: 1.2172473669052124\n",
      "Window 1 Epoch 10 Train Loss: 1.0682154927534215, Val Loss: 1.0558301210403442\n",
      "Window 1 Epoch 20 Train Loss: 0.6085350445438834, Val Loss: 0.816864013671875\n",
      "Window 1 Epoch 30 Train Loss: 0.05567958032383638, Val Loss: 0.4077487885951996\n",
      "Window 1 Epoch 40 Train Loss: -0.2935197887701147, Val Loss: -0.07921981066465378\n",
      "Window 2 Epoch 0 Train Loss: 1.271497870613547, Val Loss: 1.1318700313568115\n",
      "Window 2 Epoch 10 Train Loss: 0.7920136657883139, Val Loss: 1.0210438966751099\n",
      "Window 2 Epoch 20 Train Loss: 0.3813426234529299, Val Loss: 0.866349458694458\n",
      "Window 2 Epoch 30 Train Loss: 0.13514124670449426, Val Loss: 0.6648516654968262\n",
      "Window 2 Epoch 40 Train Loss: -0.09625623240190394, Val Loss: 0.35661038756370544\n",
      "Window 3 Epoch 0 Train Loss: 1.1306166037391214, Val Loss: 0.9466972351074219\n",
      "Window 3 Epoch 10 Train Loss: 0.6122085448573618, Val Loss: 0.7722897529602051\n",
      "Window 3 Epoch 20 Train Loss: 0.10897730247062795, Val Loss: 0.4826371669769287\n",
      "Window 3 Epoch 30 Train Loss: -0.31289502333192265, Val Loss: 0.13075672090053558\n",
      "Window 3 Epoch 40 Train Loss: -0.5649809485323289, Val Loss: -0.19649063050746918\n",
      "Window 4 Epoch 0 Train Loss: 1.1124920637467328, Val Loss: 1.0491005182266235\n",
      "Window 4 Epoch 10 Train Loss: 0.44269550740718844, Val Loss: 0.9091057181358337\n",
      "Window 4 Epoch 20 Train Loss: 0.19944800445262123, Val Loss: 0.7545623183250427\n",
      "Window 4 Epoch 30 Train Loss: 0.014233343706411473, Val Loss: 0.5600929260253906\n",
      "Window 4 Epoch 40 Train Loss: -0.1707444709890029, Val Loss: 0.3011573553085327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:00:03,949] Trial 4 finished with value: 0.6137099804356694 and parameters: {'lstm_hidden_layer_size': 20, 'mlp_hidden_dim': 9, 'learning_rate': 0.001, 'dropout': 0.1, 'batch_size': 256, 'num_gaussians': 8, 'patience': 5}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5329251275343054, Val Loss: 1.2195452451705933\n",
      "Window 0 Epoch 10 Train Loss: 1.5127894090203677, Val Loss: 1.2142384052276611\n",
      "Window 0 Epoch 20 Train Loss: 1.5067515785553875, Val Loss: 1.2089465856552124\n",
      "Window 0 Epoch 30 Train Loss: 1.491816697962144, Val Loss: 1.2037020921707153\n",
      "Window 0 Epoch 40 Train Loss: 1.4638715460721183, Val Loss: 1.1984838247299194\n",
      "Window 1 Epoch 0 Train Loss: 1.9700482867745792, Val Loss: 1.2570995092391968\n",
      "Window 1 Epoch 10 Train Loss: 1.947784764065462, Val Loss: 1.253692865371704\n",
      "Window 1 Epoch 20 Train Loss: 1.9472340701608097, Val Loss: 1.250235676765442\n",
      "Window 1 Epoch 30 Train Loss: 1.9105587594649371, Val Loss: 1.2467505931854248\n",
      "Window 1 Epoch 40 Train Loss: 1.904133567529566, Val Loss: 1.243221640586853\n",
      "Window 2 Epoch 0 Train Loss: 1.5976945703169878, Val Loss: 1.1247369050979614\n",
      "Window 2 Epoch 10 Train Loss: 1.566784727713641, Val Loss: 1.1188641786575317\n",
      "Window 2 Epoch 20 Train Loss: 1.52343901942758, Val Loss: 1.1130892038345337\n",
      "Window 2 Epoch 30 Train Loss: 1.48348197740667, Val Loss: 1.1073359251022339\n",
      "Window 2 Epoch 40 Train Loss: 1.4699216273251703, Val Loss: 1.1016602516174316\n",
      "Window 3 Epoch 0 Train Loss: 1.1050352922607871, Val Loss: 0.9655983448028564\n",
      "Window 3 Epoch 10 Train Loss: 1.0733662047105677, Val Loss: 0.9604628682136536\n",
      "Window 3 Epoch 20 Train Loss: 1.0294537826145396, Val Loss: 0.9553685784339905\n",
      "Window 3 Epoch 30 Train Loss: 1.0437625813484193, Val Loss: 0.9502688050270081\n",
      "Window 3 Epoch 40 Train Loss: 1.0071345623801737, Val Loss: 0.9451872706413269\n",
      "Window 4 Epoch 0 Train Loss: 1.4492572461857516, Val Loss: 1.019798755645752\n",
      "Window 4 Epoch 10 Train Loss: 1.4439433891632978, Val Loss: 1.016553521156311\n",
      "Window 4 Epoch 20 Train Loss: 1.4060146340201882, Val Loss: 1.0132896900177002\n",
      "Window 4 Epoch 30 Train Loss: 1.3981766557693482, Val Loss: 1.0100377798080444\n",
      "Window 4 Epoch 40 Train Loss: 1.3921227135377772, Val Loss: 1.0067936182022095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:00:20,490] Trial 5 finished with value: 1.0118296432495117 and parameters: {'lstm_hidden_layer_size': 198, 'mlp_hidden_dim': 18, 'learning_rate': 1e-06, 'dropout': 0.15, 'batch_size': 64, 'num_gaussians': 6, 'patience': 6}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.4510449647903443, Val Loss: 1.234369158744812\n",
      "Window 0 Epoch 10 Train Loss: 1.4273245435602524, Val Loss: 1.2323373556137085\n",
      "Window 0 Epoch 20 Train Loss: 1.4164158952937407, Val Loss: 1.2303537130355835\n",
      "Window 0 Epoch 30 Train Loss: 1.4041324952069452, Val Loss: 1.2283028364181519\n",
      "Window 0 Epoch 40 Train Loss: 1.4456828852260815, Val Loss: 1.2262181043624878\n",
      "Window 1 Epoch 0 Train Loss: 1.4649042412813973, Val Loss: 1.0534027814865112\n",
      "Window 1 Epoch 10 Train Loss: 1.4431621310290168, Val Loss: 1.0521844625473022\n",
      "Window 1 Epoch 20 Train Loss: 1.402611689567566, Val Loss: 1.0509734153747559\n",
      "Window 1 Epoch 30 Train Loss: 1.4339211001115686, Val Loss: 1.0498148202896118\n",
      "Window 1 Epoch 40 Train Loss: 1.3700825736101936, Val Loss: 1.0486103296279907\n",
      "Window 2 Epoch 0 Train Loss: 1.5427480302137486, Val Loss: 1.1842786073684692\n",
      "Window 2 Epoch 10 Train Loss: 1.5221295690536498, Val Loss: 1.1818926334381104\n",
      "Window 2 Epoch 20 Train Loss: 1.5771731404697193, Val Loss: 1.1794873476028442\n",
      "Window 2 Epoch 30 Train Loss: 1.576192044650807, Val Loss: 1.1770659685134888\n",
      "Window 2 Epoch 40 Train Loss: 1.5446020179636337, Val Loss: 1.1747339963912964\n",
      "Window 3 Epoch 0 Train Loss: 1.5402828118380378, Val Loss: 1.0482805967330933\n",
      "Window 3 Epoch 10 Train Loss: 1.514416571224437, Val Loss: 1.0469266176223755\n",
      "Window 3 Epoch 20 Train Loss: 1.4999201805451337, Val Loss: 1.0456304550170898\n",
      "Window 3 Epoch 30 Train Loss: 1.4914597455193015, Val Loss: 1.0443392992019653\n",
      "Window 3 Epoch 40 Train Loss: 1.5168990053850062, Val Loss: 1.043055534362793\n",
      "Window 4 Epoch 0 Train Loss: 1.263548032536226, Val Loss: 0.9743134379386902\n",
      "Window 4 Epoch 10 Train Loss: 1.2101628945855534, Val Loss: 0.9734582901000977\n",
      "Window 4 Epoch 20 Train Loss: 1.160419233266045, Val Loss: 0.972615659236908\n",
      "Window 4 Epoch 30 Train Loss: 1.2244384121894836, Val Loss: 0.9718253016471863\n",
      "Window 4 Epoch 40 Train Loss: 1.1486068234724156, Val Loss: 0.9709894061088562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:00:30,250] Trial 6 finished with value: 0.9722621440887451 and parameters: {'lstm_hidden_layer_size': 138, 'mlp_hidden_dim': 30, 'learning_rate': 1e-06, 'dropout': 0.35, 'batch_size': 128, 'num_gaussians': 6, 'patience': 9}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5486529092227712, Val Loss: 1.2061394453048706\n",
      "Window 0 Epoch 10 Train Loss: 0.7848585966054131, Val Loss: 0.9568078319231669\n",
      "Window 0 Epoch 20 Train Loss: 0.4822048469851999, Val Loss: 0.6160860061645508\n",
      "Window 0 Epoch 30 Train Loss: 0.05797458263004528, Val Loss: -0.11717839539051056\n",
      "Window 0 Epoch 40 Train Loss: -0.24581737153670366, Val Loss: -0.6561648448308309\n",
      "Window 1 Epoch 0 Train Loss: 1.3319031109529382, Val Loss: 1.1726719935735066\n",
      "Window 1 Epoch 10 Train Loss: 0.43095321150387034, Val Loss: 0.824385424455007\n",
      "Window 1 Epoch 20 Train Loss: 0.00896265380522784, Val Loss: 0.40256107846895856\n",
      "Window 1 Epoch 30 Train Loss: -0.2419021719343522, Val Loss: -0.21183741092681885\n",
      "Window 1 Epoch 40 Train Loss: -0.5267203685816596, Val Loss: -0.5002122720082601\n",
      "Window 2 Epoch 0 Train Loss: 1.262955319180208, Val Loss: 1.1108215649922688\n",
      "Window 2 Epoch 10 Train Loss: 0.3164331995038425, Val Loss: 0.6879716118176779\n",
      "Window 2 Epoch 20 Train Loss: -0.11973836381207494, Val Loss: 0.3104402770598729\n",
      "Window 2 Epoch 30 Train Loss: -0.40641740259002235, Val Loss: -0.127512256304423\n",
      "Window 2 Epoch 40 Train Loss: -0.5384415204034132, Val Loss: -0.43689246972401935\n",
      "Window 3 Epoch 0 Train Loss: 1.2907361743029426, Val Loss: 0.9014570713043213\n",
      "Window 3 Epoch 10 Train Loss: 0.500607052971335, Val Loss: 0.6146484613418579\n",
      "Window 3 Epoch 20 Train Loss: 0.20565799269606086, Val Loss: 0.3649005889892578\n",
      "Window 3 Epoch 30 Train Loss: -0.05929896663216984, Val Loss: -0.0860189398129781\n",
      "Window 3 Epoch 40 Train Loss: -0.2826245683782241, Val Loss: -0.3669344981511434\n",
      "Window 4 Epoch 0 Train Loss: 1.7906199539408965, Val Loss: 1.0309590697288513\n",
      "Window 4 Epoch 10 Train Loss: 0.7711087351686814, Val Loss: 0.8034773270289103\n",
      "Window 4 Epoch 20 Train Loss: 0.3788513160453123, Val Loss: 0.5615871548652649\n",
      "Window 4 Epoch 30 Train Loss: 0.08752908298197914, Val Loss: 0.11249641825755437\n",
      "Window 4 Epoch 40 Train Loss: -0.14264881652944228, Val Loss: -0.31047844886779785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:00:53,469] Trial 7 finished with value: 0.3080200404922168 and parameters: {'lstm_hidden_layer_size': 89, 'mlp_hidden_dim': 20, 'learning_rate': 0.0001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 8, 'patience': 6}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.435629864580491, Val Loss: 1.2657066583633423\n",
      "Window 0 Epoch 10 Train Loss: 1.4153820262235755, Val Loss: 1.2646088600158691\n",
      "Window 0 Epoch 20 Train Loss: 1.3988953509050257, Val Loss: 1.263506293296814\n",
      "Window 0 Epoch 30 Train Loss: 1.3864274644851684, Val Loss: 1.2624095678329468\n",
      "Window 0 Epoch 40 Train Loss: 1.384036618681515, Val Loss: 1.2613047361373901\n",
      "Window 1 Epoch 0 Train Loss: 2.112376324709724, Val Loss: 1.1398448944091797\n",
      "Window 1 Epoch 10 Train Loss: 2.038266582769506, Val Loss: 1.1382393836975098\n",
      "Window 1 Epoch 20 Train Loss: 2.1438799389670877, Val Loss: 1.1367570161819458\n",
      "Window 1 Epoch 30 Train Loss: 1.9869355656118954, Val Loss: 1.135347843170166\n",
      "Window 1 Epoch 40 Train Loss: 1.956264622632195, Val Loss: 1.1337931156158447\n",
      "Window 2 Epoch 0 Train Loss: 1.5982003716861501, Val Loss: 0.8742339015007019\n",
      "Window 2 Epoch 10 Train Loss: 1.479259584651274, Val Loss: 0.8724551200866699\n",
      "Window 2 Epoch 20 Train Loss: 1.5400499164356904, Val Loss: 0.8706814646720886\n",
      "Window 2 Epoch 30 Train Loss: 1.4509099337633917, Val Loss: 0.8688370585441589\n",
      "Window 2 Epoch 40 Train Loss: 1.4517835086934707, Val Loss: 0.8669300079345703\n",
      "Window 3 Epoch 0 Train Loss: 1.91212337437798, Val Loss: 1.082001805305481\n",
      "Window 3 Epoch 10 Train Loss: 1.818386277591481, Val Loss: 1.0813781023025513\n",
      "Window 3 Epoch 20 Train Loss: 1.7324860525131225, Val Loss: 1.0807040929794312\n",
      "Window 3 Epoch 30 Train Loss: 1.851820229362039, Val Loss: 1.0801235437393188\n",
      "Window 3 Epoch 40 Train Loss: 1.76524424496819, Val Loss: 1.0794847011566162\n",
      "Window 4 Epoch 0 Train Loss: 2.222173305118785, Val Loss: 1.1829345226287842\n",
      "Window 4 Epoch 10 Train Loss: 2.1294722559872796, Val Loss: 1.1819771528244019\n",
      "Window 4 Epoch 20 Train Loss: 2.0559114467396458, Val Loss: 1.1809853315353394\n",
      "Window 4 Epoch 30 Train Loss: 2.099967486437629, Val Loss: 1.18000066280365\n",
      "Window 4 Epoch 40 Train Loss: 2.076970922526191, Val Loss: 1.178971529006958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:01:04,469] Trial 8 finished with value: 1.1805319833755492 and parameters: {'lstm_hidden_layer_size': 72, 'mlp_hidden_dim': 9, 'learning_rate': 1e-06, 'dropout': 0.35, 'batch_size': 64, 'num_gaussians': 7, 'patience': 10}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.352825309529024, Val Loss: 1.154871940612793\n",
      "Window 0 Epoch 10 Train Loss: 0.44314205169677734, Val Loss: 0.6736595034599304\n",
      "Window 0 Epoch 20 Train Loss: 0.12887311704018536, Val Loss: 0.36320510506629944\n",
      "Window 0 Epoch 30 Train Loss: -0.04882028439465691, Val Loss: -0.03310052677989006\n",
      "Window 0 Epoch 40 Train Loss: -0.14923602328580968, Val Loss: -0.4931631088256836\n",
      "Window 1 Epoch 0 Train Loss: 1.4820988958022174, Val Loss: 1.0978515148162842\n",
      "Window 1 Epoch 10 Train Loss: 0.42272791750290817, Val Loss: 0.8263756632804871\n",
      "Window 1 Epoch 20 Train Loss: 0.15699471796260162, Val Loss: 0.6462742686271667\n",
      "Window 1 Epoch 30 Train Loss: -0.015305282648957527, Val Loss: 0.10534752160310745\n",
      "Window 1 Epoch 40 Train Loss: -0.3842514260376201, Val Loss: -0.366436630487442\n",
      "Window 2 Epoch 0 Train Loss: 1.3650077951655668, Val Loss: 1.1398634910583496\n",
      "Window 2 Epoch 10 Train Loss: 0.15068177573821123, Val Loss: 0.7018056511878967\n",
      "Window 2 Epoch 20 Train Loss: -0.15806163717718685, Val Loss: 0.3240281045436859\n",
      "Window 2 Epoch 30 Train Loss: -0.3794575742413016, Val Loss: -0.1537000983953476\n",
      "Window 2 Epoch 40 Train Loss: -0.4197243623172536, Val Loss: -0.4482746124267578\n",
      "Window 3 Epoch 0 Train Loss: 0.9919155082983129, Val Loss: 0.8879728317260742\n",
      "Window 3 Epoch 10 Train Loss: 0.15612363261335035, Val Loss: 0.4594379663467407\n",
      "Window 3 Epoch 20 Train Loss: -0.24106879907057566, Val Loss: 0.11329745501279831\n",
      "Window 3 Epoch 30 Train Loss: -0.3987936124380897, Val Loss: -0.1967790573835373\n",
      "Window 3 Epoch 40 Train Loss: -0.5854712153883541, Val Loss: -0.376993864774704\n",
      "Window 4 Epoch 0 Train Loss: 1.3861852881487677, Val Loss: 1.0351827144622803\n",
      "Window 4 Epoch 10 Train Loss: 0.1635631983420428, Val Loss: 0.5993296504020691\n",
      "Window 4 Epoch 20 Train Loss: -0.05522834760301253, Val Loss: 0.2698543667793274\n",
      "Window 4 Epoch 30 Train Loss: -0.3112290687420789, Val Loss: -0.14222948253154755\n",
      "Window 4 Epoch 40 Train Loss: -0.44829991284538717, Val Loss: -0.35708919167518616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:01:22,900] Trial 9 finished with value: 0.1273607336357236 and parameters: {'lstm_hidden_layer_size': 242, 'mlp_hidden_dim': 22, 'learning_rate': 0.0001, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 4, 'patience': 7}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2841834000980152, Val Loss: 1.0813194513320923\n",
      "Window 0 Epoch 10 Train Loss: 0.2197548824899337, Val Loss: 0.15339450538158417\n",
      "Window 0 Epoch 20 Train Loss: 0.39207053773543415, Val Loss: -0.3738563358783722\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.1487755842769847, Val Loss: 0.994318425655365\n",
      "Window 1 Epoch 10 Train Loss: -0.2586670620301191, Val Loss: -0.25241464376449585\n",
      "Window 1 Epoch 20 Train Loss: -0.6829013628118178, Val Loss: -0.6333728432655334\n",
      "Window 1 Epoch 30 Train Loss: -0.7241779903804555, Val Loss: -0.5785002708435059\n",
      "Window 1 Epoch 40 Train Loss: -0.7768286452573888, Val Loss: -0.5469874739646912\n",
      "Window 2 Epoch 0 Train Loss: 1.218016767501831, Val Loss: 1.0020184516906738\n",
      "Window 2 Epoch 10 Train Loss: 0.3124128862689523, Val Loss: 0.42236530780792236\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.766743095622343, Val Loss: 0.9772791862487793\n",
      "Window 3 Epoch 10 Train Loss: 0.5652507052702063, Val Loss: 0.537093460559845\n",
      "Window 3 Epoch 20 Train Loss: 0.7926498211131376, Val Loss: -0.1750284880399704\n",
      "Window 3 Epoch 30 Train Loss: 0.7393835907823899, Val Loss: -0.07397102564573288\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.3827913087957047, Val Loss: 0.989804744720459\n",
      "Window 4 Epoch 10 Train Loss: 0.7929409984981313, Val Loss: 0.6309763789176941\n",
      "Window 4 Epoch 20 Train Loss: 0.47920307145399205, Val Loss: 0.15688763558864594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:01:28,758] Trial 10 finished with value: 0.43466162350627463 and parameters: {'lstm_hidden_layer_size': 246, 'mlp_hidden_dim': 4, 'learning_rate': 0.001, 'dropout': 0.3, 'batch_size': 256, 'num_gaussians': 3, 'patience': 3}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.182801529379452, Val Loss: 1.267444133758545\n",
      "Window 0 Epoch 10 Train Loss: 0.9629592522452859, Val Loss: 1.1978188753128052\n",
      "Window 0 Epoch 20 Train Loss: 0.8318870047961965, Val Loss: 1.15006685256958\n",
      "Window 0 Epoch 30 Train Loss: 0.7438264022153966, Val Loss: 1.112473487854004\n",
      "Window 0 Epoch 40 Train Loss: 0.7071179704105153, Val Loss: 1.0769203901290894\n",
      "Window 1 Epoch 0 Train Loss: 1.6777420804079841, Val Loss: 1.2101937532424927\n",
      "Window 1 Epoch 10 Train Loss: 1.4246479421503404, Val Loss: 1.1446564197540283\n",
      "Window 1 Epoch 20 Train Loss: 1.1966527756522685, Val Loss: 1.0767614841461182\n",
      "Window 1 Epoch 30 Train Loss: 0.9892744635133183, Val Loss: 1.0115326642990112\n",
      "Window 1 Epoch 40 Train Loss: 0.8139044260978698, Val Loss: 0.950917661190033\n",
      "Window 2 Epoch 0 Train Loss: 1.5452717102275175, Val Loss: 1.2287465333938599\n",
      "Window 2 Epoch 10 Train Loss: 1.3200004717882943, Val Loss: 1.1632028818130493\n",
      "Window 2 Epoch 20 Train Loss: 1.1197110041450051, Val Loss: 1.1036080121994019\n",
      "Window 2 Epoch 30 Train Loss: 0.9338026029923383, Val Loss: 1.0464261770248413\n",
      "Window 2 Epoch 40 Train Loss: 0.7735367124220904, Val Loss: 0.9904108047485352\n",
      "Window 3 Epoch 0 Train Loss: 1.3673807290021112, Val Loss: 1.0813215970993042\n",
      "Window 3 Epoch 10 Train Loss: 0.9323040067448336, Val Loss: 1.04071843624115\n",
      "Window 3 Epoch 20 Train Loss: 0.8067406166301054, Val Loss: 0.9826307892799377\n",
      "Window 3 Epoch 30 Train Loss: 0.5778825727631064, Val Loss: 0.9229249954223633\n",
      "Window 3 Epoch 40 Train Loss: 0.5128841213619008, Val Loss: 0.8645545840263367\n",
      "Window 4 Epoch 0 Train Loss: 0.9357133645169875, Val Loss: 0.9583218693733215\n",
      "Window 4 Epoch 10 Train Loss: 0.7598793865652645, Val Loss: 0.9282529950141907\n",
      "Window 4 Epoch 20 Train Loss: 0.6536533672669355, Val Loss: 0.891350507736206\n",
      "Window 4 Epoch 30 Train Loss: 0.6210271256110248, Val Loss: 0.8505155444145203\n",
      "Window 4 Epoch 40 Train Loss: 0.5379653127053204, Val Loss: 0.8075451850891113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:01:48,191] Trial 11 finished with value: 0.869686690568924 and parameters: {'lstm_hidden_layer_size': 253, 'mlp_hidden_dim': 29, 'learning_rate': 1e-05, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 4, 'patience': 8}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.8220403472115012, Val Loss: 1.2199519872665405\n",
      "Window 0 Epoch 10 Train Loss: 0.47246752149918503, Val Loss: 0.7804176807403564\n",
      "Window 0 Epoch 20 Train Loss: 0.01074339747428894, Val Loss: 0.3488394320011139\n",
      "Window 0 Epoch 30 Train Loss: -0.3318732776711969, Val Loss: -0.18740908801555634\n",
      "Window 0 Epoch 40 Train Loss: -0.5504939253189984, Val Loss: -0.6004475951194763\n",
      "Window 1 Epoch 0 Train Loss: 1.9540325551874498, Val Loss: 1.1097073554992676\n",
      "Window 1 Epoch 10 Train Loss: 0.4712291912471547, Val Loss: 0.8618142604827881\n",
      "Window 1 Epoch 20 Train Loss: 0.16121190632090848, Val Loss: 0.5932194590568542\n",
      "Window 1 Epoch 30 Train Loss: -0.08417145616867963, Val Loss: 0.2888024151325226\n",
      "Window 1 Epoch 40 Train Loss: -0.18562238560441663, Val Loss: 0.0459262989461422\n",
      "Window 2 Epoch 0 Train Loss: 1.5817179205838372, Val Loss: 1.224915623664856\n",
      "Window 2 Epoch 10 Train Loss: 0.3140862129716312, Val Loss: 0.7990904450416565\n",
      "Window 2 Epoch 20 Train Loss: -0.016481500653659595, Val Loss: 0.4016200006008148\n",
      "Window 2 Epoch 30 Train Loss: -0.2946494071799166, Val Loss: -0.03662147372961044\n",
      "Window 2 Epoch 40 Train Loss: -0.4372354625954348, Val Loss: -0.4500730335712433\n",
      "Window 3 Epoch 0 Train Loss: 1.755442952268264, Val Loss: 1.1126760244369507\n",
      "Window 3 Epoch 10 Train Loss: 0.19140851995524238, Val Loss: 0.5609486699104309\n",
      "Window 3 Epoch 20 Train Loss: -0.06752878090914557, Val Loss: 0.29563000798225403\n",
      "Window 3 Epoch 30 Train Loss: -0.1795938991097843, Val Loss: 0.018321827054023743\n",
      "Window 3 Epoch 40 Train Loss: -0.4273898558055653, Val Loss: -0.3134598135948181\n",
      "Window 4 Epoch 0 Train Loss: 1.45509748767404, Val Loss: 0.8750925660133362\n",
      "Window 4 Epoch 10 Train Loss: 0.3194312195216908, Val Loss: 0.43687912821769714\n",
      "Window 4 Epoch 20 Train Loss: -0.21244614886886934, Val Loss: 0.015271914191544056\n",
      "Window 4 Epoch 30 Train Loss: -0.4493298102126402, Val Loss: -0.3529423475265503\n",
      "Window 4 Epoch 40 Train Loss: -0.7582653277060565, Val Loss: -0.5572085380554199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:02:05,133] Trial 12 finished with value: -0.07134061893448233 and parameters: {'lstm_hidden_layer_size': 205, 'mlp_hidden_dim': 25, 'learning_rate': 0.0001, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 4, 'patience': 7}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.6988271065319285, Val Loss: 1.0604168176651\n",
      "Window 0 Epoch 10 Train Loss: 0.42222203510649065, Val Loss: -0.09989312291145325\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.6310109665814567, Val Loss: 1.1311057806015015\n",
      "Window 1 Epoch 10 Train Loss: 0.4242937535398147, Val Loss: 0.5169147849082947\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.3576585318060481, Val Loss: 1.0123155117034912\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 4.50174750846975, Val Loss: 1.0329238176345825\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.6058347337386187, Val Loss: 1.0391203165054321\n",
      "Window 4 Epoch 10 Train Loss: 0.4998871550928144, Val Loss: -0.08205119520425797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:02:09,225] Trial 13 finished with value: -0.049866560252363946 and parameters: {'lstm_hidden_layer_size': 184, 'mlp_hidden_dim': 35, 'learning_rate': 0.001, 'dropout': 0.45, 'batch_size': 64, 'num_gaussians': 2, 'patience': 3}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 20 Train Loss: -0.18689515758963193, Val Loss: -0.7606186270713806\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.24981311489554, Val Loss: 1.1351584196090698\n",
      "Window 0 Epoch 10 Train Loss: 1.1093020887935863, Val Loss: 1.090161681175232\n",
      "Window 0 Epoch 20 Train Loss: 1.0129596670936136, Val Loss: 1.0469820499420166\n",
      "Window 0 Epoch 30 Train Loss: 0.929672904435326, Val Loss: 1.0059067010879517\n",
      "Window 0 Epoch 40 Train Loss: 0.852998971378102, Val Loss: 0.9679861068725586\n",
      "Window 1 Epoch 0 Train Loss: 2.016283707899206, Val Loss: 1.1128214597702026\n",
      "Window 1 Epoch 10 Train Loss: 1.6524890380747177, Val Loss: 1.0759968757629395\n",
      "Window 1 Epoch 20 Train Loss: 1.4221766477472642, Val Loss: 1.0429104566574097\n",
      "Window 1 Epoch 30 Train Loss: 1.2291778278350831, Val Loss: 1.0127887725830078\n",
      "Window 1 Epoch 40 Train Loss: 1.0812552313243642, Val Loss: 0.9823384284973145\n",
      "Window 2 Epoch 0 Train Loss: 1.7158456572364358, Val Loss: 1.068320631980896\n",
      "Window 2 Epoch 10 Train Loss: 1.4162012697668636, Val Loss: 1.0447863340377808\n",
      "Window 2 Epoch 20 Train Loss: 1.2933270894779878, Val Loss: 1.01814603805542\n",
      "Window 2 Epoch 30 Train Loss: 1.1030772873934578, Val Loss: 0.9889699816703796\n",
      "Window 2 Epoch 40 Train Loss: 0.937065558012794, Val Loss: 0.9581102728843689\n",
      "Window 3 Epoch 0 Train Loss: 2.3241265692430386, Val Loss: 1.1311354637145996\n",
      "Window 3 Epoch 10 Train Loss: 1.990463033844443, Val Loss: 1.1165581941604614\n",
      "Window 3 Epoch 20 Train Loss: 1.7544983305650599, Val Loss: 1.100288987159729\n",
      "Window 3 Epoch 30 Train Loss: 1.5111049500633689, Val Loss: 1.0797555446624756\n",
      "Window 3 Epoch 40 Train Loss: 1.3566931090635412, Val Loss: 1.0549709796905518\n",
      "Window 4 Epoch 0 Train Loss: 1.3811213078218347, Val Loss: 1.0893213748931885\n",
      "Window 4 Epoch 10 Train Loss: 1.2434587529126335, Val Loss: 1.060915470123291\n",
      "Window 4 Epoch 20 Train Loss: 1.1038544141545015, Val Loss: 1.032490849494934\n",
      "Window 4 Epoch 30 Train Loss: 0.9846901993190541, Val Loss: 1.0029847621917725\n",
      "Window 4 Epoch 40 Train Loss: 0.858373873093549, Val Loss: 0.9717792868614197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:02:23,340] Trial 14 finished with value: 1.0179889130592346 and parameters: {'lstm_hidden_layer_size': 163, 'mlp_hidden_dim': 26, 'learning_rate': 1e-05, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 4, 'patience': 7}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0043972898932065, Val Loss: 1.094815731048584\n",
      "Window 0 Epoch 10 Train Loss: 0.27004230092553533, Val Loss: 0.8494278788566589\n",
      "Window 0 Epoch 20 Train Loss: 0.032060702828799977, Val Loss: 0.6023088693618774\n",
      "Window 0 Epoch 30 Train Loss: -0.21539252223556532, Val Loss: 0.13611675798892975\n",
      "Window 0 Epoch 40 Train Loss: -0.47048688636106606, Val Loss: -0.2887324392795563\n",
      "Window 1 Epoch 0 Train Loss: 1.1610304452391231, Val Loss: 0.9516575932502747\n",
      "Window 1 Epoch 10 Train Loss: 0.39158796422621783, Val Loss: 0.7474126815795898\n",
      "Window 1 Epoch 20 Train Loss: 0.12395270305521348, Val Loss: 0.5978380441665649\n",
      "Window 1 Epoch 30 Train Loss: -0.10873287025619956, Val Loss: 0.3129035234451294\n",
      "Window 1 Epoch 40 Train Loss: -0.3566326062819537, Val Loss: -0.1625395268201828\n",
      "Window 2 Epoch 0 Train Loss: 1.3483421269585105, Val Loss: 1.0721559524536133\n",
      "Window 2 Epoch 10 Train Loss: 0.2827139163017273, Val Loss: 0.7601706385612488\n",
      "Window 2 Epoch 20 Train Loss: 0.006405082029454849, Val Loss: 0.4444747865200043\n",
      "Window 2 Epoch 30 Train Loss: -0.21257253702510806, Val Loss: 0.05056534707546234\n",
      "Window 2 Epoch 40 Train Loss: -0.3601012349128723, Val Loss: -0.35959503054618835\n",
      "Window 3 Epoch 0 Train Loss: 1.4023655624950633, Val Loss: 1.0317341089248657\n",
      "Window 3 Epoch 10 Train Loss: 0.13013805852216834, Val Loss: 0.628119170665741\n",
      "Window 3 Epoch 20 Train Loss: -0.06375880577984978, Val Loss: 0.3647814989089966\n",
      "Window 3 Epoch 30 Train Loss: -0.20702880849294802, Val Loss: 0.1235220804810524\n",
      "Window 3 Epoch 40 Train Loss: -0.3869906724200529, Val Loss: -0.14964725077152252\n",
      "Window 4 Epoch 0 Train Loss: 2.371205555410946, Val Loss: 1.1323119401931763\n",
      "Window 4 Epoch 10 Train Loss: 0.40043707525028904, Val Loss: 0.695166826248169\n",
      "Window 4 Epoch 20 Train Loss: -0.02658645938424503, Val Loss: 0.3603179454803467\n",
      "Window 4 Epoch 30 Train Loss: -0.2776063692920348, Val Loss: -0.08436116576194763\n",
      "Window 4 Epoch 40 Train Loss: -0.1946952961472904, Val Loss: -0.308530330657959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:02:40,029] Trial 15 finished with value: 0.193053435087204 and parameters: {'lstm_hidden_layer_size': 213, 'mlp_hidden_dim': 11, 'learning_rate': 0.0001, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 5, 'patience': 5}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5664145884794347, Val Loss: 1.0072561502456665\n",
      "Window 0 Epoch 10 Train Loss: 0.19247020970372591, Val Loss: -0.20398585498332977\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.3121734174560098, Val Loss: 0.916652500629425\n",
      "Window 1 Epoch 10 Train Loss: -0.0891081702709198, Val Loss: -0.26632651686668396\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.8812610853419585, Val Loss: 0.725654125213623\n",
      "Window 2 Epoch 10 Train Loss: -0.36549182169577654, Val Loss: -0.4378744065761566\n",
      "Window 2 Epoch 20 Train Loss: -0.752775429276859, Val Loss: -0.7122562527656555\n",
      "Window 2 Epoch 30 Train Loss: -0.784408695417292, Val Loss: -0.8738327622413635\n",
      "Window 2 Epoch 40 Train Loss: -0.7765230898296132, Val Loss: -0.9254069924354553\n",
      "Window 3 Epoch 0 Train Loss: 0.9757363292750191, Val Loss: 0.7369526028633118\n",
      "Window 3 Epoch 10 Train Loss: -0.4081972046459422, Val Loss: -0.39888834953308105\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.8951484158459831, Val Loss: 0.70444256067276\n",
      "Window 4 Epoch 10 Train Loss: -0.33921907452976, Val Loss: -0.2864225208759308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:02:46,514] Trial 16 finished with value: -0.06575323061810599 and parameters: {'lstm_hidden_layer_size': 123, 'mlp_hidden_dim': 4, 'learning_rate': 0.001, 'dropout': 0.45, 'batch_size': 64, 'num_gaussians': 5, 'patience': 4}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.8133691899916704, Val Loss: 1.3501533269882202\n",
      "Window 0 Epoch 10 Train Loss: 1.1684679999071008, Val Loss: 1.1758098602294922\n",
      "Window 0 Epoch 20 Train Loss: 1.1209720600352568, Val Loss: 1.0959572792053223\n",
      "Window 0 Epoch 30 Train Loss: 0.8877803690293256, Val Loss: 0.9697270393371582\n",
      "Window 0 Epoch 40 Train Loss: 0.7854217111363131, Val Loss: 0.8500173687934875\n",
      "Window 1 Epoch 0 Train Loss: 1.281023730951197, Val Loss: 1.1170130968093872\n",
      "Window 1 Epoch 10 Train Loss: 0.8533069654072032, Val Loss: 0.9559497237205505\n",
      "Window 1 Epoch 20 Train Loss: 0.7266587791723363, Val Loss: 0.8392284512519836\n",
      "Window 1 Epoch 30 Train Loss: 0.537563597314498, Val Loss: 0.7024404406547546\n",
      "Window 1 Epoch 40 Train Loss: 0.3774456250667572, Val Loss: 0.5419406890869141\n",
      "Window 2 Epoch 0 Train Loss: 1.134914701125201, Val Loss: 0.9772664904594421\n",
      "Window 2 Epoch 10 Train Loss: 0.5721429627783158, Val Loss: 0.8754210472106934\n",
      "Window 2 Epoch 20 Train Loss: 0.3902927834146163, Val Loss: 0.8025506138801575\n",
      "Window 2 Epoch 30 Train Loss: 0.3469444650411606, Val Loss: 0.73195481300354\n",
      "Window 2 Epoch 40 Train Loss: 0.283455387283774, Val Loss: 0.6596262454986572\n",
      "Window 3 Epoch 0 Train Loss: 1.458892728581148, Val Loss: 0.9271799921989441\n",
      "Window 3 Epoch 10 Train Loss: 0.9949429758857278, Val Loss: 0.967900812625885\n",
      "Window 3 Epoch 20 Train Loss: 0.873088870048523, Val Loss: 0.9267266392707825\n",
      "Window 3 Epoch 30 Train Loss: 0.9780145047692692, Val Loss: 0.8435704112052917\n",
      "Window 3 Epoch 40 Train Loss: 0.6746316692408394, Val Loss: 0.7851324677467346\n",
      "Window 4 Epoch 0 Train Loss: 1.9229619637657613, Val Loss: 1.0568127632141113\n",
      "Window 4 Epoch 10 Train Loss: 1.2380194218018477, Val Loss: 0.9086951613426208\n",
      "Window 4 Epoch 20 Train Loss: 0.8750371386023129, Val Loss: 0.7633540034294128\n",
      "Window 4 Epoch 30 Train Loss: 0.6300505298726699, Val Loss: 0.6762705445289612\n",
      "Window 4 Epoch 40 Train Loss: 0.5043228230756872, Val Loss: 0.5789555907249451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:02:55,888] Trial 17 finished with value: 0.7394929969310761 and parameters: {'lstm_hidden_layer_size': 220, 'mlp_hidden_dim': 27, 'learning_rate': 0.0001, 'dropout': 0.2, 'batch_size': 256, 'num_gaussians': 2, 'patience': 8}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2119107937812805, Val Loss: 0.9912918210029602\n",
      "Window 0 Epoch 10 Train Loss: 0.16547459865317626, Val Loss: -0.19525903463363647\n",
      "Window 0 Epoch 20 Train Loss: -0.24776111069847556, Val Loss: -0.7918768525123596\n",
      "Window 0 Epoch 30 Train Loss: -0.289491587526658, Val Loss: -0.9309782981872559\n",
      "Window 0 Epoch 40 Train Loss: -0.5345568236182717, Val Loss: -0.985524594783783\n",
      "Window 1 Epoch 0 Train Loss: 1.8240125297097598, Val Loss: 0.9830124974250793\n",
      "Window 1 Epoch 10 Train Loss: 0.714903163208681, Val Loss: 0.727606475353241\n",
      "Window 1 Epoch 20 Train Loss: 0.13558528970269595, Val Loss: -0.27370527386665344\n",
      "Window 1 Epoch 30 Train Loss: -0.19918586183996762, Val Loss: -0.621891975402832\n",
      "Window 1 Epoch 40 Train Loss: -0.415019255806418, Val Loss: -0.6353276371955872\n",
      "Window 2 Epoch 0 Train Loss: 1.3679383207769955, Val Loss: 0.9407623410224915\n",
      "Window 2 Epoch 10 Train Loss: 0.4940285318739274, Val Loss: 0.5446119904518127\n",
      "Window 2 Epoch 20 Train Loss: -0.17036870220128228, Val Loss: -0.7021114230155945\n",
      "Window 2 Epoch 30 Train Loss: -0.3769844543232637, Val Loss: -0.8232504725456238\n",
      "Window 2 Epoch 40 Train Loss: -0.4968684238546035, Val Loss: -0.8675534725189209\n",
      "Window 3 Epoch 0 Train Loss: 1.3842337919684018, Val Loss: 1.0612956285476685\n",
      "Window 3 Epoch 10 Train Loss: 0.2927395771531498, Val Loss: 0.3103014826774597\n",
      "Window 3 Epoch 20 Train Loss: -0.2737686164238874, Val Loss: -0.5324960350990295\n",
      "Window 3 Epoch 30 Train Loss: -0.5194172842362348, Val Loss: -0.6357143521308899\n",
      "Window 3 Epoch 40 Train Loss: -0.4805780830102808, Val Loss: -0.6684773564338684\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 4.715532702417935, Val Loss: 0.8152638077735901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:03:02,224] Trial 18 finished with value: 0.8775115370750427 and parameters: {'lstm_hidden_layer_size': 56, 'mlp_hidden_dim': 35, 'learning_rate': 0.001, 'dropout': 0.3, 'batch_size': 128, 'num_gaussians': 3, 'patience': 4}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.9052404925402473, Val Loss: 1.4384170770645142\n",
      "Window 0 Epoch 10 Train Loss: 1.7592087998109704, Val Loss: 1.4027677774429321\n",
      "Window 0 Epoch 20 Train Loss: 1.5991485556434182, Val Loss: 1.369348406791687\n",
      "Window 0 Epoch 30 Train Loss: 1.4939800296110266, Val Loss: 1.3374184370040894\n",
      "Window 0 Epoch 40 Train Loss: 1.3560644755643956, Val Loss: 1.3080697059631348\n",
      "Window 1 Epoch 0 Train Loss: 1.693540278042064, Val Loss: 1.1679625511169434\n",
      "Window 1 Epoch 10 Train Loss: 1.6257472531935748, Val Loss: 1.1415995359420776\n",
      "Window 1 Epoch 20 Train Loss: 1.444468991616193, Val Loss: 1.1152998208999634\n",
      "Window 1 Epoch 30 Train Loss: 1.373634594188017, Val Loss: 1.087531566619873\n",
      "Window 1 Epoch 40 Train Loss: 1.272976783584146, Val Loss: 1.059464931488037\n",
      "Window 2 Epoch 0 Train Loss: 1.5851481998667998, Val Loss: 1.1442577838897705\n",
      "Window 2 Epoch 10 Train Loss: 1.424275599086986, Val Loss: 1.1118804216384888\n",
      "Window 2 Epoch 20 Train Loss: 1.344013641020831, Val Loss: 1.0807421207427979\n",
      "Window 2 Epoch 30 Train Loss: 1.2077379624983844, Val Loss: 1.0525907278060913\n",
      "Window 2 Epoch 40 Train Loss: 1.0895014521654915, Val Loss: 1.025347113609314\n",
      "Window 3 Epoch 0 Train Loss: 1.142124021474053, Val Loss: 1.030595302581787\n",
      "Window 3 Epoch 10 Train Loss: 1.0006906666475184, Val Loss: 1.0032342672348022\n",
      "Window 3 Epoch 20 Train Loss: 0.9458655839807847, Val Loss: 0.9789623618125916\n",
      "Window 3 Epoch 30 Train Loss: 0.8692345575725331, Val Loss: 0.9558752179145813\n",
      "Window 3 Epoch 40 Train Loss: 0.8404329664566937, Val Loss: 0.9323692321777344\n",
      "Window 4 Epoch 0 Train Loss: 1.7861964189305024, Val Loss: 1.170562505722046\n",
      "Window 4 Epoch 10 Train Loss: 1.6151789553025189, Val Loss: 1.13385009765625\n",
      "Window 4 Epoch 20 Train Loss: 1.4560132029477288, Val Loss: 1.0979126691818237\n",
      "Window 4 Epoch 30 Train Loss: 1.372734733469346, Val Loss: 1.0599688291549683\n",
      "Window 4 Epoch 40 Train Loss: 1.3405699059542489, Val Loss: 1.0247315168380737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:03:18,119] Trial 19 finished with value: 1.0810207784175874 and parameters: {'lstm_hidden_layer_size': 163, 'mlp_hidden_dim': 24, 'learning_rate': 1e-05, 'dropout': 0.4, 'batch_size': 64, 'num_gaussians': 6, 'patience': 6}. Best is trial 2 with value: -0.07837052771910316.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1131028363283944, Val Loss: 0.7405254244804382\n",
      "Window 0 Epoch 10 Train Loss: 0.671544972062111, Val Loss: 0.016027415171265602\n",
      "Window 0 Epoch 20 Train Loss: -0.5774573896912968, Val Loss: -0.9230787754058838\n",
      "Window 0 Epoch 30 Train Loss: -0.6726529125606312, Val Loss: -0.9270690083503723\n",
      "Window 0 Epoch 40 Train Loss: -0.7218468855409061, Val Loss: -0.9470654129981995\n",
      "Window 1 Epoch 0 Train Loss: 2.5323968943427593, Val Loss: 0.8873770833015442\n",
      "Window 1 Epoch 10 Train Loss: -0.12393611014765851, Val Loss: -0.0698104277253151\n",
      "Window 1 Epoch 20 Train Loss: -0.3301711425360511, Val Loss: -0.48886117339134216\n",
      "Window 1 Epoch 30 Train Loss: -0.39919882125714246, Val Loss: -0.43440642952919006\n",
      "Window 1 Epoch 40 Train Loss: -0.438978598538567, Val Loss: -0.34909042716026306\n",
      "Window 2 Epoch 0 Train Loss: 1.6133173426459817, Val Loss: 0.7122998237609863\n",
      "Window 2 Epoch 10 Train Loss: 0.6942860659431008, Val Loss: 0.2985006272792816\n",
      "Window 2 Epoch 20 Train Loss: -0.29324487910551184, Val Loss: -0.562667191028595\n",
      "Window 2 Epoch 30 Train Loss: -0.548372787587783, Val Loss: -0.8320780396461487\n",
      "Window 2 Epoch 40 Train Loss: -0.5403653606246499, Val Loss: -0.8749380707740784\n",
      "Window 3 Epoch 0 Train Loss: 1.6795560512823218, Val Loss: 0.5418188571929932\n",
      "Window 3 Epoch 10 Train Loss: -0.1692256066378425, Val Loss: -0.42029520869255066\n",
      "Window 3 Epoch 20 Train Loss: -0.5704088854789734, Val Loss: 0.07061321288347244\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.442359281988705, Val Loss: 1.0052520036697388\n",
      "Window 4 Epoch 10 Train Loss: 0.7366588408806745, Val Loss: 0.18858598172664642\n",
      "Window 4 Epoch 20 Train Loss: -0.4697231936454773, Val Loss: -0.5079519748687744\n",
      "Window 4 Epoch 30 Train Loss: -0.8823051532577065, Val Loss: -0.6953832507133484\n",
      "Window 4 Epoch 40 Train Loss: -0.8702663814320284, Val Loss: -0.5945800542831421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:03:30,488] Trial 20 finished with value: -0.3187658578902483 and parameters: {'lstm_hidden_layer_size': 132, 'mlp_hidden_dim': 14, 'learning_rate': 0.01, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 7, 'patience': 10}. Best is trial 20 with value: -0.3187658578902483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.7089240264892578, Val Loss: 0.9535069465637207\n",
      "Window 0 Epoch 10 Train Loss: 0.4001852735877037, Val Loss: 0.025128602981567383\n",
      "Window 0 Epoch 20 Train Loss: -0.5823897660479826, Val Loss: -0.9702784419059753\n",
      "Window 0 Epoch 30 Train Loss: -0.5629165772830739, Val Loss: -0.7211194038391113\n",
      "Window 0 Epoch 40 Train Loss: -0.725897865155164, Val Loss: -0.9710871577262878\n",
      "Window 1 Epoch 0 Train Loss: 1.576160067950978, Val Loss: 0.8352518081665039\n",
      "Window 1 Epoch 10 Train Loss: 0.23507815781761618, Val Loss: -0.14763827621936798\n",
      "Window 1 Epoch 20 Train Loss: -0.2208602438253515, Val Loss: -0.5001873970031738\n",
      "Window 1 Epoch 30 Train Loss: -0.6598412135068108, Val Loss: -0.5414215922355652\n",
      "Window 1 Epoch 40 Train Loss: -0.5956445634365082, Val Loss: -0.6467108726501465\n",
      "Window 2 Epoch 0 Train Loss: 1.5235113561854643, Val Loss: 1.0612692832946777\n",
      "Window 2 Epoch 10 Train Loss: 1.135388195514679, Val Loss: 0.40932711958885193\n",
      "Window 2 Epoch 20 Train Loss: 0.016126776046174414, Val Loss: -0.15860705077648163\n",
      "Window 2 Epoch 30 Train Loss: -0.6646039483827703, Val Loss: -0.7700657248497009\n",
      "Window 2 Epoch 40 Train Loss: -0.6442779244394863, Val Loss: -0.736046552658081\n",
      "Window 3 Epoch 0 Train Loss: 3.0388291095284856, Val Loss: 1.5168110132217407\n",
      "Window 3 Epoch 10 Train Loss: 0.6135649573802948, Val Loss: 0.19553685188293457\n",
      "Window 3 Epoch 20 Train Loss: -0.21019595538868624, Val Loss: -0.5506213307380676\n",
      "Window 3 Epoch 30 Train Loss: -0.851230225983788, Val Loss: -0.02877745032310486\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.6667663682208342, Val Loss: 0.6366117596626282\n",
      "Window 4 Epoch 10 Train Loss: 0.9637205242058811, Val Loss: -0.11196959763765335\n",
      "Window 4 Epoch 20 Train Loss: -0.3008434198884403, Val Loss: -0.02161928080022335\n",
      "Window 4 Epoch 30 Train Loss: -0.9523758910684025, Val Loss: -0.5760783553123474\n",
      "Window 4 Epoch 40 Train Loss: -0.9409400390176212, Val Loss: -0.6471412777900696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:03:42,669] Trial 21 finished with value: -0.20290513712912797 and parameters: {'lstm_hidden_layer_size': 133, 'mlp_hidden_dim': 13, 'learning_rate': 0.01, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 7, 'patience': 10}. Best is trial 20 with value: -0.3187658578902483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.0641393323505626, Val Loss: 0.8438016772270203\n",
      "Window 0 Epoch 10 Train Loss: 0.7392713033451753, Val Loss: 0.41967859864234924\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.1191289628253263, Val Loss: 0.7235129475593567\n",
      "Window 1 Epoch 10 Train Loss: 0.22263000460232005, Val Loss: -0.28325673937797546\n",
      "Window 1 Epoch 20 Train Loss: -0.4088430831011604, Val Loss: -0.624701976776123\n",
      "Window 1 Epoch 30 Train Loss: -0.6093544655687668, Val Loss: -0.5976957082748413\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.877261223232045, Val Loss: 0.6982336044311523\n",
      "Window 2 Epoch 10 Train Loss: -0.2830158855634577, Val Loss: -0.73850417137146\n",
      "Window 2 Epoch 20 Train Loss: -0.4727171740111183, Val Loss: -0.6592137813568115\n",
      "Window 2 Epoch 30 Train Loss: -0.7576431376793805, Val Loss: -0.893619954586029\n",
      "Window 2 Epoch 40 Train Loss: -0.6510880372804754, Val Loss: -0.8190820813179016\n",
      "Window 3 Epoch 0 Train Loss: 1.4582134039261763, Val Loss: 0.9090776443481445\n",
      "Window 3 Epoch 10 Train Loss: -0.27076554691090304, Val Loss: -0.5526741147041321\n",
      "Window 3 Epoch 20 Train Loss: -0.4570176288660835, Val Loss: -0.24838842451572418\n",
      "Window 3 Epoch 30 Train Loss: -0.9218662730385275, Val Loss: -0.41783714294433594\n",
      "Window 3 Epoch 40 Train Loss: -0.9467104064717012, Val Loss: -0.5388297438621521\n",
      "Window 4 Epoch 0 Train Loss: 2.0799794623431036, Val Loss: 1.0002201795578003\n",
      "Window 4 Epoch 10 Train Loss: 1.0401912643278346, Val Loss: 0.04825589060783386\n",
      "Window 4 Epoch 20 Train Loss: -0.4406720207719242, Val Loss: -0.60463547706604\n",
      "Window 4 Epoch 30 Train Loss: -0.9890934279385735, Val Loss: -0.6379843354225159\n",
      "Window 4 Epoch 40 Train Loss: -0.9425113923409406, Val Loss: -0.7149778008460999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:03:53,526] Trial 22 finished with value: -0.25742056995630264 and parameters: {'lstm_hidden_layer_size': 131, 'mlp_hidden_dim': 13, 'learning_rate': 0.01, 'dropout': 0.1, 'batch_size': 64, 'num_gaussians': 7, 'patience': 10}. Best is trial 20 with value: -0.3187658578902483.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.962527886839474, Val Loss: 1.1827102899551392\n",
      "Window 0 Epoch 10 Train Loss: 0.165922068725614, Val Loss: -0.16530312597751617\n",
      "Window 0 Epoch 20 Train Loss: -0.4796359613362481, Val Loss: -0.5036229491233826\n",
      "Window 0 Epoch 30 Train Loss: -0.709389493745916, Val Loss: -1.0128778219223022\n",
      "Window 0 Epoch 40 Train Loss: -0.5924201558617984, Val Loss: -0.9770098328590393\n",
      "Window 1 Epoch 0 Train Loss: 1.3882201618306778, Val Loss: 1.0679703950881958\n",
      "Window 1 Epoch 10 Train Loss: -0.11675430322394652, Val Loss: 0.06819195300340652\n",
      "Window 1 Epoch 20 Train Loss: -0.42033619985860937, Val Loss: -0.5377287268638611\n",
      "Window 1 Epoch 30 Train Loss: -0.7274944311029771, Val Loss: -0.7041484713554382\n",
      "Window 1 Epoch 40 Train Loss: -0.6041190137582667, Val Loss: -0.6682550311088562\n",
      "Window 2 Epoch 0 Train Loss: 0.9943908389876871, Val Loss: 0.4833836853504181\n",
      "Window 2 Epoch 10 Train Loss: -0.48499968612895294, Val Loss: -0.783801257610321\n",
      "Window 2 Epoch 20 Train Loss: -0.6438359691114987, Val Loss: -0.815628707408905\n",
      "Window 2 Epoch 30 Train Loss: -0.6976586625155281, Val Loss: -0.9540227055549622\n",
      "Window 2 Epoch 40 Train Loss: -0.7390302684727837, Val Loss: -0.948890209197998\n",
      "Window 3 Epoch 0 Train Loss: 2.3135966508528765, Val Loss: 1.0415866374969482\n",
      "Window 3 Epoch 10 Train Loss: 0.8362773448053529, Val Loss: 0.04062280058860779\n",
      "Window 3 Epoch 20 Train Loss: -0.014949751636561225, Val Loss: -0.2037714570760727\n",
      "Window 3 Epoch 30 Train Loss: -0.5126340878711028, Val Loss: -0.1343793123960495\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 2.7137539145525764, Val Loss: 0.6819080710411072\n",
      "Window 4 Epoch 10 Train Loss: 0.15699262629537022, Val Loss: -0.19679594039916992\n",
      "Window 4 Epoch 20 Train Loss: -0.19482042396769805, Val Loss: -0.5316594243049622\n",
      "Window 4 Epoch 30 Train Loss: -0.7833175882171182, Val Loss: -0.6650108695030212\n",
      "Window 4 Epoch 40 Train Loss: -1.0144149081847247, Val Loss: -0.7318239808082581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:04:07,760] Trial 23 finished with value: -0.39450341038405895 and parameters: {'lstm_hidden_layer_size': 124, 'mlp_hidden_dim': 14, 'learning_rate': 0.01, 'dropout': 0.25, 'batch_size': 64, 'num_gaussians': 7, 'patience': 10}. Best is trial 23 with value: -0.39450341038405895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.057375810847563, Val Loss: 1.185196876525879\n",
      "Window 0 Epoch 10 Train Loss: 1.1479372554666856, Val Loss: 0.1923985481262207\n",
      "Window 0 Epoch 20 Train Loss: -0.5038895246561835, Val Loss: -0.7884982228279114\n",
      "Window 0 Epoch 30 Train Loss: -0.5332156694636625, Val Loss: -0.9468080401420593\n",
      "Window 0 Epoch 40 Train Loss: -0.6547937335687525, Val Loss: -0.8134391903877258\n",
      "Window 1 Epoch 0 Train Loss: 1.6953121594821705, Val Loss: 0.7310628890991211\n",
      "Window 1 Epoch 10 Train Loss: 0.15036315868882572, Val Loss: -0.37882038950920105\n",
      "Window 1 Epoch 20 Train Loss: -0.47087797403335574, Val Loss: -0.4091462194919586\n",
      "Window 1 Epoch 30 Train Loss: -0.48156372406903436, Val Loss: -0.5547752976417542\n",
      "Window 1 Epoch 40 Train Loss: -0.5333967149958891, Val Loss: -0.5956950783729553\n",
      "Window 2 Epoch 0 Train Loss: 1.8773604777280022, Val Loss: 1.0406019687652588\n",
      "Window 2 Epoch 10 Train Loss: 0.6210766198880532, Val Loss: -0.3072471022605896\n",
      "Window 2 Epoch 20 Train Loss: -0.23445276833632414, Val Loss: -0.1699472814798355\n",
      "Window 2 Epoch 30 Train Loss: -0.7199427176223082, Val Loss: -0.8257341384887695\n",
      "Window 2 Epoch 40 Train Loss: -0.7366684635246501, Val Loss: -0.5286303162574768\n",
      "Window 3 Epoch 0 Train Loss: 1.1851798934095046, Val Loss: 0.7057247161865234\n",
      "Window 3 Epoch 10 Train Loss: 0.06263996951720294, Val Loss: -0.37861931324005127\n",
      "Window 3 Epoch 20 Train Loss: -0.5794271766788819, Val Loss: -0.6321871876716614\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.8091901253251468, Val Loss: 0.7020494937896729\n",
      "Window 4 Epoch 10 Train Loss: 0.28302615754744587, Val Loss: 0.2709539830684662\n",
      "Window 4 Epoch 20 Train Loss: -0.4283102554433486, Val Loss: -0.5443897247314453\n",
      "Window 4 Epoch 30 Train Loss: -0.8597195089564604, Val Loss: -0.7117152214050293\n",
      "Window 4 Epoch 40 Train Loss: -0.9605502585803761, Val Loss: -0.7207598686218262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:04:20,217] Trial 24 finished with value: -0.23386850217357277 and parameters: {'lstm_hidden_layer_size': 109, 'mlp_hidden_dim': 16, 'learning_rate': 0.01, 'dropout': 0.25, 'batch_size': 64, 'num_gaussians': 8, 'patience': 9}. Best is trial 23 with value: -0.39450341038405895.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1595136025372674, Val Loss: 0.8799242973327637\n",
      "Window 0 Epoch 10 Train Loss: -0.0454493370476891, Val Loss: -0.2881104648113251\n",
      "Window 0 Epoch 20 Train Loss: 0.040545500306522146, Val Loss: 0.5059577226638794\n",
      "Window 0 Epoch 30 Train Loss: -0.6488444277819465, Val Loss: -1.0515872240066528\n",
      "Window 0 Epoch 40 Train Loss: -0.7957770170884974, Val Loss: -1.120103120803833\n",
      "Window 1 Epoch 0 Train Loss: 1.6441862646271201, Val Loss: 0.8223485946655273\n",
      "Window 1 Epoch 10 Train Loss: 1.1380281043052674, Val Loss: 0.1663517951965332\n",
      "Window 1 Epoch 20 Train Loss: -0.3046903603217181, Val Loss: -0.06037355586886406\n",
      "Window 1 Epoch 30 Train Loss: -0.7299750338582431, Val Loss: -0.6756053566932678\n",
      "Window 1 Epoch 40 Train Loss: -0.7078226090880001, Val Loss: -0.7077394127845764\n",
      "Window 2 Epoch 0 Train Loss: 1.2624796520962436, Val Loss: 0.7754788994789124\n",
      "Window 2 Epoch 10 Train Loss: 0.288158663055476, Val Loss: -0.21269047260284424\n",
      "Window 2 Epoch 20 Train Loss: -0.5612986368291518, Val Loss: -0.7570430636405945\n",
      "Window 2 Epoch 30 Train Loss: -0.7592796226108776, Val Loss: -0.8321278095245361\n",
      "Window 2 Epoch 40 Train Loss: -0.7291249691388186, Val Loss: -0.3874046802520752\n",
      "Window 3 Epoch 0 Train Loss: 1.1771166523765115, Val Loss: 0.7896718382835388\n",
      "Window 3 Epoch 10 Train Loss: 0.12525697862400728, Val Loss: -0.40051206946372986\n",
      "Window 3 Epoch 20 Train Loss: -0.23653063317870393, Val Loss: -0.06429202109575272\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.4560293395379011, Val Loss: 0.9118204116821289\n",
      "Window 4 Epoch 10 Train Loss: 0.3009632286955329, Val Loss: -0.18272559344768524\n",
      "Window 4 Epoch 20 Train Loss: -0.8531342879463645, Val Loss: -0.7116574645042419\n",
      "Window 4 Epoch 30 Train Loss: -0.8451315132309408, Val Loss: -0.5739877820014954\n",
      "Window 4 Epoch 40 Train Loss: -0.9744941843257231, Val Loss: -0.69560307264328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:04:31,883] Trial 25 finished with value: -0.42679225471802057 and parameters: {'lstm_hidden_layer_size': 87, 'mlp_hidden_dim': 13, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 64, 'num_gaussians': 7, 'patience': 10}. Best is trial 25 with value: -0.42679225471802057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.3504894971847534, Val Loss: 0.9990634322166443\n",
      "Window 0 Epoch 10 Train Loss: -0.03459565856877495, Val Loss: -0.641418993473053\n",
      "Window 0 Epoch 20 Train Loss: -0.49565096055760105, Val Loss: -0.8404252529144287\n",
      "Window 0 Epoch 30 Train Loss: -0.7290047271111432, Val Loss: -1.0603581666946411\n",
      "Window 0 Epoch 40 Train Loss: -0.7792997872128206, Val Loss: -1.0051690340042114\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.5111074472876156, Val Loss: 0.9481003880500793\n",
      "Window 1 Epoch 10 Train Loss: 0.1865269112586975, Val Loss: -0.3060866892337799\n",
      "Window 1 Epoch 20 Train Loss: 0.0077320818603038785, Val Loss: -0.45731303095817566\n",
      "Window 1 Epoch 30 Train Loss: -0.10476905135547414, Val Loss: -0.4676901400089264\n",
      "Window 1 Epoch 40 Train Loss: -0.4857153414277469, Val Loss: -0.6010145545005798\n",
      "Window 2 Epoch 0 Train Loss: 1.2126663255691528, Val Loss: 0.8702907562255859\n",
      "Window 2 Epoch 10 Train Loss: 0.22636720581966288, Val Loss: -0.3236010670661926\n",
      "Window 2 Epoch 20 Train Loss: 0.3424961225425496, Val Loss: -0.3586543798446655\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.1291580031899844, Val Loss: 0.8087518215179443\n",
      "Window 3 Epoch 10 Train Loss: 0.021044827826759396, Val Loss: 0.12107624858617783\n",
      "Window 3 Epoch 20 Train Loss: -0.24715635047239415, Val Loss: -0.2806345522403717\n",
      "Window 3 Epoch 30 Train Loss: -0.21207022758091199, Val Loss: -0.26368048787117004\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.6921582847483019, Val Loss: 0.8078863620758057\n",
      "Window 4 Epoch 10 Train Loss: 0.2858898119365468, Val Loss: 0.6805817484855652\n",
      "Window 4 Epoch 20 Train Loss: 0.5367066550254822, Val Loss: -0.12684574723243713\n",
      "Window 4 Epoch 30 Train Loss: -0.5691208674627192, Val Loss: -0.5436323881149292\n",
      "Window 4 Epoch 40 Train Loss: -0.714792128310484, Val Loss: -0.7438432574272156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:04:35,765] Trial 26 finished with value: -0.19083864791318775 and parameters: {'lstm_hidden_layer_size': 49, 'mlp_hidden_dim': 15, 'learning_rate': 0.01, 'dropout': 0.25, 'batch_size': 256, 'num_gaussians': 10, 'patience': 9}. Best is trial 25 with value: -0.42679225471802057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.6820206723493688, Val Loss: 0.7160813808441162\n",
      "Window 0 Epoch 10 Train Loss: -0.6277217751390793, Val Loss: -1.0595897634824116\n",
      "Window 0 Epoch 20 Train Loss: -0.44115329363766836, Val Loss: -0.7240426739056905\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.5006749411190258, Val Loss: 0.216625248392423\n",
      "Window 1 Epoch 10 Train Loss: -0.3787056638212765, Val Loss: -0.6301817695299784\n",
      "Window 1 Epoch 20 Train Loss: -0.5288553197243634, Val Loss: -0.38071176037192345\n",
      "Window 1 Epoch 30 Train Loss: -0.4608050564808004, Val Loss: -0.3068077315886815\n",
      "Window 1 Epoch 40 Train Loss: -0.4938486177781049, Val Loss: -0.6465287009874979\n",
      "Window 2 Epoch 0 Train Loss: 0.6720137433444753, Val Loss: 0.47369704643885296\n",
      "Window 2 Epoch 10 Train Loss: -0.39072667731958277, Val Loss: -0.28403759002685547\n",
      "Window 2 Epoch 20 Train Loss: -0.648032824326964, Val Loss: -0.7766524950663248\n",
      "Window 2 Epoch 30 Train Loss: -0.56349200332866, Val Loss: -0.8371208111445109\n",
      "Window 2 Epoch 40 Train Loss: -0.682127574892605, Val Loss: -0.8458637396494547\n",
      "Window 3 Epoch 0 Train Loss: 0.8236633946615107, Val Loss: 0.3894643584887187\n",
      "Window 3 Epoch 10 Train Loss: -0.07280700206756592, Val Loss: -0.20140490929285684\n",
      "Window 3 Epoch 20 Train Loss: -0.6771603965759277, Val Loss: -0.31839852531750995\n",
      "Window 3 Epoch 30 Train Loss: -0.5139942320655374, Val Loss: -0.2788782815138499\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.5837987373856938, Val Loss: 0.28087060650189716\n",
      "Window 4 Epoch 10 Train Loss: -0.3401188525031595, Val Loss: -0.5345341662565867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:04:50,994] Trial 27 finished with value: 0.042822548064092816 and parameters: {'lstm_hidden_layer_size': 93, 'mlp_hidden_dim': 10, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 32, 'num_gaussians': 9, 'patience': 10}. Best is trial 25 with value: -0.42679225471802057.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.8786959962283865, Val Loss: 1.019491195678711\n",
      "Window 0 Epoch 10 Train Loss: 0.7795407372187165, Val Loss: 0.07094687968492508\n",
      "Window 0 Epoch 20 Train Loss: -0.11248870933757109, Val Loss: -0.9502677321434021\n",
      "Window 0 Epoch 30 Train Loss: -0.36002787786371565, Val Loss: -0.771381676197052\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.9856097594429465, Val Loss: 0.7390961647033691\n",
      "Window 1 Epoch 10 Train Loss: 1.6198259335055072, Val Loss: -0.3548808991909027\n",
      "Window 1 Epoch 20 Train Loss: -0.6046621622758753, Val Loss: -0.634011447429657\n",
      "Window 1 Epoch 30 Train Loss: -0.7582536836231456, Val Loss: -0.6335025429725647\n",
      "Window 1 Epoch 40 Train Loss: -0.7288446701274198, Val Loss: -0.579176127910614\n",
      "Window 2 Epoch 0 Train Loss: 1.520538753341226, Val Loss: 0.7086904048919678\n",
      "Window 2 Epoch 10 Train Loss: 0.661666548707906, Val Loss: -0.3879554271697998\n",
      "Window 2 Epoch 20 Train Loss: 0.05810671974630917, Val Loss: -0.46981731057167053\n",
      "Window 2 Epoch 30 Train Loss: -0.5745089935555178, Val Loss: -0.7535204887390137\n",
      "Window 2 Epoch 40 Train Loss: -0.7831929546244004, Val Loss: -0.8132502436637878\n",
      "Window 3 Epoch 0 Train Loss: 1.2457864803426406, Val Loss: 0.6968443393707275\n",
      "Window 3 Epoch 10 Train Loss: 0.9742001895518864, Val Loss: -0.024176308885216713\n",
      "Window 3 Epoch 20 Train Loss: -0.334613660994698, Val Loss: -0.32008716464042664\n",
      "Window 3 Epoch 30 Train Loss: -0.8177049716781167, Val Loss: -0.4154408872127533\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.8084320341839509, Val Loss: 0.24099142849445343\n",
      "Window 4 Epoch 10 Train Loss: -0.8305971375633688, Val Loss: -0.7059764862060547\n",
      "Window 4 Epoch 20 Train Loss: -0.8677784375583424, Val Loss: -0.6159793734550476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:04:56,928] Trial 28 finished with value: -0.5611465823437486 and parameters: {'lstm_hidden_layer_size': 74, 'mlp_hidden_dim': 7, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 7, 'patience': 9}. Best is trial 28 with value: -0.5611465823437486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1572319221496583, Val Loss: 0.8680599331855774\n",
      "Window 0 Epoch 10 Train Loss: -0.2265628279657925, Val Loss: -0.1939002126455307\n",
      "Window 0 Epoch 20 Train Loss: -0.6047201528268702, Val Loss: -0.9713370203971863\n",
      "Window 0 Epoch 30 Train Loss: -0.7404646672922022, Val Loss: -0.9977465271949768\n",
      "Window 0 Epoch 40 Train Loss: -0.7490858925090117, Val Loss: -0.9505875110626221\n",
      "Window 1 Epoch 0 Train Loss: 1.5673680556521696, Val Loss: 0.8081097602844238\n",
      "Window 1 Epoch 10 Train Loss: -0.15981582823921653, Val Loss: -0.5726640820503235\n",
      "Window 1 Epoch 20 Train Loss: -0.531380520287682, Val Loss: -0.6435897946357727\n",
      "Window 1 Epoch 30 Train Loss: -0.729226550915662, Val Loss: -0.708742618560791\n",
      "Window 1 Epoch 40 Train Loss: -0.46625514282899744, Val Loss: -0.541545569896698\n",
      "Window 2 Epoch 0 Train Loss: 0.9711255881365608, Val Loss: 0.8255660533905029\n",
      "Window 2 Epoch 10 Train Loss: -0.2842305766834932, Val Loss: -0.5660318732261658\n",
      "Window 2 Epoch 20 Train Loss: -0.6712950470868279, Val Loss: -0.6930418014526367\n",
      "Window 2 Epoch 30 Train Loss: -0.7916604102359098, Val Loss: -0.9702887535095215\n",
      "Window 2 Epoch 40 Train Loss: -0.8330514325815088, Val Loss: -0.879545271396637\n",
      "Window 3 Epoch 0 Train Loss: 1.4339269225737628, Val Loss: 0.7900805473327637\n",
      "Window 3 Epoch 10 Train Loss: -0.06869435268289903, Val Loss: -0.4415934085845947\n",
      "Window 3 Epoch 20 Train Loss: -0.4838298682605519, Val Loss: -0.31169694662094116\n",
      "Window 3 Epoch 30 Train Loss: -0.42144163524403294, Val Loss: -0.33569666743278503\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.3964902713719536, Val Loss: 0.8405142426490784\n",
      "Window 4 Epoch 10 Train Loss: -0.6102294043933644, Val Loss: -0.5856364369392395\n",
      "Window 4 Epoch 20 Train Loss: -0.8697125906102797, Val Loss: -0.7600107192993164\n",
      "Window 4 Epoch 30 Train Loss: -0.9334532619925107, Val Loss: -0.7306515574455261\n",
      "Window 4 Epoch 40 Train Loss: -0.9506581620609059, Val Loss: -0.7148916721343994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:01,286] Trial 29 finished with value: -0.5902499265223742 and parameters: {'lstm_hidden_layer_size': 18, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 29 with value: -0.5902499265223742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.219512391651378, Val Loss: 0.9719797968864441\n",
      "Window 0 Epoch 10 Train Loss: 0.5225437339263804, Val Loss: -0.04923437163233757\n",
      "Window 0 Epoch 20 Train Loss: 0.35386480064953074, Val Loss: -0.6586114764213562\n",
      "Window 0 Epoch 30 Train Loss: -0.6327570333200343, Val Loss: -0.8194844126701355\n",
      "Window 0 Epoch 40 Train Loss: -0.7566847830660203, Val Loss: -1.0602105855941772\n",
      "Window 1 Epoch 0 Train Loss: 1.2113202518575332, Val Loss: 0.9058695435523987\n",
      "Window 1 Epoch 10 Train Loss: -0.30891766821636873, Val Loss: -0.5574319362640381\n",
      "Window 1 Epoch 20 Train Loss: -0.6184984524109784, Val Loss: -0.7391462326049805\n",
      "Window 1 Epoch 30 Train Loss: -0.6925063734896043, Val Loss: -0.6596863269805908\n",
      "Window 1 Epoch 40 Train Loss: -0.7268260032990399, Val Loss: -0.7000438570976257\n",
      "Window 2 Epoch 0 Train Loss: 1.367685394006617, Val Loss: 0.7553498148918152\n",
      "Window 2 Epoch 10 Train Loss: -0.1155595533286824, Val Loss: -0.31093913316726685\n",
      "Window 2 Epoch 20 Train Loss: -0.05404521423227647, Val Loss: -0.7410494685173035\n",
      "Window 2 Epoch 30 Train Loss: -0.6559049244487987, Val Loss: -0.9744033217430115\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.1780876792178434, Val Loss: 0.8635949492454529\n",
      "Window 3 Epoch 10 Train Loss: 0.5629793484070722, Val Loss: -0.32304179668426514\n",
      "Window 3 Epoch 20 Train Loss: -0.7872243119688596, Val Loss: -0.4054166078567505\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0328645094703226, Val Loss: 0.759198009967804\n",
      "Window 4 Epoch 10 Train Loss: 1.0689271518763375, Val Loss: -0.29126304388046265\n",
      "Window 4 Epoch 20 Train Loss: -0.7843720729210798, Val Loss: -0.6794866919517517\n",
      "Window 4 Epoch 30 Train Loss: -0.8933657556421617, Val Loss: -0.6934526562690735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:05,048] Trial 30 finished with value: -0.48401892483234404 and parameters: {'lstm_hidden_layer_size': 17, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 29 with value: -0.5902499265223742.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.9303614394805011, Val Loss: -0.6602982878684998\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1600725507736207, Val Loss: 1.055129885673523\n",
      "Window 0 Epoch 10 Train Loss: -0.5989253526575425, Val Loss: -0.8998158574104309\n",
      "Window 0 Epoch 20 Train Loss: -0.7771774263942943, Val Loss: -1.024163007736206\n",
      "Window 0 Epoch 30 Train Loss: -0.7194104017930872, Val Loss: -0.9606971740722656\n",
      "Window 0 Epoch 40 Train Loss: -0.7743759449790506, Val Loss: -1.0343095064163208\n",
      "Window 1 Epoch 0 Train Loss: 1.0668296928966747, Val Loss: 0.7555469870567322\n",
      "Window 1 Epoch 10 Train Loss: -0.613652402232675, Val Loss: -0.5800038576126099\n",
      "Window 1 Epoch 20 Train Loss: -0.735048186638776, Val Loss: -0.680769145488739\n",
      "Window 1 Epoch 30 Train Loss: -0.681991539702696, Val Loss: -0.6591896414756775\n",
      "Window 1 Epoch 40 Train Loss: -0.6159073122809915, Val Loss: -0.6429713368415833\n",
      "Window 2 Epoch 0 Train Loss: 1.9102668195612291, Val Loss: 0.9482102394104004\n",
      "Window 2 Epoch 10 Train Loss: 0.12315977103569928, Val Loss: -0.5075294375419617\n",
      "Window 2 Epoch 20 Train Loss: -0.007358017590116052, Val Loss: -0.10216338187456131\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.8979712967311635, Val Loss: 0.8526915907859802\n",
      "Window 3 Epoch 10 Train Loss: -0.48536032494376685, Val Loss: -0.38265928626060486\n",
      "Window 3 Epoch 20 Train Loss: -0.847149847535526, Val Loss: -0.4557899534702301\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.145064724333146, Val Loss: 0.8712204098701477\n",
      "Window 4 Epoch 10 Train Loss: -0.6948697106978473, Val Loss: -0.5407876968383789\n",
      "Window 4 Epoch 20 Train Loss: -0.8856418501629549, Val Loss: -0.602955162525177\n",
      "Window 4 Epoch 30 Train Loss: -0.9785863555178923, Val Loss: -0.7606887817382812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:08,169] Trial 31 finished with value: -0.5977332150191068 and parameters: {'lstm_hidden_layer_size': 12, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 31 with value: -0.5977332150191068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.9848749853582943, Val Loss: -0.7911009192466736\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1017748110434589, Val Loss: 0.8279109597206116\n",
      "Window 0 Epoch 10 Train Loss: -0.4798148483388564, Val Loss: -0.8698344826698303\n",
      "Window 0 Epoch 20 Train Loss: -0.7836361329695758, Val Loss: -1.050789713859558\n",
      "Window 0 Epoch 30 Train Loss: -0.8420925810757806, Val Loss: -1.055538296699524\n",
      "Window 0 Epoch 40 Train Loss: -0.6945832806475022, Val Loss: -0.9328613877296448\n",
      "Window 1 Epoch 0 Train Loss: 1.046757916141959, Val Loss: 0.8031191825866699\n",
      "Window 1 Epoch 10 Train Loss: -0.11606041522587048, Val Loss: -0.2991549074649811\n",
      "Window 1 Epoch 20 Train Loss: -0.26694943315842573, Val Loss: -0.516693115234375\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.8202852038776174, Val Loss: 0.9789130687713623\n",
      "Window 2 Epoch 10 Train Loss: -0.187308513136471, Val Loss: -0.4999549388885498\n",
      "Window 2 Epoch 20 Train Loss: -0.4634175212243024, Val Loss: -0.7861823439598083\n",
      "Window 2 Epoch 30 Train Loss: -0.7670118477765252, Val Loss: -0.8786227107048035\n",
      "Window 2 Epoch 40 Train Loss: -0.655109708589666, Val Loss: -0.8362560272216797\n",
      "Window 3 Epoch 0 Train Loss: 0.9465618369158576, Val Loss: 0.7535000443458557\n",
      "Window 3 Epoch 10 Train Loss: -0.5367958359157338, Val Loss: -0.44436028599739075\n",
      "Window 3 Epoch 20 Train Loss: -0.7783676329781027, Val Loss: -0.3309406340122223\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1194127596125882, Val Loss: 0.7376843094825745\n",
      "Window 4 Epoch 10 Train Loss: 0.0034399918948902803, Val Loss: -0.42781177163124084\n",
      "Window 4 Epoch 20 Train Loss: -0.7772573288749246, Val Loss: -0.6229916214942932\n",
      "Window 4 Epoch 30 Train Loss: -0.9460288763046265, Val Loss: -0.6579968929290771\n",
      "Window 4 Epoch 40 Train Loss: -0.9534899209527409, Val Loss: -0.6346361041069031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:12,177] Trial 32 finished with value: -0.45908467983521406 and parameters: {'lstm_hidden_layer_size': 18, 'mlp_hidden_dim': 7, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 31 with value: -0.5977332150191068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2542718738668106, Val Loss: 1.0112411975860596\n",
      "Window 0 Epoch 10 Train Loss: 0.8794424491068896, Val Loss: -0.18917769193649292\n",
      "Window 0 Epoch 20 Train Loss: -0.3435372759314144, Val Loss: -1.0058602094650269\n",
      "Window 0 Epoch 30 Train Loss: -0.7344039733269635, Val Loss: -0.9987660050392151\n",
      "Window 0 Epoch 40 Train Loss: -0.7586473000750822, Val Loss: -1.0175591707229614\n",
      "Window 1 Epoch 0 Train Loss: 1.6816645916770487, Val Loss: 0.7596755027770996\n",
      "Window 1 Epoch 10 Train Loss: 1.0118469001966364, Val Loss: 0.06912007927894592\n",
      "Window 1 Epoch 20 Train Loss: -0.2798557364940643, Val Loss: -0.44075989723205566\n",
      "Window 1 Epoch 30 Train Loss: -0.23700536138871137, Val Loss: -0.6316492557525635\n",
      "Window 1 Epoch 40 Train Loss: -0.6550799137003281, Val Loss: -0.7408598065376282\n",
      "Window 2 Epoch 0 Train Loss: 0.8689042289116803, Val Loss: 0.8292579650878906\n",
      "Window 2 Epoch 10 Train Loss: -0.5008558532770943, Val Loss: -0.7846032977104187\n",
      "Window 2 Epoch 20 Train Loss: -0.7307099643875571, Val Loss: -0.8557549118995667\n",
      "Window 2 Epoch 30 Train Loss: -0.7209672146684983, Val Loss: -0.7508348822593689\n",
      "Window 2 Epoch 40 Train Loss: -0.8277546132312101, Val Loss: -0.9152116775512695\n",
      "Window 3 Epoch 0 Train Loss: 0.8946344818788416, Val Loss: 0.7226738929748535\n",
      "Window 3 Epoch 10 Train Loss: 0.07155079910860342, Val Loss: -0.11025014519691467\n",
      "Window 3 Epoch 20 Train Loss: -0.1559781960880055, Val Loss: -0.6244487166404724\n",
      "Window 3 Epoch 30 Train Loss: -0.5989845765338224, Val Loss: -0.4543667137622833\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.7055616007131689, Val Loss: 0.5676043033599854\n",
      "Window 4 Epoch 10 Train Loss: -0.20846064448356627, Val Loss: -0.27804848551750183\n",
      "Window 4 Epoch 20 Train Loss: -0.7189987258350148, Val Loss: -0.6151275038719177\n",
      "Window 4 Epoch 30 Train Loss: -0.9562643875795253, Val Loss: -0.6960116028785706\n",
      "Window 4 Epoch 40 Train Loss: -0.9464252185821533, Val Loss: -0.6687237620353699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:18,437] Trial 33 finished with value: -0.5019743441045285 and parameters: {'lstm_hidden_layer_size': 39, 'mlp_hidden_dim': 7, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 10, 'patience': 8}. Best is trial 31 with value: -0.5977332150191068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.368135412721073, Val Loss: 0.9621406197547913\n",
      "Window 0 Epoch 10 Train Loss: -0.1766848893025342, Val Loss: -0.7699081301689148\n",
      "Window 0 Epoch 20 Train Loss: -0.5223254049525542, Val Loss: -0.9504711627960205\n",
      "Window 0 Epoch 30 Train Loss: -0.552188450308407, Val Loss: -0.9898338317871094\n",
      "Window 0 Epoch 40 Train Loss: -0.7238644421801848, Val Loss: -1.0228568315505981\n",
      "Window 1 Epoch 0 Train Loss: 1.146129194427939, Val Loss: 0.587410032749176\n",
      "Window 1 Epoch 10 Train Loss: 0.1709910278986482, Val Loss: -0.22579562664031982\n",
      "Window 1 Epoch 20 Train Loss: -0.2510456414783702, Val Loss: -0.36931148171424866\n",
      "Window 1 Epoch 30 Train Loss: -0.700241773409002, Val Loss: -0.49959543347358704\n",
      "Window 1 Epoch 40 Train Loss: -0.7199148542740765, Val Loss: -0.6910650730133057\n",
      "Window 2 Epoch 0 Train Loss: 1.072063946723938, Val Loss: 0.74567049741745\n",
      "Window 2 Epoch 10 Train Loss: 0.506186660843737, Val Loss: -0.05179765820503235\n",
      "Window 2 Epoch 20 Train Loss: -0.5060152185664457, Val Loss: -0.713726818561554\n",
      "Window 2 Epoch 30 Train Loss: -0.6952755468031939, Val Loss: -0.8395616412162781\n",
      "Window 2 Epoch 40 Train Loss: -0.7968327792953043, Val Loss: -0.9507545828819275\n",
      "Window 3 Epoch 0 Train Loss: 0.8899982131228727, Val Loss: 0.7619362473487854\n",
      "Window 3 Epoch 10 Train Loss: -0.30487146251341873, Val Loss: -0.11533655971288681\n",
      "Window 3 Epoch 20 Train Loss: -0.8389854254442103, Val Loss: -0.46178099513053894\n",
      "Window 3 Epoch 30 Train Loss: -0.8781746341200436, Val Loss: -0.4730568826198578\n",
      "Window 3 Epoch 40 Train Loss: -0.92175846155952, Val Loss: -0.4002329409122467\n",
      "Window 4 Epoch 0 Train Loss: 0.9217748396536883, Val Loss: 0.6459404230117798\n",
      "Window 4 Epoch 10 Train Loss: 0.7932655817094971, Val Loss: 0.11977851390838623\n",
      "Window 4 Epoch 20 Train Loss: -0.9012058451596429, Val Loss: -0.7698994278907776\n",
      "Window 4 Epoch 30 Train Loss: -0.8840674627528471, Val Loss: -0.7444261908531189\n",
      "Window 4 Epoch 40 Train Loss: -0.9088138134339276, Val Loss: -0.7563705444335938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:25,265] Trial 34 finished with value: -0.5205571470642463 and parameters: {'lstm_hidden_layer_size': 47, 'mlp_hidden_dim': 7, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 10, 'patience': 8}. Best is trial 31 with value: -0.5977332150191068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0940653718219084, Val Loss: 0.6169648170471191\n",
      "Window 0 Epoch 10 Train Loss: -0.6612266553149504, Val Loss: -1.0343208312988281\n",
      "Window 0 Epoch 20 Train Loss: -0.5964681475302752, Val Loss: -0.8468908667564392\n",
      "Window 0 Epoch 30 Train Loss: -0.7223638116612154, Val Loss: -1.004095435142517\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.9739558055821587, Val Loss: 0.49330389499664307\n",
      "Window 1 Epoch 10 Train Loss: -0.6518473793478573, Val Loss: -0.5643647313117981\n",
      "Window 1 Epoch 20 Train Loss: -0.5511258647021126, Val Loss: -0.44070181250572205\n",
      "Window 1 Epoch 30 Train Loss: -0.7519018202669481, Val Loss: -0.5697556734085083\n",
      "Window 1 Epoch 40 Train Loss: -0.7734250009761137, Val Loss: -0.6600345969200134\n",
      "Window 2 Epoch 0 Train Loss: 0.8979509841694552, Val Loss: 0.3267662227153778\n",
      "Window 2 Epoch 10 Train Loss: -0.7205799517912023, Val Loss: -0.810939371585846\n",
      "Window 2 Epoch 20 Train Loss: -0.8267382762011359, Val Loss: -0.93806391954422\n",
      "Window 2 Epoch 30 Train Loss: -0.8223135305853451, Val Loss: -0.9874499440193176\n",
      "Window 2 Epoch 40 Train Loss: -0.7719547580270206, Val Loss: -0.7923574447631836\n",
      "Window 3 Epoch 0 Train Loss: 0.7951868397348067, Val Loss: 0.3873179852962494\n",
      "Window 3 Epoch 10 Train Loss: -0.07327304061721353, Val Loss: -0.31066083908081055\n",
      "Window 3 Epoch 20 Train Loss: -0.7910794488121482, Val Loss: -0.49685636162757874\n",
      "Window 3 Epoch 30 Train Loss: -0.8925933216599857, Val Loss: -0.43382003903388977\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.3108472678240608, Val Loss: 0.7850198745727539\n",
      "Window 4 Epoch 10 Train Loss: 0.5024961200882406, Val Loss: -0.3275740146636963\n",
      "Window 4 Epoch 20 Train Loss: 0.1738661047640969, Val Loss: -0.14864975214004517\n",
      "Window 4 Epoch 30 Train Loss: -0.5527678551393397, Val Loss: -0.29626286029815674\n",
      "Window 4 Epoch 40 Train Loss: -0.933332197525922, Val Loss: -0.6281061172485352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:31,036] Trial 35 finished with value: -0.40507065184414387 and parameters: {'lstm_hidden_layer_size': 32, 'mlp_hidden_dim': 4, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 10, 'patience': 8}. Best is trial 31 with value: -0.5977332150191068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2388206940538744, Val Loss: 0.7995553016662598\n",
      "Window 0 Epoch 10 Train Loss: 1.3882528582741231, Val Loss: 0.03604044392704964\n",
      "Window 0 Epoch 20 Train Loss: -0.4107121647105497, Val Loss: -1.0279494524002075\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.2151840191728929, Val Loss: 0.7592750191688538\n",
      "Window 1 Epoch 10 Train Loss: -0.014563333988189698, Val Loss: -0.2413473129272461\n",
      "Window 1 Epoch 20 Train Loss: -0.3196576376522289, Val Loss: -0.7103500962257385\n",
      "Window 1 Epoch 30 Train Loss: -0.5296510839462281, Val Loss: -0.38135969638824463\n",
      "Window 1 Epoch 40 Train Loss: -0.5023457372889799, Val Loss: -0.35230037569999695\n",
      "Window 2 Epoch 0 Train Loss: 1.4095352613224703, Val Loss: 0.7847635746002197\n",
      "Window 2 Epoch 10 Train Loss: 2.0552926872758306, Val Loss: 0.171567901968956\n",
      "Window 2 Epoch 20 Train Loss: -0.2004767065188464, Val Loss: -0.6698047518730164\n",
      "Window 2 Epoch 30 Train Loss: -0.24982729077339172, Val Loss: -0.7423966526985168\n",
      "Window 2 Epoch 40 Train Loss: -0.5282520150437074, Val Loss: -0.7356589436531067\n",
      "Window 3 Epoch 0 Train Loss: 1.6572420553600087, Val Loss: 0.7224562764167786\n",
      "Window 3 Epoch 10 Train Loss: 1.2557873871747185, Val Loss: -0.06514935195446014\n",
      "Window 3 Epoch 20 Train Loss: 0.27675860222648174, Val Loss: -0.6299142837524414\n",
      "Window 3 Epoch 30 Train Loss: -0.6119786578066209, Val Loss: -0.2548567056655884\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.8889053099295672, Val Loss: 0.45442143082618713\n",
      "Window 4 Epoch 10 Train Loss: 0.5467508572252358, Val Loss: 0.050858404487371445\n",
      "Window 4 Epoch 20 Train Loss: -0.05748693592408124, Val Loss: -0.42336857318878174\n",
      "Window 4 Epoch 30 Train Loss: -0.8997070511649636, Val Loss: -0.7199075818061829\n",
      "Window 4 Epoch 40 Train Loss: -0.9986116751502542, Val Loss: -0.7864766120910645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:37,644] Trial 36 finished with value: -0.42524926593527196 and parameters: {'lstm_hidden_layer_size': 67, 'mlp_hidden_dim': 8, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 8, 'patience': 8}. Best is trial 31 with value: -0.5977332150191068.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.4407614494772518, Val Loss: 1.0653480291366577\n",
      "Window 0 Epoch 10 Train Loss: 0.31496049824882955, Val Loss: -0.3802371025085449\n",
      "Window 0 Epoch 20 Train Loss: -0.6588608887616326, Val Loss: -0.9825428128242493\n",
      "Window 0 Epoch 30 Train Loss: -0.7056532197840073, Val Loss: -0.8726661205291748\n",
      "Window 0 Epoch 40 Train Loss: -0.7642491804852205, Val Loss: -1.0052028894424438\n",
      "Window 1 Epoch 0 Train Loss: 0.7875439747642068, Val Loss: 0.7661581039428711\n",
      "Window 1 Epoch 10 Train Loss: 0.4863994558067883, Val Loss: -0.04955771937966347\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.353143160202924, Val Loss: 0.7939220070838928\n",
      "Window 2 Epoch 10 Train Loss: 0.03325811778797823, Val Loss: -0.6924457550048828\n",
      "Window 2 Epoch 20 Train Loss: -0.6628150507983039, Val Loss: -0.8624604344367981\n",
      "Window 2 Epoch 30 Train Loss: -0.7021638180929072, Val Loss: -0.7915482521057129\n",
      "Window 2 Epoch 40 Train Loss: -0.8256748088668374, Val Loss: -0.9174129962921143\n",
      "Window 3 Epoch 0 Train Loss: 1.0955806591931512, Val Loss: 0.7561598420143127\n",
      "Window 3 Epoch 10 Train Loss: 0.641315254463869, Val Loss: 0.022627731785178185\n",
      "Window 3 Epoch 20 Train Loss: -0.27004434739842137, Val Loss: -0.5282090306282043\n",
      "Window 3 Epoch 30 Train Loss: -0.6522348544176887, Val Loss: -0.4547099769115448\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.8519145139525919, Val Loss: 0.6252085566520691\n",
      "Window 4 Epoch 10 Train Loss: -0.3035967077928431, Val Loss: -0.6503469944000244\n",
      "Window 4 Epoch 20 Train Loss: -0.674210183059468, Val Loss: -0.753230631351471\n",
      "Window 4 Epoch 30 Train Loss: -0.93862268335679, Val Loss: -0.7976865172386169\n",
      "Window 4 Epoch 40 Train Loss: -0.9353608179092407, Val Loss: -0.8198065757751465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:43,392] Trial 37 finished with value: -0.638297407682985 and parameters: {'lstm_hidden_layer_size': 32, 'mlp_hidden_dim': 11, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 37 with value: -0.638297407682985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.8874469277437995, Val Loss: 1.2430365085601807\n",
      "Window 0 Epoch 10 Train Loss: 1.9023842536701876, Val Loss: 1.2428027391433716\n",
      "Window 0 Epoch 20 Train Loss: 1.8988598534640144, Val Loss: 1.242566704750061\n",
      "Window 0 Epoch 30 Train Loss: 1.917361003931831, Val Loss: 1.2423393726348877\n",
      "Window 0 Epoch 40 Train Loss: 1.9141346614501056, Val Loss: 1.2421175241470337\n",
      "Window 1 Epoch 0 Train Loss: 1.3603273773193358, Val Loss: 1.2062177658081055\n",
      "Window 1 Epoch 10 Train Loss: 1.355121858260211, Val Loss: 1.205763578414917\n",
      "Window 1 Epoch 20 Train Loss: 1.3502051835901596, Val Loss: 1.2053090333938599\n",
      "Window 1 Epoch 30 Train Loss: 1.3516030207802268, Val Loss: 1.2048557996749878\n",
      "Window 1 Epoch 40 Train Loss: 1.3488472565482645, Val Loss: 1.2044037580490112\n",
      "Window 2 Epoch 0 Train Loss: 1.307763733583338, Val Loss: 1.019549012184143\n",
      "Window 2 Epoch 10 Train Loss: 1.3072031796679777, Val Loss: 1.0188502073287964\n",
      "Window 2 Epoch 20 Train Loss: 1.2690706112805534, Val Loss: 1.0181694030761719\n",
      "Window 2 Epoch 30 Train Loss: 1.28573366838343, Val Loss: 1.0174909830093384\n",
      "Window 2 Epoch 40 Train Loss: 1.270862339103923, Val Loss: 1.016808271408081\n",
      "Window 3 Epoch 0 Train Loss: 1.2567725265727323, Val Loss: 1.0618423223495483\n",
      "Window 3 Epoch 10 Train Loss: 1.2395533112918629, Val Loss: 1.0613571405410767\n",
      "Window 3 Epoch 20 Train Loss: 1.2452553387249217, Val Loss: 1.0608733892440796\n",
      "Window 3 Epoch 30 Train Loss: 1.240906876115238, Val Loss: 1.0603896379470825\n",
      "Window 3 Epoch 40 Train Loss: 1.234541050125571, Val Loss: 1.059904932975769\n",
      "Window 4 Epoch 0 Train Loss: 1.7592097669489244, Val Loss: 1.1457182168960571\n",
      "Window 4 Epoch 10 Train Loss: 1.7728608568976907, Val Loss: 1.145304799079895\n",
      "Window 4 Epoch 20 Train Loss: 1.7927751552357394, Val Loss: 1.144894003868103\n",
      "Window 4 Epoch 30 Train Loss: 1.7853669158150167, Val Loss: 1.1444857120513916\n",
      "Window 4 Epoch 40 Train Loss: 1.7701680845372818, Val Loss: 1.1440801620483398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:50,047] Trial 38 finished with value: 1.14471177816391 and parameters: {'lstm_hidden_layer_size': 30, 'mlp_hidden_dim': 11, 'learning_rate': 1e-06, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 37 with value: -0.638297407682985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5437159793517168, Val Loss: 1.100568175315857\n",
      "Window 0 Epoch 10 Train Loss: 0.5609506306928747, Val Loss: -0.5037495493888855\n",
      "Window 0 Epoch 20 Train Loss: -0.4302408521315631, Val Loss: -0.7334972023963928\n",
      "Window 0 Epoch 30 Train Loss: -0.7291222310066223, Val Loss: -1.0805267095565796\n",
      "Window 0 Epoch 40 Train Loss: -0.7061710826088401, Val Loss: -1.1103429794311523\n",
      "Window 1 Epoch 0 Train Loss: 1.0700788854150212, Val Loss: 0.8373861312866211\n",
      "Window 1 Epoch 10 Train Loss: -0.3977897175620584, Val Loss: -0.51005619764328\n",
      "Window 1 Epoch 20 Train Loss: -0.6479109667329227, Val Loss: -0.6598576903343201\n",
      "Window 1 Epoch 30 Train Loss: -0.6577827338611378, Val Loss: -0.5841829180717468\n",
      "Window 1 Epoch 40 Train Loss: -0.7411524055985843, Val Loss: -0.6534804701805115\n",
      "Window 2 Epoch 0 Train Loss: 1.3228135064068962, Val Loss: 0.8706179261207581\n",
      "Window 2 Epoch 10 Train Loss: 0.5206681245916029, Val Loss: -0.3502541780471802\n",
      "Window 2 Epoch 20 Train Loss: -0.6380497608465306, Val Loss: -0.8652970194816589\n",
      "Window 2 Epoch 30 Train Loss: -0.6737031909998725, Val Loss: -0.6089228987693787\n",
      "Window 2 Epoch 40 Train Loss: -0.7057858129108653, Val Loss: -0.8372886776924133\n",
      "Window 3 Epoch 0 Train Loss: 1.1797740793228149, Val Loss: 0.8828869462013245\n",
      "Window 3 Epoch 10 Train Loss: -0.2540901262619916, Val Loss: -0.014738723635673523\n",
      "Window 3 Epoch 20 Train Loss: -0.7126262684429393, Val Loss: -0.41535666584968567\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.7013226974711698, Val Loss: 0.6536809802055359\n",
      "Window 4 Epoch 10 Train Loss: -0.43758454561233523, Val Loss: -0.5202298164367676\n",
      "Window 4 Epoch 20 Train Loss: -0.8779371174644022, Val Loss: -0.7524954676628113\n",
      "Window 4 Epoch 30 Train Loss: -0.8932140204485725, Val Loss: -0.764016330242157\n",
      "Window 4 Epoch 40 Train Loss: -1.0066671806223253, Val Loss: -0.7069103121757507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:05:53,737] Trial 39 finished with value: -0.5594733318686486 and parameters: {'lstm_hidden_layer_size': 14, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 9}. Best is trial 37 with value: -0.638297407682985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2354814966987162, Val Loss: 0.9472054839134216\n",
      "Window 0 Epoch 10 Train Loss: -0.1626908935957095, Val Loss: -0.2800109386444092\n",
      "Window 0 Epoch 20 Train Loss: -0.22894794646431418, Val Loss: -0.37345877289772034\n",
      "Window 0 Epoch 30 Train Loss: -0.6586144403850331, Val Loss: -0.9353432655334473\n",
      "Window 0 Epoch 40 Train Loss: -0.6678785089885487, Val Loss: -0.9692407250404358\n",
      "Window 1 Epoch 0 Train Loss: 1.1973163457477793, Val Loss: 0.7293229103088379\n",
      "Window 1 Epoch 10 Train Loss: 0.00393734625157188, Val Loss: -0.25677987933158875\n",
      "Window 1 Epoch 20 Train Loss: -0.5249580855930552, Val Loss: -0.6154053211212158\n",
      "Window 1 Epoch 30 Train Loss: -0.3807244944572449, Val Loss: -0.5632959008216858\n",
      "Window 1 Epoch 40 Train Loss: -0.6758045228789834, Val Loss: -0.6898770332336426\n",
      "Window 2 Epoch 0 Train Loss: 2.6726780894223383, Val Loss: 0.42279359698295593\n",
      "Window 2 Epoch 10 Train Loss: 1.3949319893297027, Val Loss: -0.2873353064060211\n",
      "Window 2 Epoch 20 Train Loss: -0.17354788696064669, Val Loss: -0.2622353434562683\n",
      "Window 2 Epoch 30 Train Loss: 0.12817607648232404, Val Loss: -0.18616753816604614\n",
      "Window 2 Epoch 40 Train Loss: -0.6097075438499451, Val Loss: -0.8001728653907776\n",
      "Window 3 Epoch 0 Train Loss: 1.1721136212348937, Val Loss: 0.7409479022026062\n",
      "Window 3 Epoch 10 Train Loss: 0.9304252293442978, Val Loss: -0.041323985904455185\n",
      "Window 3 Epoch 20 Train Loss: 0.31263094972161687, Val Loss: -0.37976303696632385\n",
      "Window 3 Epoch 30 Train Loss: -0.7664919081856223, Val Loss: -0.5060886740684509\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.750660716084873, Val Loss: 0.5898146629333496\n",
      "Window 4 Epoch 10 Train Loss: 0.13120374653269262, Val Loss: -0.2772412598133087\n",
      "Window 4 Epoch 20 Train Loss: -0.7735921469856711, Val Loss: -0.7091339230537415\n",
      "Window 4 Epoch 30 Train Loss: -0.6238792234308579, Val Loss: -0.6309157013893127\n",
      "Window 4 Epoch 40 Train Loss: -0.9618833281012142, Val Loss: -0.724820613861084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:00,978] Trial 40 finished with value: -0.528637232654728 and parameters: {'lstm_hidden_layer_size': 64, 'mlp_hidden_dim': 9, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 37 with value: -0.638297407682985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.3880899451760684, Val Loss: 1.039125680923462\n",
      "Window 0 Epoch 10 Train Loss: -0.5197888625369352, Val Loss: -0.8383821845054626\n",
      "Window 0 Epoch 20 Train Loss: -0.7192870447214912, Val Loss: -1.003975749015808\n",
      "Window 0 Epoch 30 Train Loss: -0.7339966434590957, Val Loss: -1.0554293394088745\n",
      "Window 0 Epoch 40 Train Loss: -0.8211060937713174, Val Loss: -1.046775460243225\n",
      "Window 1 Epoch 0 Train Loss: 1.0019783991925857, Val Loss: 0.9643698334693909\n",
      "Window 1 Epoch 10 Train Loss: -0.4860124022820417, Val Loss: -0.6430453658103943\n",
      "Window 1 Epoch 20 Train Loss: -0.642466109640458, Val Loss: -0.7562608122825623\n",
      "Window 1 Epoch 30 Train Loss: -0.697657876996433, Val Loss: -0.7191582322120667\n",
      "Window 1 Epoch 40 Train Loss: -0.8006502549788531, Val Loss: -0.7233057022094727\n",
      "Window 2 Epoch 0 Train Loss: 1.6147427089074078, Val Loss: 0.9700688719749451\n",
      "Window 2 Epoch 10 Train Loss: 0.26228595575865576, Val Loss: 0.09086116403341293\n",
      "Window 2 Epoch 20 Train Loss: -0.593306813099805, Val Loss: -0.8692706227302551\n",
      "Window 2 Epoch 30 Train Loss: -0.7896651486789479, Val Loss: -0.7685697078704834\n",
      "Window 2 Epoch 40 Train Loss: -0.8078173742574803, Val Loss: -0.8473120331764221\n",
      "Window 3 Epoch 0 Train Loss: 0.9562265814051909, Val Loss: 0.7674924731254578\n",
      "Window 3 Epoch 10 Train Loss: -0.7574807450350594, Val Loss: -0.4549141824245453\n",
      "Window 3 Epoch 20 Train Loss: -0.8897246589380152, Val Loss: -0.45477059483528137\n",
      "Window 3 Epoch 30 Train Loss: -0.9307903850779814, Val Loss: -0.4613390266895294\n",
      "Window 3 Epoch 40 Train Loss: -0.8339571790134206, Val Loss: -0.5374802947044373\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0048315766278435, Val Loss: 0.8420568108558655\n",
      "Window 4 Epoch 10 Train Loss: -0.7911987604814418, Val Loss: -0.8073861598968506\n",
      "Window 4 Epoch 20 Train Loss: -0.8247218805200913, Val Loss: -0.8501957058906555\n",
      "Window 4 Epoch 30 Train Loss: -0.8325442737691543, Val Loss: -0.8486625552177429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:04,856] Trial 41 finished with value: -0.7440888065099717 and parameters: {'lstm_hidden_layer_size': 12, 'mlp_hidden_dim': 5, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.8322153279360602, Val Loss: -0.8530811667442322\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0696753724883585, Val Loss: 0.9295225739479065\n",
      "Window 0 Epoch 10 Train Loss: -0.6471385185858782, Val Loss: -1.0459715127944946\n",
      "Window 0 Epoch 20 Train Loss: -0.7465239968019374, Val Loss: -1.0927037000656128\n",
      "Window 0 Epoch 30 Train Loss: -0.7417370249243344, Val Loss: -1.0111076831817627\n",
      "Window 0 Epoch 40 Train Loss: -0.7952050437646754, Val Loss: -1.0509434938430786\n",
      "Window 1 Epoch 0 Train Loss: 1.3857011117654687, Val Loss: 1.0245087146759033\n",
      "Window 1 Epoch 10 Train Loss: 0.11597971804001753, Val Loss: -0.3605146110057831\n",
      "Window 1 Epoch 20 Train Loss: -0.23827795575646793, Val Loss: -0.42036113142967224\n",
      "Window 1 Epoch 30 Train Loss: -0.769857386561001, Val Loss: -0.719910204410553\n",
      "Window 1 Epoch 40 Train Loss: -0.7905953461983625, Val Loss: -0.6915476322174072\n",
      "Window 2 Epoch 0 Train Loss: 0.960441643630757, Val Loss: 0.6701810956001282\n",
      "Window 2 Epoch 10 Train Loss: -0.7341539361196405, Val Loss: -0.8516466021537781\n",
      "Window 2 Epoch 20 Train Loss: -0.7985995291261112, Val Loss: -0.8924019932746887\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.9102057923990138, Val Loss: 0.5464879870414734\n",
      "Window 3 Epoch 10 Train Loss: -0.8077762218082652, Val Loss: -0.5727818608283997\n",
      "Window 3 Epoch 20 Train Loss: -0.8755736233206356, Val Loss: -0.4842492640018463\n",
      "Window 3 Epoch 30 Train Loss: -0.934845177005319, Val Loss: -0.5724826455116272\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 2.255994577407837, Val Loss: 0.9031588435173035\n",
      "Window 4 Epoch 10 Train Loss: 0.08939215717070242, Val Loss: -0.07534552365541458\n",
      "Window 4 Epoch 20 Train Loss: 3.343849191385157, Val Loss: 0.504277229309082\n",
      "Window 4 Epoch 30 Train Loss: 0.13049941918429206, Val Loss: -0.5197239518165588\n",
      "Window 4 Epoch 40 Train Loss: -0.86216609842637, Val Loss: -0.721998393535614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:09,797] Trial 42 finished with value: -0.2097220675647259 and parameters: {'lstm_hidden_layer_size': 28, 'mlp_hidden_dim': 5, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.7243641926260556, Val Loss: 0.9469702243804932\n",
      "Window 0 Epoch 10 Train Loss: 0.10357355054687051, Val Loss: -0.27773478627204895\n",
      "Window 0 Epoch 20 Train Loss: -0.3205189293973586, Val Loss: -0.8328732848167419\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.3394191309984993, Val Loss: 0.9036663174629211\n",
      "Window 1 Epoch 10 Train Loss: -0.059060126192429487, Val Loss: -0.1832055300474167\n",
      "Window 1 Epoch 20 Train Loss: -0.29367377589730653, Val Loss: -0.5959042310714722\n",
      "Window 1 Epoch 30 Train Loss: -0.5583337392526514, Val Loss: -0.5874912738800049\n",
      "Window 1 Epoch 40 Train Loss: -0.6836125553355498, Val Loss: -0.7141587138175964\n",
      "Window 2 Epoch 0 Train Loss: 1.0092448683346018, Val Loss: 0.8113067150115967\n",
      "Window 2 Epoch 10 Train Loss: 0.3243071619552724, Val Loss: 0.06330262869596481\n",
      "Window 2 Epoch 20 Train Loss: -0.6658714266033734, Val Loss: -0.96201491355896\n",
      "Window 2 Epoch 30 Train Loss: -0.585559479489046, Val Loss: -0.8493649959564209\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.9298221454900853, Val Loss: 0.6112369298934937\n",
      "Window 3 Epoch 10 Train Loss: -0.838576338150922, Val Loss: -0.6314043998718262\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0758925412682927, Val Loss: 0.676683247089386\n",
      "Window 4 Epoch 10 Train Loss: -0.14697415954926435, Val Loss: -0.3898584842681885\n",
      "Window 4 Epoch 20 Train Loss: -0.7302225564507877, Val Loss: -0.6109990477561951\n",
      "Window 4 Epoch 30 Train Loss: -0.7567676238452687, Val Loss: -0.5283135771751404\n",
      "Window 4 Epoch 40 Train Loss: -1.0050594688864316, Val Loss: -0.6890333294868469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:14,637] Trial 43 finished with value: -0.5188407512754202 and parameters: {'lstm_hidden_layer_size': 41, 'mlp_hidden_dim': 11, 'learning_rate': 0.01, 'dropout': 0.35, 'batch_size': 128, 'num_gaussians': 9, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.100833288641537, Val Loss: 1.5793336629867554\n",
      "Window 0 Epoch 10 Train Loss: 2.0894277081770056, Val Loss: 1.5787626504898071\n",
      "Window 0 Epoch 20 Train Loss: 2.146773642652175, Val Loss: 1.5781817436218262\n",
      "Window 0 Epoch 30 Train Loss: 2.1070598641563865, Val Loss: 1.577619194984436\n",
      "Window 0 Epoch 40 Train Loss: 2.1228323768166937, Val Loss: 1.5770474672317505\n",
      "Window 1 Epoch 0 Train Loss: 1.1496134166156544, Val Loss: 1.1237868070602417\n",
      "Window 1 Epoch 10 Train Loss: 1.1461835448882158, Val Loss: 1.1236424446105957\n",
      "Window 1 Epoch 20 Train Loss: 1.1482931022083058, Val Loss: 1.1234984397888184\n",
      "Window 1 Epoch 30 Train Loss: 1.1461286971148323, Val Loss: 1.1233543157577515\n",
      "Window 1 Epoch 40 Train Loss: 1.1479551391040577, Val Loss: 1.1232101917266846\n",
      "Window 2 Epoch 0 Train Loss: 1.269495139682994, Val Loss: 1.0976654291152954\n",
      "Window 2 Epoch 10 Train Loss: 1.271569507823271, Val Loss: 1.0973988771438599\n",
      "Window 2 Epoch 20 Train Loss: 1.28009947496302, Val Loss: 1.0971330404281616\n",
      "Window 2 Epoch 30 Train Loss: 1.285244063209085, Val Loss: 1.0968667268753052\n",
      "Window 2 Epoch 40 Train Loss: 1.2698998829897712, Val Loss: 1.0965994596481323\n",
      "Window 3 Epoch 0 Train Loss: 1.3986089184704948, Val Loss: 1.0901027917861938\n",
      "Window 3 Epoch 10 Train Loss: 1.3999222564697265, Val Loss: 1.08973228931427\n",
      "Window 3 Epoch 20 Train Loss: 1.3994613439896528, Val Loss: 1.0893627405166626\n",
      "Window 3 Epoch 30 Train Loss: 1.401018196554745, Val Loss: 1.0889917612075806\n",
      "Window 3 Epoch 40 Train Loss: 1.3795183355668013, Val Loss: 1.0886224508285522\n",
      "Window 4 Epoch 0 Train Loss: 1.3735824551301843, Val Loss: 1.0465737581253052\n",
      "Window 4 Epoch 10 Train Loss: 1.3832598475848927, Val Loss: 1.046435832977295\n",
      "Window 4 Epoch 20 Train Loss: 1.3770023388021133, Val Loss: 1.046298861503601\n",
      "Window 4 Epoch 30 Train Loss: 1.4148883516648236, Val Loss: 1.0461620092391968\n",
      "Window 4 Epoch 40 Train Loss: 1.3592348289489746, Val Loss: 1.0460247993469238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:19,257] Trial 44 finished with value: 1.046237211227417 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 8, 'learning_rate': 1e-06, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.9361259192578932, Val Loss: 0.9942342638969421\n",
      "Window 0 Epoch 10 Train Loss: -0.36982248839210063, Val Loss: -0.5070230861504873\n",
      "Window 0 Epoch 20 Train Loss: -0.6000898400474998, Val Loss: -1.0004332462946575\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.7421546264255748, Val Loss: 0.6938627560933431\n",
      "Window 1 Epoch 10 Train Loss: -0.24749306762919707, Val Loss: -0.47504866123199463\n",
      "Window 1 Epoch 20 Train Loss: -0.3706726933928097, Val Loss: -0.6289530992507935\n",
      "Window 1 Epoch 30 Train Loss: -0.4089603347638074, Val Loss: -0.47439711292584735\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.34632067294681773, Val Loss: -0.5046584804852804\n",
      "Window 2 Epoch 10 Train Loss: -0.6177319809969734, Val Loss: -0.626203586657842\n",
      "Window 2 Epoch 20 Train Loss: -0.5824709432615953, Val Loss: -0.8531036575635275\n",
      "Window 2 Epoch 30 Train Loss: -0.5612087972725139, Val Loss: -0.8018079996109009\n",
      "Window 2 Epoch 40 Train Loss: -0.6442008638398393, Val Loss: -0.9627303679784139\n",
      "Window 3 Epoch 0 Train Loss: 1.6061869921403773, Val Loss: 0.6711444060007731\n",
      "Window 3 Epoch 10 Train Loss: -0.14174935754607706, Val Loss: -0.5170851945877075\n",
      "Window 3 Epoch 20 Train Loss: 0.42554080598494587, Val Loss: -0.29204415281613666\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.42472431694760043, Val Loss: 0.46475692590077716\n",
      "Window 4 Epoch 10 Train Loss: -0.5872541758593391, Val Loss: -0.5675415595372518\n",
      "Window 4 Epoch 20 Train Loss: -0.8422249894983628, Val Loss: -0.7598924040794373\n",
      "Window 4 Epoch 30 Train Loss: -0.7858459335214951, Val Loss: -0.3258163531621297\n",
      "Window 4 Epoch 40 Train Loss: -0.9791979290457333, Val Loss: -0.6902735332647959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:29,826] Trial 45 finished with value: -0.4347686370213828 and parameters: {'lstm_hidden_layer_size': 26, 'mlp_hidden_dim': 5, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 32, 'num_gaussians': 6, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.333317886240342, Val Loss: 1.2142499685287476\n",
      "Window 0 Epoch 10 Train Loss: 2.15513689882615, Val Loss: 1.2032233476638794\n",
      "Window 0 Epoch 20 Train Loss: 2.044759414616753, Val Loss: 1.1925997734069824\n",
      "Window 0 Epoch 30 Train Loss: 2.0945227311639223, Val Loss: 1.1818846464157104\n",
      "Window 0 Epoch 40 Train Loss: 2.0031793005326213, Val Loss: 1.1717075109481812\n",
      "Window 1 Epoch 0 Train Loss: 2.229485055138083, Val Loss: 1.1362459659576416\n",
      "Window 1 Epoch 10 Train Loss: 2.1418844113630406, Val Loss: 1.1280847787857056\n",
      "Window 1 Epoch 20 Train Loss: 2.0034849643707275, Val Loss: 1.119998574256897\n",
      "Window 1 Epoch 30 Train Loss: 1.9552439484876745, Val Loss: 1.111588716506958\n",
      "Window 1 Epoch 40 Train Loss: 1.8060325473897598, Val Loss: 1.1034876108169556\n",
      "Window 2 Epoch 0 Train Loss: 2.811560160973493, Val Loss: 1.2967727184295654\n",
      "Window 2 Epoch 10 Train Loss: 2.6953992809968836, Val Loss: 1.2834638357162476\n",
      "Window 2 Epoch 20 Train Loss: 2.6773975720125085, Val Loss: 1.270071268081665\n",
      "Window 2 Epoch 30 Train Loss: 2.4484468962164487, Val Loss: 1.2572675943374634\n",
      "Window 2 Epoch 40 Train Loss: 2.4288678606818705, Val Loss: 1.2444689273834229\n",
      "Window 3 Epoch 0 Train Loss: 1.7556127865174238, Val Loss: 1.0963844060897827\n",
      "Window 3 Epoch 10 Train Loss: 1.817926083172069, Val Loss: 1.0858112573623657\n",
      "Window 3 Epoch 20 Train Loss: 1.719756589496837, Val Loss: 1.0751935243606567\n",
      "Window 3 Epoch 30 Train Loss: 1.6189210936602425, Val Loss: 1.0647835731506348\n",
      "Window 3 Epoch 40 Train Loss: 1.6471126797619988, Val Loss: 1.0550711154937744\n",
      "Window 4 Epoch 0 Train Loss: 1.0153652243053213, Val Loss: 0.9833806157112122\n",
      "Window 4 Epoch 10 Train Loss: 0.9819169733103584, Val Loss: 0.9784328937530518\n",
      "Window 4 Epoch 20 Train Loss: 0.9658117344800163, Val Loss: 0.9734644889831543\n",
      "Window 4 Epoch 30 Train Loss: 0.940289162046769, Val Loss: 0.9683549404144287\n",
      "Window 4 Epoch 40 Train Loss: 0.8968918138391831, Val Loss: 0.9630513191223145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:37,961] Trial 46 finished with value: 0.9710215699672698 and parameters: {'lstm_hidden_layer_size': 77, 'mlp_hidden_dim': 10, 'learning_rate': 1e-05, 'dropout': 0.4, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.6255312024845796, Val Loss: 0.9142130017280579\n",
      "Window 0 Epoch 10 Train Loss: 0.5975730366566602, Val Loss: -0.3563850224018097\n",
      "Window 0 Epoch 20 Train Loss: 0.08885176181793213, Val Loss: -0.5593767762184143\n",
      "Window 0 Epoch 30 Train Loss: -0.34567191825193516, Val Loss: -0.7860345840454102\n",
      "Window 0 Epoch 40 Train Loss: -0.6572427755243638, Val Loss: -1.0086902379989624\n",
      "Window 1 Epoch 0 Train Loss: 1.4084458004727083, Val Loss: 0.7205517888069153\n",
      "Window 1 Epoch 10 Train Loss: 0.38725764393806456, Val Loss: -0.26333609223365784\n",
      "Window 1 Epoch 20 Train Loss: -0.3351326830246869, Val Loss: -0.619374692440033\n",
      "Window 1 Epoch 30 Train Loss: -0.652281491616193, Val Loss: -0.7014567255973816\n",
      "Window 1 Epoch 40 Train Loss: -0.7655966528724222, Val Loss: -0.6142621636390686\n",
      "Window 2 Epoch 0 Train Loss: 0.8690852048817803, Val Loss: 0.7098255753517151\n",
      "Window 2 Epoch 10 Train Loss: -0.41899777607006183, Val Loss: -0.8038216233253479\n",
      "Window 2 Epoch 20 Train Loss: -0.5325586955687579, Val Loss: -0.4702252149581909\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.3805425423734328, Val Loss: 0.5719951391220093\n",
      "Window 3 Epoch 10 Train Loss: 0.32973343638812797, Val Loss: -0.5937667489051819\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.2541068462764515, Val Loss: 0.7072124481201172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:43,188] Trial 47 finished with value: -0.3472837177105248 and parameters: {'lstm_hidden_layer_size': 58, 'mlp_hidden_dim': 8, 'learning_rate': 0.01, 'dropout': 0.3, 'batch_size': 128, 'num_gaussians': 10, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 10 Train Loss: 0.479089521520278, Val Loss: -0.54567551612854\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2758790871676278, Val Loss: 0.9351435303688049\n",
      "Window 0 Epoch 10 Train Loss: -0.33585740201613484, Val Loss: -0.662132203578949\n",
      "Window 0 Epoch 20 Train Loss: -0.5412929518082562, Val Loss: -0.8905432820320129\n",
      "Window 0 Epoch 30 Train Loss: -0.737446403503418, Val Loss: -0.9772353768348694\n",
      "Window 0 Epoch 40 Train Loss: -0.7345223118277157, Val Loss: -0.9714711308479309\n",
      "Window 1 Epoch 0 Train Loss: 1.2297682668181027, Val Loss: 0.6749842762947083\n",
      "Window 1 Epoch 10 Train Loss: 1.0480290557005827, Val Loss: 0.14011113345623016\n",
      "Window 1 Epoch 20 Train Loss: -0.5249917755407446, Val Loss: -0.5707947611808777\n",
      "Window 1 Epoch 30 Train Loss: -0.6532542040768792, Val Loss: -0.582746148109436\n",
      "Window 1 Epoch 40 Train Loss: -0.7112209577420179, Val Loss: -0.6587857604026794\n",
      "Window 2 Epoch 0 Train Loss: 1.0936668829356924, Val Loss: 0.7277896404266357\n",
      "Window 2 Epoch 10 Train Loss: -0.09741533209295834, Val Loss: -0.39648863673210144\n",
      "Window 2 Epoch 20 Train Loss: -0.6054019819988924, Val Loss: -0.7849342226982117\n",
      "Window 2 Epoch 30 Train Loss: -0.5623448573841768, Val Loss: -0.8226444721221924\n",
      "Window 2 Epoch 40 Train Loss: -0.6823159094417797, Val Loss: -0.7652650475502014\n",
      "Window 3 Epoch 0 Train Loss: 0.9655522117895239, Val Loss: 0.6487020254135132\n",
      "Window 3 Epoch 10 Train Loss: -0.327939049356124, Val Loss: -0.3643686771392822\n",
      "Window 3 Epoch 20 Train Loss: -0.7707272797472337, Val Loss: -0.5573988556861877\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.9484755750263438, Val Loss: 0.8052652478218079\n",
      "Window 4 Epoch 10 Train Loss: -0.21933086542522207, Val Loss: -0.5019811391830444\n",
      "Window 4 Epoch 20 Train Loss: -0.7488875171717475, Val Loss: -0.6874684691429138\n",
      "Window 4 Epoch 30 Train Loss: -0.9335266068402459, Val Loss: -0.7139391303062439\n",
      "Window 4 Epoch 40 Train Loss: -0.9004235685572904, Val Loss: -0.6662926077842712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:49,087] Trial 48 finished with value: -0.5476055146753788 and parameters: {'lstm_hidden_layer_size': 39, 'mlp_hidden_dim': 17, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 10}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.0337221426122327, Val Loss: 1.4769123792648315\n",
      "Window 0 Epoch 10 Train Loss: 2.0569824706806856, Val Loss: 1.4759217500686646\n",
      "Window 0 Epoch 20 Train Loss: 2.0126204386879416, Val Loss: 1.4749301671981812\n",
      "Window 0 Epoch 30 Train Loss: 1.987791751132292, Val Loss: 1.4739446640014648\n",
      "Window 0 Epoch 40 Train Loss: 2.0366338166068583, Val Loss: 1.472945213317871\n",
      "Window 1 Epoch 0 Train Loss: 1.3437013637318331, Val Loss: 1.0747798681259155\n",
      "Window 1 Epoch 10 Train Loss: 1.302385615461013, Val Loss: 1.07452392578125\n",
      "Window 1 Epoch 20 Train Loss: 1.3279384444741642, Val Loss: 1.0742679834365845\n",
      "Window 1 Epoch 30 Train Loss: 1.326862213190864, Val Loss: 1.0740138292312622\n",
      "Window 1 Epoch 40 Train Loss: 1.3411950408711153, Val Loss: 1.0737577676773071\n",
      "Window 2 Epoch 0 Train Loss: 1.7620802175297456, Val Loss: 1.2230606079101562\n",
      "Window 2 Epoch 10 Train Loss: 1.7643991964003618, Val Loss: 1.222511649131775\n",
      "Window 2 Epoch 20 Train Loss: 1.7235862535588882, Val Loss: 1.2219626903533936\n",
      "Window 2 Epoch 30 Train Loss: 1.764864588064306, Val Loss: 1.221413254737854\n",
      "Window 2 Epoch 40 Train Loss: 1.7719943371941063, Val Loss: 1.220860242843628\n",
      "Window 3 Epoch 0 Train Loss: 1.7171492882335888, Val Loss: 1.093741774559021\n",
      "Window 3 Epoch 10 Train Loss: 1.689538974200978, Val Loss: 1.0934613943099976\n",
      "Window 3 Epoch 20 Train Loss: 1.6987488093095666, Val Loss: 1.0931851863861084\n",
      "Window 3 Epoch 30 Train Loss: 1.7048789849000818, Val Loss: 1.0929023027420044\n",
      "Window 3 Epoch 40 Train Loss: 1.6849795240514418, Val Loss: 1.0926213264465332\n",
      "Window 4 Epoch 0 Train Loss: 1.9776991933934829, Val Loss: 1.1403182744979858\n",
      "Window 4 Epoch 10 Train Loss: 1.9281325550640331, Val Loss: 1.1399036645889282\n",
      "Window 4 Epoch 20 Train Loss: 1.9382527648701386, Val Loss: 1.13950777053833\n",
      "Window 4 Epoch 30 Train Loss: 1.8865064912683824, Val Loss: 1.1390641927719116\n",
      "Window 4 Epoch 40 Train Loss: 1.9487108707427978, Val Loss: 1.1386429071426392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:06:53,682] Trial 49 finished with value: 1.1392963171005248 and parameters: {'lstm_hidden_layer_size': 21, 'mlp_hidden_dim': 5, 'learning_rate': 1e-06, 'dropout': 0.45, 'batch_size': 128, 'num_gaussians': 8, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2349627284442677, Val Loss: 1.1154129107793171\n",
      "Window 0 Epoch 10 Train Loss: 0.5800605330747717, Val Loss: 0.9217923680941263\n",
      "Window 0 Epoch 20 Train Loss: 0.25930353865903966, Val Loss: 0.699129561583201\n",
      "Window 0 Epoch 30 Train Loss: -0.02754685212584103, Val Loss: 0.33002322912216187\n",
      "Window 0 Epoch 40 Train Loss: -0.31048956499380226, Val Loss: -0.29213209946950275\n",
      "Window 1 Epoch 0 Train Loss: 1.682831870247336, Val Loss: 1.295565128326416\n",
      "Window 1 Epoch 10 Train Loss: 0.7645768387177411, Val Loss: 0.9429110487302145\n",
      "Window 1 Epoch 20 Train Loss: 0.3673538925367243, Val Loss: 0.6628370483716329\n",
      "Window 1 Epoch 30 Train Loss: 0.12999238992438597, Val Loss: 0.35571936269601184\n",
      "Window 1 Epoch 40 Train Loss: -0.12759981309666354, Val Loss: -0.007522786657015483\n",
      "Window 2 Epoch 0 Train Loss: 1.6041239746879128, Val Loss: 1.1002727349599202\n",
      "Window 2 Epoch 10 Train Loss: 0.6187456529280718, Val Loss: 0.9696126381556193\n",
      "Window 2 Epoch 20 Train Loss: 0.3079397566178266, Val Loss: 0.8224412202835083\n",
      "Window 2 Epoch 30 Train Loss: 0.08928607211393469, Val Loss: 0.6215193271636963\n",
      "Window 2 Epoch 40 Train Loss: -0.10716455326360814, Val Loss: 0.3476719657580058\n",
      "Window 3 Epoch 0 Train Loss: 2.112850493262796, Val Loss: 0.9114013314247131\n",
      "Window 3 Epoch 10 Train Loss: 0.9213292151338914, Val Loss: 0.7887960076332092\n",
      "Window 3 Epoch 20 Train Loss: 0.5251868787933799, Val Loss: 0.6682777404785156\n",
      "Window 3 Epoch 30 Train Loss: 0.28010240681031173, Val Loss: 0.5324636896451315\n",
      "Window 3 Epoch 40 Train Loss: 0.17417289965292987, Val Loss: 0.4042813877264659\n",
      "Window 4 Epoch 0 Train Loss: 1.885419386695413, Val Loss: 1.1325006484985352\n",
      "Window 4 Epoch 10 Train Loss: 1.214245948230519, Val Loss: 0.9790376822153727\n",
      "Window 4 Epoch 20 Train Loss: 0.8168790389509762, Val Loss: 0.8330059846242269\n",
      "Window 4 Epoch 30 Train Loss: 0.5916166214381947, Val Loss: 0.7197580138842264\n",
      "Window 4 Epoch 40 Train Loss: 0.42619758037959826, Val Loss: 0.5945631464322408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:10,331] Trial 50 finished with value: 0.7874540617068608 and parameters: {'lstm_hidden_layer_size': 51, 'mlp_hidden_dim': 10, 'learning_rate': 0.0001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 9, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0608812033428865, Val Loss: 0.8501335978507996\n",
      "Window 0 Epoch 10 Train Loss: -0.5133287987989538, Val Loss: -0.8405501842498779\n",
      "Window 0 Epoch 20 Train Loss: -0.7252314413295072, Val Loss: -1.0114755630493164\n",
      "Window 0 Epoch 30 Train Loss: -0.7907511750389548, Val Loss: -1.0115829706192017\n",
      "Window 0 Epoch 40 Train Loss: -0.7699449867360733, Val Loss: -0.9573369026184082\n",
      "Window 1 Epoch 0 Train Loss: 1.2236329308678122, Val Loss: 1.0514906644821167\n",
      "Window 1 Epoch 10 Train Loss: -0.10619605807697072, Val Loss: -0.47271665930747986\n",
      "Window 1 Epoch 20 Train Loss: -0.7275942571022931, Val Loss: -0.729302167892456\n",
      "Window 1 Epoch 30 Train Loss: -0.7576594285403981, Val Loss: -0.722585141658783\n",
      "Window 1 Epoch 40 Train Loss: -0.7576517681514515, Val Loss: -0.6786608099937439\n",
      "Window 2 Epoch 0 Train Loss: 1.413228841529173, Val Loss: 0.8773276209831238\n",
      "Window 2 Epoch 10 Train Loss: -0.7022548102631289, Val Loss: -0.7490879893302917\n",
      "Window 2 Epoch 20 Train Loss: -0.721451896499185, Val Loss: -0.6600289344787598\n",
      "Window 2 Epoch 30 Train Loss: -0.8117471522443435, Val Loss: -0.890226423740387\n",
      "Window 2 Epoch 40 Train Loss: -0.8570280197087456, Val Loss: -0.9656731486320496\n",
      "Window 3 Epoch 0 Train Loss: 0.991252658367157, Val Loss: 0.7874970436096191\n",
      "Window 3 Epoch 10 Train Loss: -0.8334444656091577, Val Loss: -0.44884276390075684\n",
      "Window 3 Epoch 20 Train Loss: -0.9081857929510229, Val Loss: -0.5136578679084778\n",
      "Window 3 Epoch 30 Train Loss: -0.9428968568409191, Val Loss: -0.6083555221557617\n",
      "Window 3 Epoch 40 Train Loss: -0.9625104494655834, Val Loss: -0.5823614001274109\n",
      "Window 4 Epoch 0 Train Loss: 1.058758288972518, Val Loss: 0.7052740454673767\n",
      "Window 4 Epoch 10 Train Loss: -0.7486418808207792, Val Loss: -0.7599367499351501\n",
      "Window 4 Epoch 20 Train Loss: -0.9234424950094784, Val Loss: -0.714019238948822\n",
      "Window 4 Epoch 30 Train Loss: -0.9513757276535034, Val Loss: -0.6682889461517334\n",
      "Window 4 Epoch 40 Train Loss: -0.9698764618705301, Val Loss: -0.6653310656547546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:14,924] Trial 51 finished with value: -0.6146488663554192 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0606792211532592, Val Loss: 0.9874520301818848\n",
      "Window 0 Epoch 10 Train Loss: -0.5756676366749932, Val Loss: -0.938894510269165\n",
      "Window 0 Epoch 20 Train Loss: -0.6871844469799715, Val Loss: -1.030082106590271\n",
      "Window 0 Epoch 30 Train Loss: -0.7418301736607271, Val Loss: -1.0176175832748413\n",
      "Window 0 Epoch 40 Train Loss: -0.7517195301897386, Val Loss: -1.0523219108581543\n",
      "Window 1 Epoch 0 Train Loss: 0.7488123460376964, Val Loss: 0.9024353623390198\n",
      "Window 1 Epoch 10 Train Loss: -0.2086719524159151, Val Loss: -0.40196314454078674\n",
      "Window 1 Epoch 20 Train Loss: -0.6789081261438482, Val Loss: -0.6338737607002258\n",
      "Window 1 Epoch 30 Train Loss: -0.4279221353811376, Val Loss: -0.5689520239830017\n",
      "Window 1 Epoch 40 Train Loss: -0.8837864246087915, Val Loss: -0.7816805243492126\n",
      "Window 2 Epoch 0 Train Loss: 1.77751003854415, Val Loss: 1.0669327974319458\n",
      "Window 2 Epoch 10 Train Loss: -0.007402652291690602, Val Loss: -0.643155038356781\n",
      "Window 2 Epoch 20 Train Loss: -0.746036065045525, Val Loss: -0.962225615978241\n",
      "Window 2 Epoch 30 Train Loss: -0.7764620635088753, Val Loss: -0.7174821496009827\n",
      "Window 2 Epoch 40 Train Loss: -0.8545247449594385, Val Loss: -0.9188178181648254\n",
      "Window 3 Epoch 0 Train Loss: 1.4478835728589226, Val Loss: 0.7446334958076477\n",
      "Window 3 Epoch 10 Train Loss: -0.5314373295447405, Val Loss: -0.4468717575073242\n",
      "Window 3 Epoch 20 Train Loss: -0.4829967110297259, Val Loss: -0.21473269164562225\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0457034422369564, Val Loss: 0.769010066986084\n",
      "Window 4 Epoch 10 Train Loss: -0.791822017361136, Val Loss: -0.5780409574508667\n",
      "Window 4 Epoch 20 Train Loss: -0.9105262722688563, Val Loss: -0.7439163327217102\n",
      "Window 4 Epoch 30 Train Loss: -0.9391586903964771, Val Loss: -0.7603400349617004\n",
      "Window 4 Epoch 40 Train Loss: -0.9162441915624282, Val Loss: -0.6599498391151428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:18,697] Trial 52 finished with value: -0.6414887627959251 and parameters: {'lstm_hidden_layer_size': 11, 'mlp_hidden_dim': 4, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0313021665460924, Val Loss: 0.8001806735992432\n",
      "Window 0 Epoch 10 Train Loss: -0.69254426984226, Val Loss: -1.0576696395874023\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.211173959900351, Val Loss: 0.9626172184944153\n",
      "Window 1 Epoch 10 Train Loss: -0.3525545201582067, Val Loss: -0.6205202341079712\n",
      "Window 1 Epoch 20 Train Loss: -0.7634580976822797, Val Loss: -0.7056312561035156\n",
      "Window 1 Epoch 30 Train Loss: -0.611580253348631, Val Loss: -0.6600714325904846\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.9664938967368182, Val Loss: 0.8316510319709778\n",
      "Window 2 Epoch 10 Train Loss: 0.05296097217237248, Val Loss: -0.0993959978222847\n",
      "Window 2 Epoch 20 Train Loss: -0.7318350510036244, Val Loss: -0.8844599723815918\n",
      "Window 2 Epoch 30 Train Loss: -0.81751744705088, Val Loss: -0.9376725554466248\n",
      "Window 2 Epoch 40 Train Loss: -0.831317039938534, Val Loss: -0.9076361656188965\n",
      "Window 3 Epoch 0 Train Loss: 0.8845239815992467, Val Loss: 0.7383034229278564\n",
      "Window 3 Epoch 10 Train Loss: -0.653055149527157, Val Loss: -0.41833338141441345\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.3547265644634472, Val Loss: 0.6411628723144531\n",
      "Window 4 Epoch 10 Train Loss: 0.11867850126589045, Val Loss: -0.002751227468252182\n",
      "Window 4 Epoch 20 Train Loss: -0.604777903136085, Val Loss: -0.7710177898406982\n",
      "Window 4 Epoch 30 Train Loss: -0.9128408056146958, Val Loss: -0.6674759984016418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:21,720] Trial 53 finished with value: -0.40849416099488733 and parameters: {'lstm_hidden_layer_size': 13, 'mlp_hidden_dim': 4, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.994994646801668, Val Loss: -0.7512731552124023\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.351446065341725, Val Loss: 1.2610188722610474\n",
      "Window 0 Epoch 10 Train Loss: 1.037758987090167, Val Loss: 1.1677640676498413\n",
      "Window 0 Epoch 20 Train Loss: 0.8282986985935884, Val Loss: 1.0803900957107544\n",
      "Window 0 Epoch 30 Train Loss: 0.5869401780998006, Val Loss: 0.96328204870224\n",
      "Window 0 Epoch 40 Train Loss: 0.3641884190194747, Val Loss: 0.8250975012779236\n",
      "Window 1 Epoch 0 Train Loss: 1.2615528676089118, Val Loss: 1.1520605087280273\n",
      "Window 1 Epoch 10 Train Loss: 1.0576916977938484, Val Loss: 1.0251144170761108\n",
      "Window 1 Epoch 20 Train Loss: 0.8116721273871029, Val Loss: 0.8402745127677917\n",
      "Window 1 Epoch 30 Train Loss: 0.3917953275932985, Val Loss: 0.5238763689994812\n",
      "Window 1 Epoch 40 Train Loss: -0.14477944374084473, Val Loss: 0.009889141656458378\n",
      "Window 2 Epoch 0 Train Loss: 1.0193174360780155, Val Loss: 1.0725834369659424\n",
      "Window 2 Epoch 10 Train Loss: 0.5660225688008701, Val Loss: 0.8744272589683533\n",
      "Window 2 Epoch 20 Train Loss: 0.2609880070300663, Val Loss: 0.6339603066444397\n",
      "Window 2 Epoch 30 Train Loss: -0.07831773151369656, Val Loss: 0.3659783601760864\n",
      "Window 2 Epoch 40 Train Loss: -0.22377954328761382, Val Loss: 0.10173595696687698\n",
      "Window 3 Epoch 0 Train Loss: 1.1055136893777286, Val Loss: 1.074394941329956\n",
      "Window 3 Epoch 10 Train Loss: 0.9085782826648039, Val Loss: 0.9042659401893616\n",
      "Window 3 Epoch 20 Train Loss: 0.6967720019116121, Val Loss: 0.6856783032417297\n",
      "Window 3 Epoch 30 Train Loss: 0.41453638960333433, Val Loss: 0.3542637526988983\n",
      "Window 3 Epoch 40 Train Loss: 0.02470561295747757, Val Loss: -0.06867749243974686\n",
      "Window 4 Epoch 0 Train Loss: 1.3392759830811445, Val Loss: 1.0190811157226562\n",
      "Window 4 Epoch 10 Train Loss: 0.9482523793332717, Val Loss: 0.9214251041412354\n",
      "Window 4 Epoch 20 Train Loss: 0.5824442533885732, Val Loss: 0.7597992420196533\n",
      "Window 4 Epoch 30 Train Loss: 0.21383960685309242, Val Loss: 0.5153897404670715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:24,877] Trial 54 finished with value: 0.5733764422684908 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 6, 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 256, 'num_gaussians': 9, 'patience': 10}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.1610671943426132, Val Loss: 0.16889558732509613\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2317244538138894, Val Loss: 1.2603747844696045\n",
      "Window 0 Epoch 10 Train Loss: 1.2294206846461577, Val Loss: 1.2573152780532837\n",
      "Window 0 Epoch 20 Train Loss: 1.2281577040167415, Val Loss: 1.2542638778686523\n",
      "Window 0 Epoch 30 Train Loss: 1.2206053383210127, Val Loss: 1.2512019872665405\n",
      "Window 0 Epoch 40 Train Loss: 1.2169522624857285, Val Loss: 1.2481592893600464\n",
      "Window 1 Epoch 0 Train Loss: 1.867292664752287, Val Loss: 1.3064664602279663\n",
      "Window 1 Epoch 10 Train Loss: 1.884413303487441, Val Loss: 1.3003753423690796\n",
      "Window 1 Epoch 20 Train Loss: 1.878285142954658, Val Loss: 1.2942572832107544\n",
      "Window 1 Epoch 30 Train Loss: 1.8087474576164695, Val Loss: 1.2882912158966064\n",
      "Window 1 Epoch 40 Train Loss: 1.768135970620548, Val Loss: 1.2826024293899536\n",
      "Window 2 Epoch 0 Train Loss: 1.8252871131896973, Val Loss: 1.1996599435806274\n",
      "Window 2 Epoch 10 Train Loss: 1.8295206269095925, Val Loss: 1.1930283308029175\n",
      "Window 2 Epoch 20 Train Loss: 1.7841413497924805, Val Loss: 1.186734914779663\n",
      "Window 2 Epoch 30 Train Loss: 1.7650690061905805, Val Loss: 1.1806296110153198\n",
      "Window 2 Epoch 40 Train Loss: 1.7307104926950792, Val Loss: 1.1745086908340454\n",
      "Window 3 Epoch 0 Train Loss: 1.3242424776974846, Val Loss: 1.0166248083114624\n",
      "Window 3 Epoch 10 Train Loss: 1.3052769773146686, Val Loss: 1.0116181373596191\n",
      "Window 3 Epoch 20 Train Loss: 1.2839866256713868, Val Loss: 1.0065943002700806\n",
      "Window 3 Epoch 30 Train Loss: 1.2559883779637955, Val Loss: 1.0015124082565308\n",
      "Window 3 Epoch 40 Train Loss: 1.2431251725028543, Val Loss: 0.996381938457489\n",
      "Window 4 Epoch 0 Train Loss: 1.93231097277473, Val Loss: 1.0567026138305664\n",
      "Window 4 Epoch 10 Train Loss: 1.8795260092791388, Val Loss: 1.051659107208252\n",
      "Window 4 Epoch 20 Train Loss: 1.9046003462286556, Val Loss: 1.046523928642273\n",
      "Window 4 Epoch 30 Train Loss: 1.8657887192333447, Val Loss: 1.041372299194336\n",
      "Window 4 Epoch 40 Train Loss: 1.7900893045874202, Val Loss: 1.036126971244812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:31,996] Trial 55 finished with value: 1.0441584277153015 and parameters: {'lstm_hidden_layer_size': 31, 'mlp_hidden_dim': 4, 'learning_rate': 1e-05, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 10, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2199377688239603, Val Loss: 1.0288612842559814\n",
      "Window 0 Epoch 10 Train Loss: -0.39508985610569225, Val Loss: -0.3129884898662567\n",
      "Window 0 Epoch 20 Train Loss: -0.6429619665706859, Val Loss: -1.0734819173812866\n",
      "Window 0 Epoch 30 Train Loss: -0.7489703899271348, Val Loss: -1.0422638654708862\n",
      "Window 0 Epoch 40 Train Loss: -0.7806133383863112, Val Loss: -0.9947323799133301\n",
      "Window 1 Epoch 0 Train Loss: 1.1775759006949031, Val Loss: 0.843730628490448\n",
      "Window 1 Epoch 10 Train Loss: 0.38907559563131894, Val Loss: -0.24630074203014374\n",
      "Window 1 Epoch 20 Train Loss: -0.46235156171462116, Val Loss: -0.6459605693817139\n",
      "Window 1 Epoch 30 Train Loss: -0.7119656738112955, Val Loss: -0.6634323596954346\n",
      "Window 1 Epoch 40 Train Loss: -0.7503967854555915, Val Loss: -0.6756554245948792\n",
      "Window 2 Epoch 0 Train Loss: 1.0847762262119967, Val Loss: 0.635807454586029\n",
      "Window 2 Epoch 10 Train Loss: -0.5939301152790294, Val Loss: -0.7152052521705627\n",
      "Window 2 Epoch 20 Train Loss: -0.7634710638663348, Val Loss: -0.9035969376564026\n",
      "Window 2 Epoch 30 Train Loss: -0.8201127011635724, Val Loss: -0.9935364127159119\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.8781958759532256, Val Loss: 0.6719916462898254\n",
      "Window 3 Epoch 10 Train Loss: 0.5280174799526439, Val Loss: 0.24529875814914703\n",
      "Window 3 Epoch 20 Train Loss: -0.06683692371144015, Val Loss: -0.45459532737731934\n",
      "Window 3 Epoch 30 Train Loss: -0.6372063244090361, Val Loss: -0.45373275876045227\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.2216359947709476, Val Loss: 0.7938159108161926\n",
      "Window 4 Epoch 10 Train Loss: -0.8167115632225486, Val Loss: -0.7152251601219177\n",
      "Window 4 Epoch 20 Train Loss: -0.7652142516304465, Val Loss: -0.766880989074707\n",
      "Window 4 Epoch 30 Train Loss: -1.0019001195010018, Val Loss: -0.7740632891654968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:36,647] Trial 56 finished with value: -0.6469266080856323 and parameters: {'lstm_hidden_layer_size': 23, 'mlp_hidden_dim': 9, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 6, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.8397875055144814, Val Loss: -0.6254920363426208\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1858060114523943, Val Loss: 0.7701039910316467\n",
      "Window 0 Epoch 10 Train Loss: 0.26216669882045074, Val Loss: -0.24962282180786133\n",
      "Window 0 Epoch 20 Train Loss: -0.01843918618033914, Val Loss: -0.7487937808036804\n",
      "Window 0 Epoch 30 Train Loss: -0.40890138682197125, Val Loss: -0.9340094923973083\n",
      "Window 0 Epoch 40 Train Loss: -0.7275399261362412, Val Loss: -1.009604573249817\n",
      "Window 1 Epoch 0 Train Loss: 1.1161781740188599, Val Loss: 0.7748237252235413\n",
      "Window 1 Epoch 10 Train Loss: 0.04049544257276198, Val Loss: -0.34790563583374023\n",
      "Window 1 Epoch 20 Train Loss: -0.5101315872809467, Val Loss: -0.5038312673568726\n",
      "Window 1 Epoch 30 Train Loss: -0.7799295332852532, Val Loss: -0.6253098249435425\n",
      "Window 1 Epoch 40 Train Loss: -0.5317874863568475, Val Loss: -0.6048703789710999\n",
      "Window 2 Epoch 0 Train Loss: 0.9255581831932068, Val Loss: 0.8029565215110779\n",
      "Window 2 Epoch 10 Train Loss: 0.650393575219547, Val Loss: 0.006702010054141283\n",
      "Window 2 Epoch 20 Train Loss: 0.23089363208588431, Val Loss: -0.5335397124290466\n",
      "Window 2 Epoch 30 Train Loss: -0.49390342817587013, Val Loss: -0.6031084060668945\n",
      "Window 2 Epoch 40 Train Loss: -0.6231118132086361, Val Loss: -0.9095309376716614\n",
      "Window 3 Epoch 0 Train Loss: 0.6434829557643217, Val Loss: 0.4744149148464203\n",
      "Window 3 Epoch 10 Train Loss: -0.700944060718312, Val Loss: -0.579973578453064\n",
      "Window 3 Epoch 20 Train Loss: -0.7840456808314604, Val Loss: -0.5861626267433167\n",
      "Window 3 Epoch 30 Train Loss: -0.8193214622665854, Val Loss: -0.37948620319366455\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1206304669380187, Val Loss: 0.6721388697624207\n",
      "Window 4 Epoch 10 Train Loss: -0.32916409871157476, Val Loss: -0.6235470771789551\n",
      "Window 4 Epoch 20 Train Loss: -0.7197673522724825, Val Loss: -0.7625735402107239\n",
      "Window 4 Epoch 30 Train Loss: -0.955253856602837, Val Loss: -0.7589032649993896\n",
      "Window 4 Epoch 40 Train Loss: -0.9642705345153808, Val Loss: -0.7395995259284973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:43,567] Trial 57 finished with value: -0.5749312695860863 and parameters: {'lstm_hidden_layer_size': 40, 'mlp_hidden_dim': 9, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 6, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.147501482963562, Val Loss: 0.9075584411621094\n",
      "Window 0 Epoch 10 Train Loss: -0.6758266851481269, Val Loss: -0.8889668583869934\n",
      "Window 0 Epoch 20 Train Loss: -0.7273737304350909, Val Loss: -1.0103530883789062\n",
      "Window 0 Epoch 30 Train Loss: -0.8154197806470534, Val Loss: -1.0610142946243286\n",
      "Window 0 Epoch 40 Train Loss: -0.7977444256053251, Val Loss: -1.098158836364746\n",
      "Window 1 Epoch 0 Train Loss: 1.29543394018622, Val Loss: 0.8723292350769043\n",
      "Window 1 Epoch 10 Train Loss: -0.31077810967669767, Val Loss: -0.3448622524738312\n",
      "Window 1 Epoch 20 Train Loss: -0.6803188445988824, Val Loss: -0.6277427077293396\n",
      "Window 1 Epoch 30 Train Loss: -0.6646591392685385, Val Loss: -0.7045537829399109\n",
      "Window 1 Epoch 40 Train Loss: -0.5738246059417724, Val Loss: -0.6051158905029297\n",
      "Window 2 Epoch 0 Train Loss: 1.167145636362188, Val Loss: 0.875365674495697\n",
      "Window 2 Epoch 10 Train Loss: 0.07042250833090614, Val Loss: 0.030638201162219048\n",
      "Window 2 Epoch 20 Train Loss: -0.5780734563575072, Val Loss: -0.7840674519538879\n",
      "Window 2 Epoch 30 Train Loss: -0.7814839809081133, Val Loss: -0.9703381061553955\n",
      "Window 2 Epoch 40 Train Loss: -0.8072703376938315, Val Loss: -0.943612277507782\n",
      "Window 3 Epoch 0 Train Loss: 1.23700263486189, Val Loss: 0.815331757068634\n",
      "Window 3 Epoch 10 Train Loss: -0.2254912909339456, Val Loss: -0.2489926815032959\n",
      "Window 3 Epoch 20 Train Loss: -0.8133446755128748, Val Loss: -0.5175752639770508\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.9194284649456248, Val Loss: 0.5763102173805237\n",
      "Window 4 Epoch 10 Train Loss: -0.5111307602770189, Val Loss: -0.5434772372245789\n",
      "Window 4 Epoch 20 Train Loss: -0.9277886805814856, Val Loss: -0.7522115111351013\n",
      "Window 4 Epoch 30 Train Loss: -0.8411459607236526, Val Loss: -0.5625513195991516\n",
      "Window 4 Epoch 40 Train Loss: -0.994664241285885, Val Loss: -0.7440449595451355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:47,587] Trial 58 finished with value: -0.5898615220934152 and parameters: {'lstm_hidden_layer_size': 21, 'mlp_hidden_dim': 19, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.9301487630956313, Val Loss: 1.463988184928894\n",
      "Window 0 Epoch 10 Train Loss: 1.6351231992945952, Val Loss: 1.38678777217865\n",
      "Window 0 Epoch 20 Train Loss: 1.4505138994665707, Val Loss: 1.318557858467102\n",
      "Window 0 Epoch 30 Train Loss: 1.2341541222965016, Val Loss: 1.253551959991455\n",
      "Window 0 Epoch 40 Train Loss: 1.0432324454363655, Val Loss: 1.1883013248443604\n",
      "Window 1 Epoch 0 Train Loss: 1.3799805789835313, Val Loss: 1.1726564168930054\n",
      "Window 1 Epoch 10 Train Loss: 1.1741914423774271, Val Loss: 1.0985060930252075\n",
      "Window 1 Epoch 20 Train Loss: 1.0129002840378705, Val Loss: 1.023992896080017\n",
      "Window 1 Epoch 30 Train Loss: 0.9021051004353692, Val Loss: 0.9438212513923645\n",
      "Window 1 Epoch 40 Train Loss: 0.7787930863043842, Val Loss: 0.852275550365448\n",
      "Window 2 Epoch 0 Train Loss: 1.2005332357743208, Val Loss: 1.067999243736267\n",
      "Window 2 Epoch 10 Train Loss: 0.9028201103210449, Val Loss: 1.0198074579238892\n",
      "Window 2 Epoch 20 Train Loss: 0.8010478639602661, Val Loss: 0.9696247577667236\n",
      "Window 2 Epoch 30 Train Loss: 0.7151173243803136, Val Loss: 0.9220773577690125\n",
      "Window 2 Epoch 40 Train Loss: 0.6215820751470678, Val Loss: 0.8704831004142761\n",
      "Window 3 Epoch 0 Train Loss: 1.4758539772033692, Val Loss: 1.0615919828414917\n",
      "Window 3 Epoch 10 Train Loss: 1.220744220789741, Val Loss: 1.0271819829940796\n",
      "Window 3 Epoch 20 Train Loss: 1.0517469539361841, Val Loss: 0.9819615483283997\n",
      "Window 3 Epoch 30 Train Loss: 0.8804150408857009, Val Loss: 0.9220648407936096\n",
      "Window 3 Epoch 40 Train Loss: 0.685889165541705, Val Loss: 0.8499789237976074\n",
      "Window 4 Epoch 0 Train Loss: 1.164964200188132, Val Loss: 1.1064335107803345\n",
      "Window 4 Epoch 10 Train Loss: 0.9548423750260296, Val Loss: 1.0446385145187378\n",
      "Window 4 Epoch 20 Train Loss: 0.7950898387852837, Val Loss: 0.9870271682739258\n",
      "Window 4 Epoch 30 Train Loss: 0.7150688181203955, Val Loss: 0.9319556355476379\n",
      "Window 4 Epoch 40 Train Loss: 0.5961015611536362, Val Loss: 0.8755862712860107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:53,917] Trial 59 finished with value: 0.9633248794078827 and parameters: {'lstm_hidden_layer_size': 35, 'mlp_hidden_dim': 22, 'learning_rate': 0.0001, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 5, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2816494790245505, Val Loss: 1.1906509399414062\n",
      "Window 0 Epoch 10 Train Loss: 0.7740423951429479, Val Loss: 1.021178126335144\n",
      "Window 0 Epoch 20 Train Loss: 0.43689629786154804, Val Loss: 0.8377644419670105\n",
      "Window 0 Epoch 30 Train Loss: 0.19022725035162533, Val Loss: 0.5304906964302063\n",
      "Window 0 Epoch 40 Train Loss: -0.1360009341730791, Val Loss: 0.10953065752983093\n",
      "Window 1 Epoch 0 Train Loss: 1.92769897517036, Val Loss: 1.157670259475708\n",
      "Window 1 Epoch 10 Train Loss: 1.0403122124952429, Val Loss: 0.9303632378578186\n",
      "Window 1 Epoch 20 Train Loss: 0.43794600143152124, Val Loss: 0.5680293440818787\n",
      "Window 1 Epoch 30 Train Loss: -0.2509580932645237, Val Loss: -0.18210166692733765\n",
      "Window 1 Epoch 40 Train Loss: -0.5314696349817164, Val Loss: -0.4177519381046295\n",
      "Window 2 Epoch 0 Train Loss: 3.198037250182208, Val Loss: 1.1951295137405396\n",
      "Window 2 Epoch 10 Train Loss: 1.4431669967314775, Val Loss: 1.0373653173446655\n",
      "Window 2 Epoch 20 Train Loss: 0.9670527733073515, Val Loss: 0.8290490508079529\n",
      "Window 2 Epoch 30 Train Loss: 0.4304902317944695, Val Loss: 0.537603497505188\n",
      "Window 2 Epoch 40 Train Loss: 0.10317424972267712, Val Loss: 0.3242253363132477\n",
      "Window 3 Epoch 0 Train Loss: 1.7555658876194673, Val Loss: 1.2238496541976929\n",
      "Window 3 Epoch 10 Train Loss: 0.8779985569505131, Val Loss: 0.9452957510948181\n",
      "Window 3 Epoch 20 Train Loss: 0.2736899517914828, Val Loss: 0.6136074662208557\n",
      "Window 3 Epoch 30 Train Loss: -0.013636495435939115, Val Loss: 0.33285805583000183\n",
      "Window 3 Epoch 40 Train Loss: -0.2969304302159478, Val Loss: -0.06141233444213867\n",
      "Window 4 Epoch 0 Train Loss: 1.008400304036982, Val Loss: 0.9835144877433777\n",
      "Window 4 Epoch 10 Train Loss: 0.5855818122975966, Val Loss: 0.8326110243797302\n",
      "Window 4 Epoch 20 Train Loss: 0.1513037276618621, Val Loss: 0.6137619018554688\n",
      "Window 4 Epoch 30 Train Loss: -0.17601267358836006, Val Loss: 0.29787930846214294\n",
      "Window 4 Epoch 40 Train Loss: -0.4906840895203983, Val Loss: -0.11768905073404312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:07:57,737] Trial 60 finished with value: 0.39843929452821614 and parameters: {'lstm_hidden_layer_size': 24, 'mlp_hidden_dim': 12, 'learning_rate': 0.001, 'dropout': 0.2, 'batch_size': 256, 'num_gaussians': 6, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.25091380035176, Val Loss: 1.0511771440505981\n",
      "Window 0 Epoch 10 Train Loss: 0.26192081198972816, Val Loss: -0.310442179441452\n",
      "Window 0 Epoch 20 Train Loss: -0.6005343372681562, Val Loss: -1.0067057609558105\n",
      "Window 0 Epoch 30 Train Loss: -0.7511273552389706, Val Loss: -1.1073318719863892\n",
      "Window 0 Epoch 40 Train Loss: -0.6618066580155316, Val Loss: -1.0017880201339722\n",
      "Window 1 Epoch 0 Train Loss: 0.9233087183447445, Val Loss: 0.7539026141166687\n",
      "Window 1 Epoch 10 Train Loss: 0.5114745091866044, Val Loss: 0.3727213442325592\n",
      "Window 1 Epoch 20 Train Loss: 0.5975895626404706, Val Loss: -0.3469906747341156\n",
      "Window 1 Epoch 30 Train Loss: -0.5092891425244949, Val Loss: -0.6700728535652161\n",
      "Window 1 Epoch 40 Train Loss: -0.7744419243756463, Val Loss: -0.6954333782196045\n",
      "Window 2 Epoch 0 Train Loss: 1.37245553521549, Val Loss: 0.8967554569244385\n",
      "Window 2 Epoch 10 Train Loss: 0.04707798586172216, Val Loss: -0.5102107524871826\n",
      "Window 2 Epoch 20 Train Loss: -0.6579152551819296, Val Loss: -0.9084150195121765\n",
      "Window 2 Epoch 30 Train Loss: -0.7683841968985164, Val Loss: -0.8964845538139343\n",
      "Window 2 Epoch 40 Train Loss: -0.8512597227096558, Val Loss: -0.9772374629974365\n",
      "Window 3 Epoch 0 Train Loss: 0.8710579971706166, Val Loss: 0.5546544194221497\n",
      "Window 3 Epoch 10 Train Loss: -0.6691934471971849, Val Loss: -0.22949786484241486\n",
      "Window 3 Epoch 20 Train Loss: -0.8586849609543296, Val Loss: -0.48841702938079834\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.8908963746183058, Val Loss: 0.6348589658737183\n",
      "Window 4 Epoch 10 Train Loss: -0.05465632733176736, Val Loss: -0.42465630173683167\n",
      "Window 4 Epoch 20 Train Loss: -0.8373103551303639, Val Loss: -0.7824791073799133\n",
      "Window 4 Epoch 30 Train Loss: -0.8213788088630227, Val Loss: -0.7803307175636292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:02,087] Trial 61 finished with value: -0.573064811527729 and parameters: {'lstm_hidden_layer_size': 23, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.9489720338933608, Val Loss: -0.740207850933075\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.3692652264763328, Val Loss: 1.069824457168579\n",
      "Window 0 Epoch 10 Train Loss: -0.6598735594749451, Val Loss: -1.0246374607086182\n",
      "Window 0 Epoch 20 Train Loss: -0.7554131886538338, Val Loss: -1.0647727251052856\n",
      "Window 0 Epoch 30 Train Loss: -0.7680113137469572, Val Loss: -1.1474430561065674\n",
      "Window 0 Epoch 40 Train Loss: -0.7919725217538721, Val Loss: -1.0655401945114136\n",
      "Window 1 Epoch 0 Train Loss: 2.1058702738144817, Val Loss: 1.0162858963012695\n",
      "Window 1 Epoch 10 Train Loss: -0.27716235707787906, Val Loss: -0.574200451374054\n",
      "Window 1 Epoch 20 Train Loss: -0.6162997909153209, Val Loss: -0.6809021830558777\n",
      "Window 1 Epoch 30 Train Loss: -0.6640895445206586, Val Loss: -0.6465256810188293\n",
      "Window 1 Epoch 40 Train Loss: -0.6920923223214991, Val Loss: -0.7356385588645935\n",
      "Window 2 Epoch 0 Train Loss: 1.1611665147893568, Val Loss: 0.8508825302124023\n",
      "Window 2 Epoch 10 Train Loss: -0.520190116447561, Val Loss: -0.6307485103607178\n",
      "Window 2 Epoch 20 Train Loss: -0.7714294255481047, Val Loss: -0.8797757625579834\n",
      "Window 2 Epoch 30 Train Loss: -0.811706825985628, Val Loss: -0.8740255832672119\n",
      "Window 2 Epoch 40 Train Loss: -0.8743612432479858, Val Loss: -0.9566239714622498\n",
      "Window 3 Epoch 0 Train Loss: 2.1168861495747286, Val Loss: 1.1521556377410889\n",
      "Window 3 Epoch 10 Train Loss: -0.1318577528701109, Val Loss: -0.3464333117008209\n",
      "Window 3 Epoch 20 Train Loss: -0.6205293161728803, Val Loss: -0.5915184020996094\n",
      "Window 3 Epoch 30 Train Loss: -0.7951752176004298, Val Loss: -0.4542713165283203\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.5247112579906688, Val Loss: 0.7967367172241211\n",
      "Window 4 Epoch 10 Train Loss: -0.0781552279696745, Val Loss: -0.2607133090496063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:05,904] Trial 62 finished with value: -0.06603459268808365 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 8, 'learning_rate': 0.01, 'dropout': 0.4, 'batch_size': 128, 'num_gaussians': 8, 'patience': 10}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 20 Train Loss: 0.06019756204941693, Val Loss: -0.42391565442085266\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1855567672673393, Val Loss: 0.8180636763572693\n",
      "Window 0 Epoch 10 Train Loss: 0.4157774865627289, Val Loss: -0.27353689074516296\n",
      "Window 0 Epoch 20 Train Loss: -0.3748100688176997, Val Loss: -0.6227392554283142\n",
      "Window 0 Epoch 30 Train Loss: -0.7322742668320151, Val Loss: -0.8711665272712708\n",
      "Window 0 Epoch 40 Train Loss: -0.5427143782727859, Val Loss: -0.8704195022583008\n",
      "Window 1 Epoch 0 Train Loss: 2.383728290165172, Val Loss: 1.0051380395889282\n",
      "Window 1 Epoch 10 Train Loss: 1.837445993537412, Val Loss: -0.0201529823243618\n",
      "Window 1 Epoch 20 Train Loss: 0.1472591916252585, Val Loss: -0.3947463035583496\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.7184628459986518, Val Loss: 0.7120416760444641\n",
      "Window 2 Epoch 10 Train Loss: -0.5714643126375535, Val Loss: -0.873759925365448\n",
      "Window 2 Epoch 20 Train Loss: -0.7281229200082667, Val Loss: -0.9182548522949219\n",
      "Window 2 Epoch 30 Train Loss: -0.7889502072334289, Val Loss: -0.8441343903541565\n",
      "Window 2 Epoch 40 Train Loss: -0.7253549530926873, Val Loss: -0.9543371200561523\n",
      "Window 3 Epoch 0 Train Loss: 1.0640075663959279, Val Loss: 0.6429610848426819\n",
      "Window 3 Epoch 10 Train Loss: -0.27422948542763204, Val Loss: -0.31136325001716614\n",
      "Window 3 Epoch 20 Train Loss: -0.7741836731574114, Val Loss: -0.5749568343162537\n",
      "Window 3 Epoch 30 Train Loss: -0.863344108357149, Val Loss: -0.5940723419189453\n",
      "Window 3 Epoch 40 Train Loss: -0.7423962514540728, Val Loss: -0.5125654935836792\n",
      "Window 4 Epoch 0 Train Loss: 1.287633606966804, Val Loss: 0.7734134197235107\n",
      "Window 4 Epoch 10 Train Loss: 0.24161118016523472, Val Loss: -0.2830815315246582\n",
      "Window 4 Epoch 20 Train Loss: 0.04306657482596005, Val Loss: -0.7022688388824463\n",
      "Window 4 Epoch 30 Train Loss: -0.8288865009476157, Val Loss: -0.6470043659210205\n",
      "Window 4 Epoch 40 Train Loss: -0.946037743512322, Val Loss: -0.7336185574531555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:11,909] Trial 63 finished with value: -0.4682333440706134 and parameters: {'lstm_hidden_layer_size': 45, 'mlp_hidden_dim': 5, 'learning_rate': 0.01, 'dropout': 0.3, 'batch_size': 128, 'num_gaussians': 9, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.04459897293764, Val Loss: 0.9631009101867676\n",
      "Window 0 Epoch 10 Train Loss: -0.2737368960941539, Val Loss: -0.47302642464637756\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.1604887976365932, Val Loss: 0.5623418688774109\n",
      "Window 1 Epoch 10 Train Loss: -0.5405007447214688, Val Loss: -0.5029779076576233\n",
      "Window 1 Epoch 20 Train Loss: -0.653740051353679, Val Loss: -0.6017146706581116\n",
      "Window 1 Epoch 30 Train Loss: -0.6535317479862887, Val Loss: -0.6179150342941284\n",
      "Window 1 Epoch 40 Train Loss: -0.7082983465755687, Val Loss: -0.6188387274742126\n",
      "Window 2 Epoch 0 Train Loss: 2.4611889135136322, Val Loss: 1.2283670902252197\n",
      "Window 2 Epoch 10 Train Loss: 0.2690033492971869, Val Loss: -0.3131882846355438\n",
      "Window 2 Epoch 20 Train Loss: -0.6613539655068341, Val Loss: -0.8459131717681885\n",
      "Window 2 Epoch 30 Train Loss: -0.7212817962730632, Val Loss: -0.9001264572143555\n",
      "Window 2 Epoch 40 Train Loss: -0.6934845237170949, Val Loss: -0.8874439597129822\n",
      "Window 3 Epoch 0 Train Loss: 1.4601415489701663, Val Loss: 0.8381717205047607\n",
      "Window 3 Epoch 10 Train Loss: -0.4646202934840146, Val Loss: 0.0936616063117981\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.9376363813175874, Val Loss: 1.3537530899047852\n",
      "Window 4 Epoch 10 Train Loss: 0.19214270170997172, Val Loss: -0.5114278197288513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:16,067] Trial 64 finished with value: -0.38909645892422773 and parameters: {'lstm_hidden_layer_size': 32, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.45, 'batch_size': 128, 'num_gaussians': 1, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 20 Train Loss: -0.8615342981675091, Val Loss: -0.6891810894012451\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.852737488185658, Val Loss: 0.9776321053504944\n",
      "Window 0 Epoch 10 Train Loss: 0.06252346031806048, Val Loss: -0.05399271845817566\n",
      "Window 0 Epoch 20 Train Loss: -0.5679134253894581, Val Loss: -0.9241519570350647\n",
      "Window 0 Epoch 30 Train Loss: -0.7122907646964578, Val Loss: -0.987490713596344\n",
      "Window 0 Epoch 40 Train Loss: -0.6681419437071856, Val Loss: -0.9640639424324036\n",
      "Window 1 Epoch 0 Train Loss: 4.223856273819418, Val Loss: 0.9575889706611633\n",
      "Window 1 Epoch 10 Train Loss: 2.754812985869015, Val Loss: 1.0895090103149414\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 5.475042638498194, Val Loss: 0.7909322381019592\n",
      "Window 2 Epoch 10 Train Loss: 0.9713924090301289, Val Loss: 0.35265854001045227\n",
      "Window 2 Epoch 20 Train Loss: -0.3116409710224937, Val Loss: -0.4597814083099365\n",
      "Window 2 Epoch 30 Train Loss: -0.6227061033248902, Val Loss: -0.8369507193565369\n",
      "Window 2 Epoch 40 Train Loss: -0.7134138038579155, Val Loss: -0.9327591061592102\n",
      "Window 3 Epoch 0 Train Loss: 0.7957582470949959, Val Loss: 0.027615712955594063\n",
      "Window 3 Epoch 10 Train Loss: -0.7633311891555786, Val Loss: -0.4585777521133423\n",
      "Window 3 Epoch 20 Train Loss: -0.7828791803472183, Val Loss: -0.5860706567764282\n",
      "Window 3 Epoch 30 Train Loss: -0.7794302282613866, Val Loss: -0.5430161356925964\n",
      "Window 3 Epoch 40 Train Loss: -0.7890018414048587, Val Loss: -0.5475770831108093\n",
      "Window 4 Epoch 0 Train Loss: 3.5200947279088637, Val Loss: 0.9745242595672607\n",
      "Window 4 Epoch 10 Train Loss: 1.3918685173637726, Val Loss: -0.22082467377185822\n",
      "Window 4 Epoch 20 Train Loss: -0.6926159672176136, Val Loss: -0.7221753001213074\n",
      "Window 4 Epoch 30 Train Loss: -0.916065598375657, Val Loss: -0.7529268264770508\n",
      "Window 4 Epoch 40 Train Loss: -0.8558873619752771, Val Loss: -0.6329149007797241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:25,187] Trial 65 finished with value: -0.5431957343965769 and parameters: {'lstm_hidden_layer_size': 179, 'mlp_hidden_dim': 9, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 10}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.7856386041641236, Val Loss: 0.8417333563168844\n",
      "Window 0 Epoch 10 Train Loss: -0.5038457696578081, Val Loss: -0.8878585497538248\n",
      "Window 0 Epoch 20 Train Loss: -0.5326892343689413, Val Loss: -0.9373837312062582\n",
      "Window 0 Epoch 30 Train Loss: -0.6214074362025541, Val Loss: -0.7933907906214396\n",
      "Window 0 Epoch 40 Train Loss: -0.6731975525968215, Val Loss: -1.048072099685669\n",
      "Window 1 Epoch 0 Train Loss: 1.010893794228049, Val Loss: 0.945117712020874\n",
      "Window 1 Epoch 10 Train Loss: -0.5677633260278141, Val Loss: -0.5993494987487793\n",
      "Window 1 Epoch 20 Train Loss: -0.5298778236262939, Val Loss: -0.23461000124613443\n",
      "Window 1 Epoch 30 Train Loss: -0.38587246228666866, Val Loss: -0.4648776302735011\n",
      "Window 1 Epoch 40 Train Loss: -0.7357795088431415, Val Loss: -0.7111573020617167\n",
      "Window 2 Epoch 0 Train Loss: 0.426452100276947, Val Loss: 0.431838055451711\n",
      "Window 2 Epoch 10 Train Loss: -0.5122488203995368, Val Loss: -0.9058164556821188\n",
      "Window 2 Epoch 20 Train Loss: -0.6725449550151825, Val Loss: -0.9180795351664225\n",
      "Window 2 Epoch 30 Train Loss: -0.6872753648547565, Val Loss: -0.8951596816380819\n",
      "Window 2 Epoch 40 Train Loss: -0.68328163537909, Val Loss: -0.9872141083081564\n",
      "Window 3 Epoch 0 Train Loss: 0.40098296403884887, Val Loss: 0.12271105746428172\n",
      "Window 3 Epoch 10 Train Loss: -0.5340821493373198, Val Loss: -0.4693867564201355\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.4683626271696653, Val Loss: 0.6967525084813436\n",
      "Window 4 Epoch 10 Train Loss: 0.3856200584944557, Val Loss: -0.2381767431894938\n",
      "Window 4 Epoch 20 Train Loss: -0.5710024513917811, Val Loss: -0.7080129186312357\n",
      "Window 4 Epoch 30 Train Loss: -0.8790343769858865, Val Loss: -0.7116890549659729\n",
      "Window 4 Epoch 40 Train Loss: -0.9323905071090249, Val Loss: -0.7645013630390167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:34,737] Trial 66 finished with value: -0.4113672860711813 and parameters: {'lstm_hidden_layer_size': 19, 'mlp_hidden_dim': 5, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 32, 'num_gaussians': 10, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.6447355158188763, Val Loss: 1.2693833112716675\n",
      "Window 0 Epoch 10 Train Loss: 1.6054738414988798, Val Loss: 1.2602523565292358\n",
      "Window 0 Epoch 20 Train Loss: 1.5498365121729234, Val Loss: 1.251296043395996\n",
      "Window 0 Epoch 30 Train Loss: 1.5131463101330926, Val Loss: 1.2423723936080933\n",
      "Window 0 Epoch 40 Train Loss: 1.4714003770491657, Val Loss: 1.2335283756256104\n",
      "Window 1 Epoch 0 Train Loss: 2.2056406001483695, Val Loss: 1.278755784034729\n",
      "Window 1 Epoch 10 Train Loss: 2.1489371232425465, Val Loss: 1.262065052986145\n",
      "Window 1 Epoch 20 Train Loss: 2.0848515468485216, Val Loss: 1.246097445487976\n",
      "Window 1 Epoch 30 Train Loss: 2.0379207327786615, Val Loss: 1.2303942441940308\n",
      "Window 1 Epoch 40 Train Loss: 1.9275768308078542, Val Loss: 1.2157025337219238\n",
      "Window 2 Epoch 0 Train Loss: 1.3215964729645673, Val Loss: 1.3096786737442017\n",
      "Window 2 Epoch 10 Train Loss: 1.2921726423151352, Val Loss: 1.2912644147872925\n",
      "Window 2 Epoch 20 Train Loss: 1.2610282987706802, Val Loss: 1.2730721235275269\n",
      "Window 2 Epoch 30 Train Loss: 1.2308785455367144, Val Loss: 1.2549422979354858\n",
      "Window 2 Epoch 40 Train Loss: 1.207834444326513, Val Loss: 1.2371145486831665\n",
      "Window 3 Epoch 0 Train Loss: 1.6034376309899723, Val Loss: 1.0648058652877808\n",
      "Window 3 Epoch 10 Train Loss: 1.5007436272677253, Val Loss: 1.0580941438674927\n",
      "Window 3 Epoch 20 Train Loss: 1.5029088856192196, Val Loss: 1.0521637201309204\n",
      "Window 3 Epoch 30 Train Loss: 1.487094300213982, Val Loss: 1.0463460683822632\n",
      "Window 3 Epoch 40 Train Loss: 1.4296977306814755, Val Loss: 1.040863275527954\n",
      "Window 4 Epoch 0 Train Loss: 0.9780625470946817, Val Loss: 0.9680253863334656\n",
      "Window 4 Epoch 10 Train Loss: 0.9675262027628282, Val Loss: 0.9553402066230774\n",
      "Window 4 Epoch 20 Train Loss: 0.8926327440317939, Val Loss: 0.9427939057350159\n",
      "Window 4 Epoch 30 Train Loss: 0.8305589945176068, Val Loss: 0.9303895831108093\n",
      "Window 4 Epoch 40 Train Loss: 0.8022995379391838, Val Loss: 0.9181056618690491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:42,133] Trial 67 finished with value: 0.9373154592514038 and parameters: {'lstm_hidden_layer_size': 54, 'mlp_hidden_dim': 7, 'learning_rate': 1e-05, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 8, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.6606792504647199, Val Loss: 0.9587511420249939\n",
      "Window 0 Epoch 10 Train Loss: -0.21954493529656355, Val Loss: -0.3238257169723511\n",
      "Window 0 Epoch 20 Train Loss: -0.6507539636948529, Val Loss: -0.9602689743041992\n",
      "Window 0 Epoch 30 Train Loss: -0.7030166268348694, Val Loss: -0.9932106137275696\n",
      "Window 0 Epoch 40 Train Loss: -0.7838056780310239, Val Loss: -1.0720959901809692\n",
      "Window 1 Epoch 0 Train Loss: 1.06608041973675, Val Loss: 0.8072060942649841\n",
      "Window 1 Epoch 10 Train Loss: -0.3433372789270738, Val Loss: -0.412907212972641\n",
      "Window 1 Epoch 20 Train Loss: -0.20958005260018742, Val Loss: -0.6329584717750549\n",
      "Window 1 Epoch 30 Train Loss: -0.6751065444946289, Val Loss: -0.6972677111625671\n",
      "Window 1 Epoch 40 Train Loss: -0.4887145374802982, Val Loss: -0.6820799708366394\n",
      "Window 2 Epoch 0 Train Loss: 0.9362844387222738, Val Loss: 0.755787193775177\n",
      "Window 2 Epoch 10 Train Loss: -0.7018974949331844, Val Loss: -0.7644786834716797\n",
      "Window 2 Epoch 20 Train Loss: -0.8009954538064844, Val Loss: -0.9890457987785339\n",
      "Window 2 Epoch 30 Train Loss: -0.7767499758215511, Val Loss: -0.9760364890098572\n",
      "Window 2 Epoch 40 Train Loss: -0.8255115093904383, Val Loss: -0.9461908340454102\n",
      "Window 3 Epoch 0 Train Loss: 1.2023174044665168, Val Loss: 0.7347978949546814\n",
      "Window 3 Epoch 10 Train Loss: -0.7419416257914375, Val Loss: -0.7265915870666504\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.9319513926786535, Val Loss: 0.8206028938293457\n",
      "Window 4 Epoch 10 Train Loss: -0.3720985200825859, Val Loss: -0.5990697741508484\n",
      "Window 4 Epoch 20 Train Loss: -0.8013981833177455, Val Loss: -0.708489716053009\n",
      "Window 4 Epoch 30 Train Loss: -1.0113501789990593, Val Loss: -0.7796091437339783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:46,023] Trial 68 finished with value: -0.585108737796545 and parameters: {'lstm_hidden_layer_size': 17, 'mlp_hidden_dim': 8, 'learning_rate': 0.01, 'dropout': 0.25, 'batch_size': 128, 'num_gaussians': 9, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.9917197923099293, Val Loss: -0.7594966292381287\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 3.0685267821480244, Val Loss: 0.897382915019989\n",
      "Window 0 Epoch 10 Train Loss: 1.624916528112748, Val Loss: 0.47348126769065857\n",
      "Window 0 Epoch 20 Train Loss: 0.20735216456301073, Val Loss: -0.6667699813842773\n",
      "Window 0 Epoch 30 Train Loss: -0.6406089429294362, Val Loss: -1.0100198984146118\n",
      "Window 0 Epoch 40 Train Loss: -0.7305679467145134, Val Loss: -1.0896127223968506\n",
      "Window 1 Epoch 0 Train Loss: 3.046301203615525, Val Loss: 1.050071120262146\n",
      "Window 1 Epoch 10 Train Loss: 1.8633625456866096, Val Loss: 0.4737643301486969\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 28.28300634468303, Val Loss: 1.3045682907104492\n",
      "Window 2 Epoch 10 Train Loss: 1.892429337501526, Val Loss: 0.4438619315624237\n",
      "Window 2 Epoch 20 Train Loss: 1.9988214738228742, Val Loss: 0.4534022808074951\n",
      "Window 2 Epoch 30 Train Loss: 0.759815789531259, Val Loss: -0.5837528705596924\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 2.3752008623235366, Val Loss: 0.6905651092529297\n",
      "Window 3 Epoch 10 Train Loss: 1.1861304514548359, Val Loss: -0.19761569797992706\n",
      "Window 3 Epoch 20 Train Loss: -0.521613504746381, Val Loss: -0.033004190772771835\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 9.355017499362722, Val Loss: 1.8480581045150757\n",
      "Window 4 Epoch 10 Train Loss: 3.7928745987836052, Val Loss: 0.9594152569770813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:51,637] Trial 69 finished with value: 1.805603465613197 and parameters: {'lstm_hidden_layer_size': 147, 'mlp_hidden_dim': 12, 'learning_rate': 0.01, 'dropout': 0.35, 'batch_size': 128, 'num_gaussians': 3, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.4507584647571339, Val Loss: 1.0151513814926147\n",
      "Window 0 Epoch 10 Train Loss: 0.22373685892890482, Val Loss: -0.2315947413444519\n",
      "Window 0 Epoch 20 Train Loss: -0.3364053873454823, Val Loss: -0.7486880421638489\n",
      "Window 0 Epoch 30 Train Loss: -0.6642805820352891, Val Loss: -0.8913092017173767\n",
      "Window 0 Epoch 40 Train Loss: -0.7234219415047589, Val Loss: -0.9173009991645813\n",
      "Window 1 Epoch 0 Train Loss: 1.65070613748887, Val Loss: 1.0195889472961426\n",
      "Window 1 Epoch 10 Train Loss: 0.205667464242262, Val Loss: 0.06267840415239334\n",
      "Window 1 Epoch 20 Train Loss: -0.44129761001643014, Val Loss: -0.517517626285553\n",
      "Window 1 Epoch 30 Train Loss: -0.6815123768413768, Val Loss: -0.5004684925079346\n",
      "Window 1 Epoch 40 Train Loss: -0.7636357592133914, Val Loss: -0.5948260426521301\n",
      "Window 2 Epoch 0 Train Loss: 1.3874270694396076, Val Loss: 0.9554235935211182\n",
      "Window 2 Epoch 10 Train Loss: 0.18451500857577605, Val Loss: -0.41380491852760315\n",
      "Window 2 Epoch 20 Train Loss: -0.2670900482903509, Val Loss: -0.67549067735672\n",
      "Window 2 Epoch 30 Train Loss: -0.4286432737462661, Val Loss: -0.622912585735321\n",
      "Window 2 Epoch 40 Train Loss: -0.7067054915428161, Val Loss: -0.8227044939994812\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.0864122382332297, Val Loss: 0.7599198818206787\n",
      "Window 3 Epoch 10 Train Loss: -0.4106318942238303, Val Loss: -0.4469003677368164\n",
      "Window 3 Epoch 20 Train Loss: -0.8209079599380493, Val Loss: -0.5226429104804993\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.5792940190259148, Val Loss: 0.7956139445304871\n",
      "Window 4 Epoch 10 Train Loss: 0.8788255209081313, Val Loss: -0.3889200687408447\n",
      "Window 4 Epoch 20 Train Loss: -0.12506474088220035, Val Loss: -0.3403101861476898\n",
      "Window 4 Epoch 30 Train Loss: -0.6596944372794208, Val Loss: -0.6639791131019592\n",
      "Window 4 Epoch 40 Train Loss: -0.8974135788749246, Val Loss: -0.6831512451171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:55,829] Trial 70 finished with value: -0.3856736158579588 and parameters: {'lstm_hidden_layer_size': 27, 'mlp_hidden_dim': 32, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 256, 'num_gaussians': 10, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1354142860805287, Val Loss: 0.8531147837638855\n",
      "Window 0 Epoch 10 Train Loss: -0.6306486960018383, Val Loss: -1.0298746824264526\n",
      "Window 0 Epoch 20 Train Loss: -0.7878968771766214, Val Loss: -1.079041600227356\n",
      "Window 0 Epoch 30 Train Loss: -0.7544702274659101, Val Loss: -1.0703928470611572\n",
      "Window 0 Epoch 40 Train Loss: -0.6959860588522518, Val Loss: -1.0421985387802124\n",
      "Window 1 Epoch 0 Train Loss: 0.9520138530170217, Val Loss: 0.8150298595428467\n",
      "Window 1 Epoch 10 Train Loss: -0.503103452430052, Val Loss: -0.6168398857116699\n",
      "Window 1 Epoch 20 Train Loss: -0.6500018065115984, Val Loss: -0.598547637462616\n",
      "Window 1 Epoch 30 Train Loss: -0.7562828692267923, Val Loss: -0.6484627723693848\n",
      "Window 1 Epoch 40 Train Loss: -0.716428390530979, Val Loss: -0.6237167119979858\n",
      "Window 2 Epoch 0 Train Loss: 1.239520863084232, Val Loss: 0.7582041621208191\n",
      "Window 2 Epoch 10 Train Loss: -0.4939243159574621, Val Loss: -0.6725460886955261\n",
      "Window 2 Epoch 20 Train Loss: -0.8107829347778769, Val Loss: -0.8909382224082947\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.8948338657266953, Val Loss: 0.5972001552581787\n",
      "Window 3 Epoch 10 Train Loss: -0.7043528640971465, Val Loss: -0.5049856305122375\n",
      "Window 3 Epoch 20 Train Loss: -0.8905864359350766, Val Loss: -0.4813706576824188\n",
      "Window 3 Epoch 30 Train Loss: -0.8457931089401245, Val Loss: -0.47785723209381104\n",
      "Window 3 Epoch 40 Train Loss: -0.9096199069303624, Val Loss: -0.5146005153656006\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.8000055014385896, Val Loss: 0.7810681462287903\n",
      "Window 4 Epoch 10 Train Loss: 0.6240129770952113, Val Loss: -0.32604655623435974\n",
      "Window 4 Epoch 20 Train Loss: -0.6549482931810267, Val Loss: -0.5499638319015503\n",
      "Window 4 Epoch 30 Train Loss: -0.9724522001603071, Val Loss: -0.6814694404602051\n",
      "Window 4 Epoch 40 Train Loss: -0.9938701388415169, Val Loss: -0.7530307769775391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:08:59,837] Trial 71 finished with value: -0.5074025362730026 and parameters: {'lstm_hidden_layer_size': 19, 'mlp_hidden_dim': 4, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5049886547817903, Val Loss: 0.9415607452392578\n",
      "Window 0 Epoch 10 Train Loss: -0.11881340237224804, Val Loss: -0.718670666217804\n",
      "Window 0 Epoch 20 Train Loss: -0.6318309008373933, Val Loss: -1.0124356746673584\n",
      "Window 0 Epoch 30 Train Loss: -0.7289259663750144, Val Loss: -1.047982931137085\n",
      "Window 0 Epoch 40 Train Loss: -0.7195403536628274, Val Loss: -1.0319172143936157\n",
      "Window 1 Epoch 0 Train Loss: 1.249547799054314, Val Loss: 0.8846748471260071\n",
      "Window 1 Epoch 10 Train Loss: -0.2829627763523775, Val Loss: -0.3922198712825775\n",
      "Window 1 Epoch 20 Train Loss: -0.48437784293118646, Val Loss: -0.6419051885604858\n",
      "Window 1 Epoch 30 Train Loss: -0.7282353482526891, Val Loss: -0.6016943454742432\n",
      "Window 1 Epoch 40 Train Loss: -0.80154626678018, Val Loss: -0.6663361191749573\n",
      "Window 2 Epoch 0 Train Loss: 0.7909620558514314, Val Loss: 0.6574432253837585\n",
      "Window 2 Epoch 10 Train Loss: -0.2963294622477363, Val Loss: -0.5140359401702881\n",
      "Window 2 Epoch 20 Train Loss: -0.422886623915504, Val Loss: -0.6462750434875488\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.2984918057217318, Val Loss: 0.8037159442901611\n",
      "Window 3 Epoch 10 Train Loss: -0.20892807189156026, Val Loss: -0.5483701825141907\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0064777379877428, Val Loss: 0.7036184668540955\n",
      "Window 4 Epoch 10 Train Loss: -0.32306819186491126, Val Loss: -0.7346980571746826\n",
      "Window 4 Epoch 20 Train Loss: -0.7622176980972291, Val Loss: -0.767977237701416\n",
      "Window 4 Epoch 30 Train Loss: -0.9392992639541626, Val Loss: -0.725114107131958\n",
      "Window 4 Epoch 40 Train Loss: -0.9646211295969346, Val Loss: -0.7151944041252136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:05,143] Trial 72 finished with value: -0.5764659851789474 and parameters: {'lstm_hidden_layer_size': 36, 'mlp_hidden_dim': 20, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 5}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.311551370340235, Val Loss: 0.8375527858734131\n",
      "Window 0 Epoch 10 Train Loss: -0.44846154675764194, Val Loss: -0.7993123531341553\n",
      "Window 0 Epoch 20 Train Loss: -0.6918298008862663, Val Loss: -1.0509638786315918\n",
      "Window 0 Epoch 30 Train Loss: -0.7660417687191683, Val Loss: -0.9973783493041992\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.435571417387794, Val Loss: 0.9622535705566406\n",
      "Window 1 Epoch 10 Train Loss: -0.31732009831596825, Val Loss: -0.3421766459941864\n",
      "Window 1 Epoch 20 Train Loss: -0.6273800349235534, Val Loss: -0.3361866772174835\n",
      "Window 1 Epoch 30 Train Loss: -0.671990896393271, Val Loss: -0.609122633934021\n",
      "Window 1 Epoch 40 Train Loss: -0.7794901703385746, Val Loss: -0.691901445388794\n",
      "Window 2 Epoch 0 Train Loss: 1.2506787708226372, Val Loss: 0.6169453263282776\n",
      "Window 2 Epoch 10 Train Loss: -0.25501206021098527, Val Loss: -0.4980045258998871\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.1421486452046563, Val Loss: 0.7185744643211365\n",
      "Window 3 Epoch 10 Train Loss: -0.4076081772411571, Val Loss: -0.5152042508125305\n",
      "Window 3 Epoch 20 Train Loss: -0.4263761587703929, Val Loss: -0.3315276801586151\n",
      "Window 3 Epoch 30 Train Loss: -0.8346806972167071, Val Loss: -0.5215471386909485\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1005858732672298, Val Loss: 0.580944299697876\n",
      "Window 4 Epoch 10 Train Loss: -0.15057147432776058, Val Loss: -0.603797197341919\n",
      "Window 4 Epoch 20 Train Loss: -0.6956343583499685, Val Loss: -0.685567319393158\n",
      "Window 4 Epoch 30 Train Loss: -0.849057963034686, Val Loss: -0.7500740885734558\n",
      "Window 4 Epoch 40 Train Loss: -0.9454370518291698, Val Loss: -0.7607870101928711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:08,837] Trial 73 finished with value: -0.5966265646647662 and parameters: {'lstm_hidden_layer_size': 24, 'mlp_hidden_dim': 18, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.689788557361154, Val Loss: 1.003386378288269\n",
      "Window 0 Epoch 10 Train Loss: -0.3998385509322671, Val Loss: -0.8408889770507812\n",
      "Window 0 Epoch 20 Train Loss: -0.6140391924801994, Val Loss: -0.8429575562477112\n",
      "Window 0 Epoch 30 Train Loss: -0.7322817798221812, Val Loss: -1.051979660987854\n",
      "Window 0 Epoch 40 Train Loss: -0.7524695075259489, Val Loss: -1.0485374927520752\n",
      "Window 1 Epoch 0 Train Loss: 1.9344190004292656, Val Loss: 0.9173294901847839\n",
      "Window 1 Epoch 10 Train Loss: 0.21457368272192337, Val Loss: -0.21804827451705933\n",
      "Window 1 Epoch 20 Train Loss: -0.5535777452412773, Val Loss: -0.6021350026130676\n",
      "Window 1 Epoch 30 Train Loss: -0.6083780782362994, Val Loss: -0.6097236275672913\n",
      "Window 1 Epoch 40 Train Loss: -0.76464911923689, Val Loss: -0.7354598641395569\n",
      "Window 2 Epoch 0 Train Loss: 1.2465074830896714, Val Loss: 1.02227783203125\n",
      "Window 2 Epoch 10 Train Loss: -0.5939767377516803, Val Loss: -0.7259857654571533\n",
      "Window 2 Epoch 20 Train Loss: -0.7318042112799252, Val Loss: -0.7052328586578369\n",
      "Window 2 Epoch 30 Train Loss: -0.8228998997632195, Val Loss: -0.8412125706672668\n",
      "Window 2 Epoch 40 Train Loss: -0.8538192526031942, Val Loss: -0.8853256106376648\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.382292767272276, Val Loss: 0.7878013253211975\n",
      "Window 3 Epoch 10 Train Loss: 0.0314196320141063, Val Loss: -0.29889312386512756\n",
      "Window 3 Epoch 20 Train Loss: -0.8134583325947032, Val Loss: -0.40034058690071106\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1480791089114022, Val Loss: 0.8445112705230713\n",
      "Window 4 Epoch 10 Train Loss: -0.7303781735195833, Val Loss: -0.6602180600166321\n",
      "Window 4 Epoch 20 Train Loss: -0.8918500961976893, Val Loss: -0.7354870438575745\n",
      "Window 4 Epoch 30 Train Loss: -0.8640653970662285, Val Loss: -0.6137838959693909\n",
      "Window 4 Epoch 40 Train Loss: -0.9286614807914285, Val Loss: -0.6362648010253906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:12,770] Trial 74 finished with value: -0.610926580876112 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 7, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 6, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.456443194922279, Val Loss: 0.8190431594848633\n",
      "Window 0 Epoch 10 Train Loss: -0.059780333743375894, Val Loss: -0.43363046646118164\n",
      "Window 0 Epoch 20 Train Loss: -0.47204972365323233, Val Loss: -0.66511470079422\n",
      "Window 0 Epoch 30 Train Loss: -0.5859868847622591, Val Loss: -1.0044947862625122\n",
      "Window 0 Epoch 40 Train Loss: -0.7416041044627919, Val Loss: -1.0479750633239746\n",
      "Window 1 Epoch 0 Train Loss: 1.4371453589551588, Val Loss: 0.8904860019683838\n",
      "Window 1 Epoch 10 Train Loss: -0.41290731079438153, Val Loss: -0.5335367918014526\n",
      "Window 1 Epoch 20 Train Loss: -0.5799496019587798, Val Loss: -0.6634564995765686\n",
      "Window 1 Epoch 30 Train Loss: -0.6620355624311111, Val Loss: -0.7162479758262634\n",
      "Window 1 Epoch 40 Train Loss: -0.8057903167780708, Val Loss: -0.7191755771636963\n",
      "Window 2 Epoch 0 Train Loss: 1.263604960862328, Val Loss: 0.7995498776435852\n",
      "Window 2 Epoch 10 Train Loss: -0.4155168867111206, Val Loss: -0.6086902618408203\n",
      "Window 2 Epoch 20 Train Loss: -0.700753090802361, Val Loss: -0.8351108431816101\n",
      "Window 2 Epoch 30 Train Loss: -0.7782879889712614, Val Loss: -0.8702530264854431\n",
      "Window 2 Epoch 40 Train Loss: -0.7613735186352449, Val Loss: -0.8333883285522461\n",
      "Window 3 Epoch 0 Train Loss: 0.9611449768963982, Val Loss: 0.8782340884208679\n",
      "Window 3 Epoch 10 Train Loss: -0.3499080723874709, Val Loss: -0.48090827465057373\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.7833645308718962, Val Loss: 0.6333094239234924\n",
      "Window 4 Epoch 10 Train Loss: -0.5539417935820187, Val Loss: -0.6920105814933777\n",
      "Window 4 Epoch 20 Train Loss: -0.9115095043182373, Val Loss: -0.7435525059700012\n",
      "Window 4 Epoch 30 Train Loss: -0.9458147301393397, Val Loss: -0.7029402852058411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:16,502] Trial 75 finished with value: -0.559867062088516 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 10, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 6, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1099685144424438, Val Loss: 1.0442653894424438\n",
      "Window 0 Epoch 10 Train Loss: 1.0815240792667165, Val Loss: 1.0426713228225708\n",
      "Window 0 Epoch 20 Train Loss: 1.149839997291565, Val Loss: 1.0403467416763306\n",
      "Window 0 Epoch 30 Train Loss: 1.1377280776640948, Val Loss: 1.0376828908920288\n",
      "Window 0 Epoch 40 Train Loss: 1.1237773003297693, Val Loss: 1.0350991487503052\n",
      "Window 1 Epoch 0 Train Loss: 1.660393151956446, Val Loss: 1.1938059329986572\n",
      "Window 1 Epoch 10 Train Loss: 1.6255238687290865, Val Loss: 1.189614176750183\n",
      "Window 1 Epoch 20 Train Loss: 1.5958170739342186, Val Loss: 1.1854424476623535\n",
      "Window 1 Epoch 30 Train Loss: 1.5937967808106366, Val Loss: 1.1812820434570312\n",
      "Window 1 Epoch 40 Train Loss: 1.5507993487750782, Val Loss: 1.1771520376205444\n",
      "Window 2 Epoch 0 Train Loss: 1.422474198621862, Val Loss: 1.1246095895767212\n",
      "Window 2 Epoch 10 Train Loss: 1.4147413884892184, Val Loss: 1.1222457885742188\n",
      "Window 2 Epoch 20 Train Loss: 1.4071363216287949, Val Loss: 1.1198952198028564\n",
      "Window 2 Epoch 30 Train Loss: 1.389757282593671, Val Loss: 1.1175683736801147\n",
      "Window 2 Epoch 40 Train Loss: 1.408630123979905, Val Loss: 1.1152653694152832\n",
      "Window 3 Epoch 0 Train Loss: 2.0568317845288444, Val Loss: 1.0319198369979858\n",
      "Window 3 Epoch 10 Train Loss: 2.0538948502260097, Val Loss: 1.027901291847229\n",
      "Window 3 Epoch 20 Train Loss: 2.0344908624536853, Val Loss: 1.0238991975784302\n",
      "Window 3 Epoch 30 Train Loss: 1.9585197224336512, Val Loss: 1.0199934244155884\n",
      "Window 3 Epoch 40 Train Loss: 1.9364204373079188, Val Loss: 1.0161985158920288\n",
      "Window 4 Epoch 0 Train Loss: 1.442611027885886, Val Loss: 1.1058411598205566\n",
      "Window 4 Epoch 10 Train Loss: 1.4296015186870799, Val Loss: 1.1021147966384888\n",
      "Window 4 Epoch 20 Train Loss: 1.402260913287892, Val Loss: 1.0984069108963013\n",
      "Window 4 Epoch 30 Train Loss: 1.396763588961433, Val Loss: 1.094628930091858\n",
      "Window 4 Epoch 40 Train Loss: 1.3819529679242302, Val Loss: 1.090860366821289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:29,509] Trial 76 finished with value: 1.096683406829834 and parameters: {'lstm_hidden_layer_size': 229, 'mlp_hidden_dim': 15, 'learning_rate': 1e-06, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 6, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0346047597772934, Val Loss: 0.9389479160308838\n",
      "Window 0 Epoch 10 Train Loss: -0.06266332181937555, Val Loss: 0.19190774857997894\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 2.443686144772698, Val Loss: 0.6831344962120056\n",
      "Window 1 Epoch 10 Train Loss: 0.6223964573004667, Val Loss: -0.2873556911945343\n",
      "Window 1 Epoch 20 Train Loss: -0.3457136087207233, Val Loss: -0.6719152331352234\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.6702417425548328, Val Loss: 0.7179939150810242\n",
      "Window 2 Epoch 10 Train Loss: 0.442793885679806, Val Loss: 0.1362316757440567\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.6870370136990267, Val Loss: 0.6656971573829651\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.2022861382540535, Val Loss: 0.5492178201675415\n",
      "Window 4 Epoch 10 Train Loss: 0.9226936945845099, Val Loss: -0.017424656078219414\n",
      "Window 4 Epoch 20 Train Loss: -0.6473441004753113, Val Loss: -0.44060707092285156\n",
      "Window 4 Epoch 30 Train Loss: -0.9518091451420504, Val Loss: -0.8080973625183105\n",
      "Window 4 Epoch 40 Train Loss: -0.9496700687969433, Val Loss: -0.7983949780464172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:32,587] Trial 77 finished with value: -0.5338178851827979 and parameters: {'lstm_hidden_layer_size': 47, 'mlp_hidden_dim': 7, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 5, 'patience': 5}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.1643051498076495, Val Loss: 1.344285488128662\n",
      "Window 0 Epoch 10 Train Loss: 1.9450300690707039, Val Loss: 1.2906113862991333\n",
      "Window 0 Epoch 20 Train Loss: 1.7256281824672923, Val Loss: 1.2421997785568237\n",
      "Window 0 Epoch 30 Train Loss: 1.5427376567616182, Val Loss: 1.1937503814697266\n",
      "Window 0 Epoch 40 Train Loss: 1.3424543638790356, Val Loss: 1.139987587928772\n",
      "Window 1 Epoch 0 Train Loss: 1.5209290797570172, Val Loss: 1.0070101022720337\n",
      "Window 1 Epoch 10 Train Loss: 1.2056243256961598, Val Loss: 0.9510910511016846\n",
      "Window 1 Epoch 20 Train Loss: 0.9211433330704184, Val Loss: 0.8914758563041687\n",
      "Window 1 Epoch 30 Train Loss: 0.7755902469859404, Val Loss: 0.8357691168785095\n",
      "Window 1 Epoch 40 Train Loss: 0.6297778704587151, Val Loss: 0.7672081589698792\n",
      "Window 2 Epoch 0 Train Loss: 0.9813592509662403, Val Loss: 0.9379130005836487\n",
      "Window 2 Epoch 10 Train Loss: 0.857912570027744, Val Loss: 0.9017284512519836\n",
      "Window 2 Epoch 20 Train Loss: 0.762096034639022, Val Loss: 0.8638184666633606\n",
      "Window 2 Epoch 30 Train Loss: 0.6240193528287551, Val Loss: 0.820635974407196\n",
      "Window 2 Epoch 40 Train Loss: 0.5270048535571379, Val Loss: 0.7721306681632996\n",
      "Window 3 Epoch 0 Train Loss: 1.507247833925135, Val Loss: 1.0523542165756226\n",
      "Window 3 Epoch 10 Train Loss: 1.3466537408267751, Val Loss: 1.0174663066864014\n",
      "Window 3 Epoch 20 Train Loss: 1.1946902956682093, Val Loss: 0.9816152453422546\n",
      "Window 3 Epoch 30 Train Loss: 1.0420888210745418, Val Loss: 0.941591203212738\n",
      "Window 3 Epoch 40 Train Loss: 0.8993067277179044, Val Loss: 0.8941452503204346\n",
      "Window 4 Epoch 0 Train Loss: 1.1867549080007216, Val Loss: 1.0806151628494263\n",
      "Window 4 Epoch 10 Train Loss: 1.0949372942307416, Val Loss: 1.0389326810836792\n",
      "Window 4 Epoch 20 Train Loss: 1.0094234396429622, Val Loss: 0.9979589581489563\n",
      "Window 4 Epoch 30 Train Loss: 0.9261605115497813, Val Loss: 0.9547200202941895\n",
      "Window 4 Epoch 40 Train Loss: 0.8376198991607218, Val Loss: 0.90606689453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:38,137] Trial 78 finished with value: 0.9750979197025299 and parameters: {'lstm_hidden_layer_size': 26, 'mlp_hidden_dim': 22, 'learning_rate': 0.0001, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 5}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.7191499575446634, Val Loss: 0.7828663190205892\n",
      "Window 0 Epoch 10 Train Loss: 0.07176317067707286, Val Loss: -0.6033872167269388\n",
      "Window 0 Epoch 20 Train Loss: -0.5292309797511381, Val Loss: -0.8128363291422526\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.8404028736843783, Val Loss: 0.9569638967514038\n",
      "Window 1 Epoch 10 Train Loss: -0.1259929530760821, Val Loss: -0.36928857366244\n",
      "Window 1 Epoch 20 Train Loss: -0.42137831687927246, Val Loss: -0.7162977059682211\n",
      "Window 1 Epoch 30 Train Loss: -0.6020064794316011, Val Loss: -0.6578148106733958\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.1280914581523223, Val Loss: 0.7181146144866943\n",
      "Window 2 Epoch 10 Train Loss: -0.013760500620393192, Val Loss: 0.22316677371660867\n",
      "Window 2 Epoch 20 Train Loss: -0.4854619107877507, Val Loss: -0.6589866280555725\n",
      "Window 2 Epoch 30 Train Loss: -0.7259802961349487, Val Loss: -0.9530121485392252\n",
      "Window 2 Epoch 40 Train Loss: -0.6119589677628349, Val Loss: -0.7024582425753275\n",
      "Window 3 Epoch 0 Train Loss: 0.8317118862096001, Val Loss: 0.8618395725886027\n",
      "Window 3 Epoch 10 Train Loss: -0.33197126497240625, Val Loss: 0.02394697070121765\n",
      "Window 3 Epoch 20 Train Loss: -0.6598128851722268, Val Loss: -0.2781786223252614\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1098034008811501, Val Loss: 0.8786847988764445\n",
      "Window 4 Epoch 10 Train Loss: -0.544390081798329, Val Loss: -0.05151350051164627\n",
      "Window 4 Epoch 20 Train Loss: -0.8051742685542387, Val Loss: -0.7458862463633219\n",
      "Window 4 Epoch 30 Train Loss: -0.6896186060063979, Val Loss: -0.6925309101740519\n",
      "Window 4 Epoch 40 Train Loss: -0.9151696659536923, Val Loss: -0.7320294479529063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:53,437] Trial 79 finished with value: -0.4177765511597196 and parameters: {'lstm_hidden_layer_size': 61, 'mlp_hidden_dim': 24, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 32, 'num_gaussians': 5, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5379556808752173, Val Loss: 1.135689616203308\n",
      "Window 0 Epoch 10 Train Loss: 0.40340692144982954, Val Loss: -0.09476166218519211\n",
      "Window 0 Epoch 20 Train Loss: -0.4341237132689532, Val Loss: -1.1030193567276\n",
      "Window 0 Epoch 30 Train Loss: -0.6751374536402085, Val Loss: -1.0443826913833618\n",
      "Window 0 Epoch 40 Train Loss: -0.6869801069708431, Val Loss: -1.0543923377990723\n",
      "Window 1 Epoch 0 Train Loss: 1.57832639021032, Val Loss: 0.9656081199645996\n",
      "Window 1 Epoch 10 Train Loss: 0.7144698344959932, Val Loss: -0.483075886964798\n",
      "Window 1 Epoch 20 Train Loss: -0.510825808468987, Val Loss: -0.6024153828620911\n",
      "Window 1 Epoch 30 Train Loss: -0.6118912016644197, Val Loss: -0.6619038581848145\n",
      "Window 1 Epoch 40 Train Loss: -0.6742299606519587, Val Loss: -0.5987683534622192\n",
      "Window 2 Epoch 0 Train Loss: 1.4846017384529113, Val Loss: 0.8028989434242249\n",
      "Window 2 Epoch 10 Train Loss: 0.3835201370716095, Val Loss: -0.5867456793785095\n",
      "Window 2 Epoch 20 Train Loss: -0.42921355471891515, Val Loss: -0.8885729908943176\n",
      "Window 2 Epoch 30 Train Loss: -0.766667144018061, Val Loss: -0.9364943504333496\n",
      "Window 2 Epoch 40 Train Loss: -0.7465526335379656, Val Loss: -0.8626856207847595\n",
      "Window 3 Epoch 0 Train Loss: 0.946613385256599, Val Loss: 0.5264654159545898\n",
      "Window 3 Epoch 10 Train Loss: -0.7592356701458202, Val Loss: -0.5636162757873535\n",
      "Window 3 Epoch 20 Train Loss: -0.7983991352249594, Val Loss: -0.4777720868587494\n",
      "Window 3 Epoch 30 Train Loss: -0.7935727966532987, Val Loss: -0.5597625374794006\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.3438153174344232, Val Loss: 0.7480555176734924\n",
      "Window 4 Epoch 10 Train Loss: 0.9248923538362279, Val Loss: -0.22289173305034637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:09:58,732] Trial 80 finished with value: -0.12469621952623129 and parameters: {'lstm_hidden_layer_size': 34, 'mlp_hidden_dim': 5, 'learning_rate': 0.01, 'dropout': 0.4, 'batch_size': 128, 'num_gaussians': 6, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.4045291019888486, Val Loss: 1.0474132299423218\n",
      "Window 0 Epoch 10 Train Loss: -0.09912782556870404, Val Loss: -0.3192724287509918\n",
      "Window 0 Epoch 20 Train Loss: -0.5052225614996517, Val Loss: -0.7262962460517883\n",
      "Window 0 Epoch 30 Train Loss: -0.6955362189517301, Val Loss: -1.007161259651184\n",
      "Window 0 Epoch 40 Train Loss: -0.5543173782965716, Val Loss: -0.8994979858398438\n",
      "Window 1 Epoch 0 Train Loss: 1.3780030285610871, Val Loss: 0.9258055090904236\n",
      "Window 1 Epoch 10 Train Loss: -0.18913303319145652, Val Loss: -0.42840877175331116\n",
      "Window 1 Epoch 20 Train Loss: -0.4913588369593901, Val Loss: -0.5714921355247498\n",
      "Window 1 Epoch 30 Train Loss: -0.7264504345725564, Val Loss: -0.6262611746788025\n",
      "Window 1 Epoch 40 Train Loss: -0.6085443662194645, Val Loss: -0.6914059519767761\n",
      "Window 2 Epoch 0 Train Loss: 1.0842364515977747, Val Loss: 0.935020387172699\n",
      "Window 2 Epoch 10 Train Loss: -0.7935076113308177, Val Loss: -0.9358366131782532\n",
      "Window 2 Epoch 20 Train Loss: -0.8123790668038761, Val Loss: -0.8531486988067627\n",
      "Window 2 Epoch 30 Train Loss: -0.8545084336224724, Val Loss: -0.7901915907859802\n",
      "Window 2 Epoch 40 Train Loss: -0.9035689638642703, Val Loss: -0.9869358539581299\n",
      "Window 3 Epoch 0 Train Loss: 1.1663760887875276, Val Loss: 0.7295176982879639\n",
      "Window 3 Epoch 10 Train Loss: -0.5884541705075432, Val Loss: -0.5454206466674805\n",
      "Window 3 Epoch 20 Train Loss: -0.6793939098189858, Val Loss: -0.24122703075408936\n",
      "Window 3 Epoch 30 Train Loss: -0.8138585455277387, Val Loss: -0.4708784520626068\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.9194257220099954, Val Loss: 0.6494562029838562\n",
      "Window 4 Epoch 10 Train Loss: -0.4300312406876508, Val Loss: -0.510890543460846\n",
      "Window 4 Epoch 20 Train Loss: -0.8120334389630486, Val Loss: -0.7243278622627258\n",
      "Window 4 Epoch 30 Train Loss: -0.909803825266221, Val Loss: -0.7103819847106934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:02,590] Trial 81 finished with value: -0.561555381566286 and parameters: {'lstm_hidden_layer_size': 16, 'mlp_hidden_dim': 7, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 7, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.9109250466963824, Val Loss: -0.7478218078613281\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.118166475716759, Val Loss: 0.9451380372047424\n",
      "Window 0 Epoch 10 Train Loss: -0.18761726281222174, Val Loss: -0.6286551356315613\n",
      "Window 0 Epoch 20 Train Loss: -0.5379790909150067, Val Loss: -1.0267934799194336\n",
      "Window 0 Epoch 30 Train Loss: -0.6906090963588042, Val Loss: -0.9790324568748474\n",
      "Window 0 Epoch 40 Train Loss: -0.7064221456471611, Val Loss: -0.9791393280029297\n",
      "Window 1 Epoch 0 Train Loss: 1.356517758509692, Val Loss: 0.9797837138175964\n",
      "Window 1 Epoch 10 Train Loss: 0.9148326530877282, Val Loss: -0.17575354874134064\n",
      "Window 1 Epoch 20 Train Loss: -0.15381662354749792, Val Loss: -0.3905515968799591\n",
      "Window 1 Epoch 30 Train Loss: -0.6104038922926959, Val Loss: -0.64485102891922\n",
      "Window 1 Epoch 40 Train Loss: -0.7413762093992794, Val Loss: -0.6417651772499084\n",
      "Window 2 Epoch 0 Train Loss: 0.965665356131161, Val Loss: 0.7131025791168213\n",
      "Window 2 Epoch 10 Train Loss: -0.6299398425046135, Val Loss: -0.8679459095001221\n",
      "Window 2 Epoch 20 Train Loss: -0.7442140716664931, Val Loss: -0.9419746994972229\n",
      "Window 2 Epoch 30 Train Loss: -0.7795652393733754, Val Loss: -0.8943129181861877\n",
      "Window 2 Epoch 40 Train Loss: -0.7761617884916417, Val Loss: -1.0130345821380615\n",
      "Window 3 Epoch 0 Train Loss: 1.0737484362546135, Val Loss: 0.7622594833374023\n",
      "Window 3 Epoch 10 Train Loss: -0.6979912909339456, Val Loss: -0.510107696056366\n",
      "Window 3 Epoch 20 Train Loss: -0.8373055041537565, Val Loss: -0.26262035965919495\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0423216518233804, Val Loss: 0.7565612196922302\n",
      "Window 4 Epoch 10 Train Loss: 0.7701925299448126, Val Loss: 0.24211502075195312\n",
      "Window 4 Epoch 20 Train Loss: -0.08861015530193553, Val Loss: -0.5561423897743225\n",
      "Window 4 Epoch 30 Train Loss: 0.8049363320014056, Val Loss: -0.5420300364494324\n",
      "Window 4 Epoch 40 Train Loss: -0.6874510826784022, Val Loss: -0.7193498611450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:07,809] Trial 82 finished with value: -0.33576200231909753 and parameters: {'lstm_hidden_layer_size': 27, 'mlp_hidden_dim': 5, 'learning_rate': 0.01, 'dropout': 0.15, 'batch_size': 128, 'num_gaussians': 9, 'patience': 9}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1336563632067511, Val Loss: 0.9470596313476562\n",
      "Window 0 Epoch 10 Train Loss: -0.4985862301377689, Val Loss: -0.9126133322715759\n",
      "Window 0 Epoch 20 Train Loss: -0.6838462300861583, Val Loss: -0.9924585819244385\n",
      "Window 0 Epoch 30 Train Loss: -0.7413618551983553, Val Loss: -1.001042366027832\n",
      "Window 0 Epoch 40 Train Loss: -0.8092878899854772, Val Loss: -1.10950767993927\n",
      "Window 1 Epoch 0 Train Loss: 0.9618651471418493, Val Loss: 0.8158180713653564\n",
      "Window 1 Epoch 10 Train Loss: -0.6776001541754779, Val Loss: -0.6615490317344666\n",
      "Window 1 Epoch 20 Train Loss: -0.737349364196553, Val Loss: -0.6799988746643066\n",
      "Window 1 Epoch 30 Train Loss: -0.7566271065263187, Val Loss: -0.7168588638305664\n",
      "Window 1 Epoch 40 Train Loss: -0.7830238849976483, Val Loss: -0.7295482158660889\n",
      "Window 2 Epoch 0 Train Loss: 0.9881729201709523, Val Loss: 0.9105481505393982\n",
      "Window 2 Epoch 10 Train Loss: -0.04311235284104067, Val Loss: -0.39160409569740295\n",
      "Window 2 Epoch 20 Train Loss: -0.6641928695229923, Val Loss: -0.8317222595214844\n",
      "Window 2 Epoch 30 Train Loss: -0.6894875333589666, Val Loss: -0.7522876858711243\n",
      "Window 2 Epoch 40 Train Loss: -0.7792735531750847, Val Loss: -0.9182736277580261\n",
      "Window 3 Epoch 0 Train Loss: 1.6606707491594201, Val Loss: 0.8277913928031921\n",
      "Window 3 Epoch 10 Train Loss: -0.3607564231227426, Val Loss: -0.2957974970340729\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.3033000877324272, Val Loss: 0.8114826679229736\n",
      "Window 4 Epoch 10 Train Loss: -0.3694161704007317, Val Loss: -0.44108954071998596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:10,802] Trial 83 finished with value: -0.28099842369556427 and parameters: {'lstm_hidden_layer_size': 15, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.3, 'batch_size': 128, 'num_gaussians': 8, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.9256620911990896, Val Loss: 1.2591519355773926\n",
      "Window 0 Epoch 10 Train Loss: 0.30911432308309217, Val Loss: 0.4901105463504791\n",
      "Window 0 Epoch 20 Train Loss: -0.28134297370910644, Val Loss: -0.37648805975914\n",
      "Window 0 Epoch 30 Train Loss: -0.5540209969352273, Val Loss: -0.8508079051971436\n",
      "Window 0 Epoch 40 Train Loss: -0.6165694717799916, Val Loss: -0.9234794974327087\n",
      "Window 1 Epoch 0 Train Loss: 1.9578500756095438, Val Loss: 1.1200729608535767\n",
      "Window 1 Epoch 10 Train Loss: 0.4453923243634841, Val Loss: 0.6287885904312134\n",
      "Window 1 Epoch 20 Train Loss: -0.13136822272749507, Val Loss: -0.3614283800125122\n",
      "Window 1 Epoch 30 Train Loss: -0.6085284076017492, Val Loss: -0.6543557047843933\n",
      "Window 1 Epoch 40 Train Loss: -0.5626970411749447, Val Loss: -0.6228919625282288\n",
      "Window 2 Epoch 0 Train Loss: 1.5849833892373477, Val Loss: 1.1008018255233765\n",
      "Window 2 Epoch 10 Train Loss: 0.2631368206529056, Val Loss: 0.5218364000320435\n",
      "Window 2 Epoch 20 Train Loss: -0.24622392707011279, Val Loss: -0.44937005639076233\n",
      "Window 2 Epoch 30 Train Loss: -0.4930086412149317, Val Loss: -0.6373646259307861\n",
      "Window 2 Epoch 40 Train Loss: -0.645619290155523, Val Loss: -0.9336625933647156\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.3890211220348583, Val Loss: 0.9005836844444275\n",
      "Window 3 Epoch 10 Train Loss: -0.021899498481960857, Val Loss: 0.030051345005631447\n",
      "Window 3 Epoch 20 Train Loss: -0.539975423111635, Val Loss: -0.5509486794471741\n",
      "Window 3 Epoch 30 Train Loss: -0.7270446398678948, Val Loss: -0.5628177523612976\n",
      "Window 3 Epoch 40 Train Loss: -0.7608692309435676, Val Loss: -0.5150709748268127\n",
      "Window 4 Epoch 0 Train Loss: 1.1363545133085813, Val Loss: 0.9575915336608887\n",
      "Window 4 Epoch 10 Train Loss: 0.1606921733828152, Val Loss: 0.330764502286911\n",
      "Window 4 Epoch 20 Train Loss: -0.6494589689198662, Val Loss: -0.5148472785949707\n",
      "Window 4 Epoch 30 Train Loss: -0.6951904097725363, Val Loss: -0.6925387382507324\n",
      "Window 4 Epoch 40 Train Loss: -0.9340773004644057, Val Loss: -0.7355006337165833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:17,481] Trial 84 finished with value: -0.32284149505198 and parameters: {'lstm_hidden_layer_size': 42, 'mlp_hidden_dim': 8, 'learning_rate': 0.001, 'dropout': 0.45, 'batch_size': 128, 'num_gaussians': 8, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.996253282883588, Val Loss: 0.8383393287658691\n",
      "Window 0 Epoch 10 Train Loss: -0.48221259411643536, Val Loss: -0.7734694480895996\n",
      "Window 0 Epoch 20 Train Loss: -0.6632315620254068, Val Loss: -1.0041184425354004\n",
      "Window 0 Epoch 30 Train Loss: -0.7008659207119661, Val Loss: -0.9596416354179382\n",
      "Window 0 Epoch 40 Train Loss: -0.7338007102293127, Val Loss: -1.0790560245513916\n",
      "Window 1 Epoch 0 Train Loss: 1.1041759453100317, Val Loss: 0.8058778643608093\n",
      "Window 1 Epoch 10 Train Loss: -0.3488277928268208, Val Loss: -0.5427289605140686\n",
      "Window 1 Epoch 20 Train Loss: -0.6566494679450989, Val Loss: -0.5998886227607727\n",
      "Window 1 Epoch 30 Train Loss: -0.6389671885266024, Val Loss: -0.62276291847229\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.9762666486291325, Val Loss: 0.8067524433135986\n",
      "Window 2 Epoch 10 Train Loss: -0.41791051450897665, Val Loss: -0.7970896363258362\n",
      "Window 2 Epoch 20 Train Loss: -0.7337317888876971, Val Loss: -0.992597758769989\n",
      "Window 2 Epoch 30 Train Loss: -0.6923858629254733, Val Loss: -0.635806143283844\n",
      "Window 2 Epoch 40 Train Loss: -0.7666652923471787, Val Loss: -0.869337797164917\n",
      "Window 3 Epoch 0 Train Loss: 0.9579127993303187, Val Loss: 0.7035694718360901\n",
      "Window 3 Epoch 10 Train Loss: -0.5586587410814622, Val Loss: -0.5527918934822083\n",
      "Window 3 Epoch 20 Train Loss: -0.8271991529184229, Val Loss: -0.6169891953468323\n",
      "Window 3 Epoch 30 Train Loss: -0.8907354352053474, Val Loss: -0.670177698135376\n",
      "Window 3 Epoch 40 Train Loss: -0.9154127923180075, Val Loss: -0.6233791708946228\n",
      "Window 4 Epoch 0 Train Loss: 1.6931616511064418, Val Loss: 0.6727064251899719\n",
      "Window 4 Epoch 10 Train Loss: 0.6494469724683201, Val Loss: 0.3150818645954132\n",
      "Window 4 Epoch 20 Train Loss: -0.05787924135432524, Val Loss: -0.6191731691360474\n",
      "Window 4 Epoch 30 Train Loss: -0.8325319853950949, Val Loss: -0.729341983795166\n",
      "Window 4 Epoch 40 Train Loss: -0.926395115852356, Val Loss: -0.7283274531364441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:22,383] Trial 85 finished with value: -0.27439256381243465 and parameters: {'lstm_hidden_layer_size': 23, 'mlp_hidden_dim': 9, 'learning_rate': 0.01, 'dropout': 0.25, 'batch_size': 128, 'num_gaussians': 9, 'patience': 10}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2556160358821644, Val Loss: 0.8206533789634705\n",
      "Window 0 Epoch 10 Train Loss: -0.3840392964026507, Val Loss: -0.8861953616142273\n",
      "Window 0 Epoch 20 Train Loss: -0.6169833020602955, Val Loss: -0.9884594082832336\n",
      "Window 0 Epoch 30 Train Loss: -0.7272181450619417, Val Loss: -1.026379942893982\n",
      "Window 0 Epoch 40 Train Loss: -0.8038231905768899, Val Loss: -1.0889655351638794\n",
      "Window 1 Epoch 0 Train Loss: 1.076591960402096, Val Loss: 0.9912344813346863\n",
      "Window 1 Epoch 10 Train Loss: -0.3853185071664698, Val Loss: -0.5340059995651245\n",
      "Window 1 Epoch 20 Train Loss: -0.6387129305390751, Val Loss: -0.6529933214187622\n",
      "Window 1 Epoch 30 Train Loss: -0.8151114078129039, Val Loss: -0.6598814129829407\n",
      "Window 1 Epoch 40 Train Loss: -0.7516659038207111, Val Loss: -0.7344607710838318\n",
      "Window 2 Epoch 0 Train Loss: 0.7320038408391616, Val Loss: 0.8121562600135803\n",
      "Window 2 Epoch 10 Train Loss: -0.39562086217543657, Val Loss: -0.6646975874900818\n",
      "Window 2 Epoch 20 Train Loss: -0.7984813608842738, Val Loss: -0.9268553853034973\n",
      "Window 2 Epoch 30 Train Loss: -0.6607329082489014, Val Loss: -0.8635113835334778\n",
      "Window 2 Epoch 40 Train Loss: -0.7600388871922212, Val Loss: -0.9398622512817383\n",
      "Window 3 Epoch 0 Train Loss: 1.000467180925257, Val Loss: 0.7008513808250427\n",
      "Window 3 Epoch 10 Train Loss: -0.7609066954781027, Val Loss: -0.6782782077789307\n",
      "Window 3 Epoch 20 Train Loss: -0.7546925080523771, Val Loss: -0.42880257964134216\n",
      "Window 3 Epoch 30 Train Loss: -0.78392941755407, Val Loss: -0.30548927187919617\n",
      "Window 3 Epoch 40 Train Loss: -0.9450669176438276, Val Loss: -0.5351648330688477\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1523250661176794, Val Loss: 0.7276687622070312\n",
      "Window 4 Epoch 10 Train Loss: -0.3081616504052106, Val Loss: -0.6343105435371399\n",
      "Window 4 Epoch 20 Train Loss: -0.8660613710740034, Val Loss: -0.6498090624809265\n",
      "Window 4 Epoch 30 Train Loss: -0.8748443093019374, Val Loss: -0.7101216912269592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:26,441] Trial 86 finished with value: -0.5946457129716873 and parameters: {'lstm_hidden_layer_size': 16, 'mlp_hidden_dim': 11, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.9682234769708971, Val Loss: -0.7905691266059875\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5613393317951876, Val Loss: 0.9903289675712585\n",
      "Window 0 Epoch 10 Train Loss: -0.5473111151246464, Val Loss: -0.8709560036659241\n",
      "Window 0 Epoch 20 Train Loss: -0.7021903972064748, Val Loss: -0.9677926898002625\n",
      "Window 0 Epoch 30 Train Loss: -0.775068665672751, Val Loss: -0.9963831901550293\n",
      "Window 0 Epoch 40 Train Loss: -0.7841785394444185, Val Loss: -1.0037084817886353\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.752286747483646, Val Loss: 0.8727303147315979\n",
      "Window 1 Epoch 10 Train Loss: -0.2270234246113721, Val Loss: -0.47476819157600403\n",
      "Window 1 Epoch 20 Train Loss: -0.5443488069141612, Val Loss: -0.6658581495285034\n",
      "Window 1 Epoch 30 Train Loss: -0.7041131342158599, Val Loss: -0.6977922916412354\n",
      "Window 1 Epoch 40 Train Loss: -0.6420343180263743, Val Loss: -0.6341428160667419\n",
      "Window 2 Epoch 0 Train Loss: 1.1444083641557132, Val Loss: 0.8099752068519592\n",
      "Window 2 Epoch 10 Train Loss: -0.49563108808854045, Val Loss: -0.7820608019828796\n",
      "Window 2 Epoch 20 Train Loss: -0.6916620504154879, Val Loss: -0.6489374041557312\n",
      "Window 2 Epoch 30 Train Loss: -0.7748263182359584, Val Loss: -1.002851128578186\n",
      "Window 2 Epoch 40 Train Loss: -0.8409206212268157, Val Loss: -1.0193616151809692\n",
      "Window 3 Epoch 0 Train Loss: 1.8518409205885495, Val Loss: 0.9772694706916809\n",
      "Window 3 Epoch 10 Train Loss: 0.2652543189245112, Val Loss: -0.34550830721855164\n",
      "Window 3 Epoch 20 Train Loss: -0.26839877268847295, Val Loss: -0.3935050964355469\n",
      "Window 3 Epoch 30 Train Loss: -0.8311783452594982, Val Loss: -0.4101314842700958\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0425266386480891, Val Loss: 0.9166553020477295\n",
      "Window 4 Epoch 10 Train Loss: -0.792150273884044, Val Loss: -0.7171223163604736\n",
      "Window 4 Epoch 20 Train Loss: -0.8962520296433393, Val Loss: -0.7699616551399231\n",
      "Window 4 Epoch 30 Train Loss: -0.9072400861627915, Val Loss: -0.7918443083763123\n",
      "Window 4 Epoch 40 Train Loss: -0.9583888205359964, Val Loss: -0.7679553031921387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:30,894] Trial 87 finished with value: -0.6021663207001984 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 12, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.4050998421276317, Val Loss: 1.1028140783309937\n",
      "Window 0 Epoch 10 Train Loss: -0.3637687509200152, Val Loss: -0.8078190684318542\n",
      "Window 0 Epoch 20 Train Loss: -0.7585752426876742, Val Loss: -1.0258255004882812\n",
      "Window 0 Epoch 30 Train Loss: -0.7753863427218269, Val Loss: -0.9410912990570068\n",
      "Window 0 Epoch 40 Train Loss: -0.7102844682861776, Val Loss: -1.0405112504959106\n",
      "Window 1 Epoch 0 Train Loss: 0.9944707344560062, Val Loss: 0.8459407687187195\n",
      "Window 1 Epoch 10 Train Loss: -0.40205837642445286, Val Loss: -0.3340797424316406\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.0882943541863386, Val Loss: 0.9828488230705261\n",
      "Window 2 Epoch 10 Train Loss: -0.3736876770328073, Val Loss: -0.6261187195777893\n",
      "Window 2 Epoch 20 Train Loss: -0.625285729450338, Val Loss: -0.6823403239250183\n",
      "Window 2 Epoch 30 Train Loss: -0.7943917501673979, Val Loss: -0.8533958792686462\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.3372199040300705, Val Loss: 0.948328971862793\n",
      "Window 3 Epoch 10 Train Loss: -0.6356821137316087, Val Loss: -0.4602435529232025\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.7213815891041475, Val Loss: 0.9861841201782227\n",
      "Window 4 Epoch 10 Train Loss: -0.5005375172110165, Val Loss: -0.477224200963974\n",
      "Window 4 Epoch 20 Train Loss: -0.6905059434385861, Val Loss: -0.7269309163093567\n",
      "Window 4 Epoch 30 Train Loss: -0.9357776263180901, Val Loss: -0.6750364899635315\n",
      "Window 4 Epoch 40 Train Loss: -0.897363385032205, Val Loss: -0.6280153393745422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:34,307] Trial 88 finished with value: -0.5047223728895187 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 12, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 6, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.4289182965895708, Val Loss: 1.0338431596755981\n",
      "Window 0 Epoch 10 Train Loss: 0.1992769388591542, Val Loss: 0.3028642237186432\n",
      "Window 0 Epoch 20 Train Loss: -0.4760817474477431, Val Loss: -0.8136133551597595\n",
      "Window 0 Epoch 30 Train Loss: -0.6591117616260753, Val Loss: -1.013471245765686\n",
      "Window 0 Epoch 40 Train Loss: -0.7310809504284578, Val Loss: -1.0049898624420166\n",
      "Window 1 Epoch 0 Train Loss: 1.2206932900933658, Val Loss: 0.896794855594635\n",
      "Window 1 Epoch 10 Train Loss: 0.25932983818847466, Val Loss: -0.021599747240543365\n",
      "Window 1 Epoch 20 Train Loss: -0.1718574199255775, Val Loss: -0.5055041313171387\n",
      "Window 1 Epoch 30 Train Loss: -0.60836245284361, Val Loss: -0.6489620804786682\n",
      "Window 1 Epoch 40 Train Loss: -0.6297545225480023, Val Loss: -0.6808827519416809\n",
      "Window 2 Epoch 0 Train Loss: 1.5096566167999717, Val Loss: 0.9751908183097839\n",
      "Window 2 Epoch 10 Train Loss: 0.034604387791717754, Val Loss: -0.3029109537601471\n",
      "Window 2 Epoch 20 Train Loss: -0.48012608331792495, Val Loss: -0.8634340763092041\n",
      "Window 2 Epoch 30 Train Loss: -0.666000907982097, Val Loss: -0.8250448107719421\n",
      "Window 2 Epoch 40 Train Loss: -0.7204192341075224, Val Loss: -0.926953136920929\n",
      "Window 3 Epoch 0 Train Loss: 0.9131026800941019, Val Loss: 0.6060004830360413\n",
      "Window 3 Epoch 10 Train Loss: 0.16919447551755346, Val Loss: -0.16652870178222656\n",
      "Window 3 Epoch 20 Train Loss: -0.46286551980411306, Val Loss: -0.3893961012363434\n",
      "Window 3 Epoch 30 Train Loss: -0.7008048210424536, Val Loss: -0.6295316815376282\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.2368684705565958, Val Loss: 0.7718572616577148\n",
      "Window 4 Epoch 10 Train Loss: -0.2329601806752822, Val Loss: -0.5986108183860779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:40,357] Trial 89 finished with value: -0.29528004862368107 and parameters: {'lstm_hidden_layer_size': 31, 'mlp_hidden_dim': 15, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 20 Train Loss: -0.5525631535754484, Val Loss: -0.5009738802909851\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.7125815049339743, Val Loss: 1.20303213596344\n",
      "Window 0 Epoch 10 Train Loss: 1.702429495418773, Val Loss: 1.2013099193572998\n",
      "Window 0 Epoch 20 Train Loss: 1.6996184012469124, Val Loss: 1.1995927095413208\n",
      "Window 0 Epoch 30 Train Loss: 1.6556614070780138, Val Loss: 1.1978615522384644\n",
      "Window 0 Epoch 40 Train Loss: 1.6480273964825798, Val Loss: 1.1961753368377686\n",
      "Window 1 Epoch 0 Train Loss: 1.8498930448644302, Val Loss: 1.1746660470962524\n",
      "Window 1 Epoch 10 Train Loss: 1.8749200837752398, Val Loss: 1.1719660758972168\n",
      "Window 1 Epoch 20 Train Loss: 1.8222055081760182, Val Loss: 1.1692789793014526\n",
      "Window 1 Epoch 30 Train Loss: 1.784567101983463, Val Loss: 1.1666208505630493\n",
      "Window 1 Epoch 40 Train Loss: 1.8352318960077623, Val Loss: 1.1639248132705688\n",
      "Window 2 Epoch 0 Train Loss: 1.066834145714255, Val Loss: 1.0601493120193481\n",
      "Window 2 Epoch 10 Train Loss: 1.0721508264541626, Val Loss: 1.0586256980895996\n",
      "Window 2 Epoch 20 Train Loss: 1.0526622169158038, Val Loss: 1.0571273565292358\n",
      "Window 2 Epoch 30 Train Loss: 1.0635961198806763, Val Loss: 1.055594563484192\n",
      "Window 2 Epoch 40 Train Loss: 1.0719689770305858, Val Loss: 1.0540672540664673\n",
      "Window 3 Epoch 0 Train Loss: 0.9992216559017406, Val Loss: 0.9622557759284973\n",
      "Window 3 Epoch 10 Train Loss: 1.0030524977515725, Val Loss: 0.9603899121284485\n",
      "Window 3 Epoch 20 Train Loss: 0.9974023605795468, Val Loss: 0.9585385918617249\n",
      "Window 3 Epoch 30 Train Loss: 0.9907811382237602, Val Loss: 0.9566704630851746\n",
      "Window 3 Epoch 40 Train Loss: 0.9791786920323091, Val Loss: 0.9547682404518127\n",
      "Window 4 Epoch 0 Train Loss: 1.7283782089457793, Val Loss: 1.15285062789917\n",
      "Window 4 Epoch 10 Train Loss: 1.7093678151859957, Val Loss: 1.1503524780273438\n",
      "Window 4 Epoch 20 Train Loss: 1.699968547821045, Val Loss: 1.1478270292282104\n",
      "Window 4 Epoch 30 Train Loss: 1.709410634321325, Val Loss: 1.1452763080596924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:44,303] Trial 90 finished with value: 1.146656334400177 and parameters: {'lstm_hidden_layer_size': 22, 'mlp_hidden_dim': 17, 'learning_rate': 1e-05, 'dropout': 0.2, 'batch_size': 256, 'num_gaussians': 7, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: 1.6598840556425207, Val Loss: 1.1427165269851685\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.6057779270059922, Val Loss: 1.1396304368972778\n",
      "Window 0 Epoch 10 Train Loss: -0.6529762698622311, Val Loss: -0.9288268089294434\n",
      "Window 0 Epoch 20 Train Loss: -0.7246688041967504, Val Loss: -1.0759763717651367\n",
      "Window 0 Epoch 30 Train Loss: -0.7559867607845979, Val Loss: -1.0967183113098145\n",
      "Window 0 Epoch 40 Train Loss: -0.7511741391350242, Val Loss: -1.0426342487335205\n",
      "Window 1 Epoch 0 Train Loss: 1.3327957179967096, Val Loss: 0.8630945086479187\n",
      "Window 1 Epoch 10 Train Loss: -0.3617219572908738, Val Loss: -0.5400112867355347\n",
      "Window 1 Epoch 20 Train Loss: -0.6722739606745103, Val Loss: -0.7315824627876282\n",
      "Window 1 Epoch 30 Train Loss: -0.7645435145322015, Val Loss: -0.6838071346282959\n",
      "Window 1 Epoch 40 Train Loss: -0.7857462472074173, Val Loss: -0.7109827995300293\n",
      "Window 2 Epoch 0 Train Loss: 1.1366875132392436, Val Loss: 0.7574284672737122\n",
      "Window 2 Epoch 10 Train Loss: 0.07993300896357088, Val Loss: -0.1474432498216629\n",
      "Window 2 Epoch 20 Train Loss: -0.6029408613373252, Val Loss: -0.837347686290741\n",
      "Window 2 Epoch 30 Train Loss: -0.621008887571447, Val Loss: -0.7070881724357605\n",
      "Window 2 Epoch 40 Train Loss: -0.737738674808951, Val Loss: -0.9125151634216309\n",
      "Window 3 Epoch 0 Train Loss: 1.1062416432885562, Val Loss: 0.8768098950386047\n",
      "Window 3 Epoch 10 Train Loss: -0.19908362430684706, Val Loss: -0.48514771461486816\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1941299465123345, Val Loss: 0.8418152928352356\n",
      "Window 4 Epoch 10 Train Loss: -0.7516537834616268, Val Loss: -0.7790839076042175\n",
      "Window 4 Epoch 20 Train Loss: -0.880605180684258, Val Loss: -0.7479209899902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:47,657] Trial 91 finished with value: -0.5819513618946075 and parameters: {'lstm_hidden_layer_size': 16, 'mlp_hidden_dim': 13, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 6, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 30 Train Loss: -0.9320705318450928, Val Loss: -0.6883751749992371\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.7827541922120487, Val Loss: 0.863719642162323\n",
      "Window 0 Epoch 10 Train Loss: 1.2326574739309795, Val Loss: -0.322180837392807\n",
      "Window 0 Epoch 20 Train Loss: -0.002039443254470825, Val Loss: -0.4167383909225464\n",
      "Window 0 Epoch 30 Train Loss: -0.715569431922015, Val Loss: -1.0588610172271729\n",
      "Window 0 Epoch 40 Train Loss: -0.7520146536827087, Val Loss: -1.0680707693099976\n",
      "Window 1 Epoch 0 Train Loss: 3.4053518891334535, Val Loss: 0.8006920218467712\n",
      "Window 1 Epoch 10 Train Loss: 0.3487830503372585, Val Loss: 0.16932155191898346\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.823976373391993, Val Loss: 0.906963586807251\n",
      "Window 2 Epoch 10 Train Loss: 1.7985313454095055, Val Loss: 0.4191523492336273\n",
      "Window 2 Epoch 20 Train Loss: -0.236130830189761, Val Loss: 0.09145034104585648\n",
      "Window 2 Epoch 30 Train Loss: -0.6712289308099185, Val Loss: -0.8373941779136658\n",
      "Window 2 Epoch 40 Train Loss: -0.7485383157169118, Val Loss: -0.9238815307617188\n",
      "Window 3 Epoch 0 Train Loss: 0.620691598443424, Val Loss: 0.3771308958530426\n",
      "Window 3 Epoch 10 Train Loss: -0.62031241571202, Val Loss: -0.5760589241981506\n",
      "Window 3 Epoch 20 Train Loss: -0.7450151126524981, Val Loss: -0.3146919310092926\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 2.5695303053014418, Val Loss: 0.8668217062950134\n",
      "Window 4 Epoch 10 Train Loss: 0.6207376919073218, Val Loss: -0.34974583983421326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:53,751] Trial 92 finished with value: -0.10936967817985493 and parameters: {'lstm_hidden_layer_size': 109, 'mlp_hidden_dim': 11, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 20 Train Loss: 0.684965197689393, Val Loss: -0.41690146923065186\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.1656061969083897, Val Loss: 0.8503378033638\n",
      "Window 0 Epoch 10 Train Loss: 0.9812103154378778, Val Loss: -0.3660479485988617\n",
      "Window 0 Epoch 20 Train Loss: -0.24674430454478544, Val Loss: -0.9665883183479309\n",
      "Window 0 Epoch 30 Train Loss: -0.6613918904697194, Val Loss: -1.087765097618103\n",
      "Window 0 Epoch 40 Train Loss: -0.778531062743243, Val Loss: -0.9877308011054993\n",
      "Window 1 Epoch 0 Train Loss: 1.3972876520717845, Val Loss: 0.9018919467926025\n",
      "Window 1 Epoch 10 Train Loss: -0.019433443826787612, Val Loss: -0.18173806369304657\n",
      "Window 1 Epoch 20 Train Loss: -0.2424833241631003, Val Loss: -0.5549466609954834\n",
      "Window 1 Epoch 30 Train Loss: -0.6277001498727237, Val Loss: -0.6545804142951965\n",
      "Window 1 Epoch 40 Train Loss: -0.7380341991256265, Val Loss: -0.6459270715713501\n",
      "Window 2 Epoch 0 Train Loss: 1.0213972042588626, Val Loss: 0.654188871383667\n",
      "Window 2 Epoch 10 Train Loss: 0.33667508917696337, Val Loss: -0.23456478118896484\n",
      "Window 2 Epoch 20 Train Loss: 0.0028184669158037973, Val Loss: -0.4301771819591522\n",
      "Window 2 Epoch 30 Train Loss: -0.6021089507551755, Val Loss: -0.7466556429862976\n",
      "Window 2 Epoch 40 Train Loss: -0.7135681587107041, Val Loss: -0.7865950465202332\n",
      "Window 3 Epoch 0 Train Loss: 1.4008725075160755, Val Loss: 0.7390418648719788\n",
      "Window 3 Epoch 10 Train Loss: 0.4307645439049777, Val Loss: -0.14467330276966095\n",
      "Window 3 Epoch 20 Train Loss: -0.48224596654667573, Val Loss: -0.381425142288208\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.8907181347117704, Val Loss: 0.785955011844635\n",
      "Window 4 Epoch 10 Train Loss: 0.03354419266476351, Val Loss: -0.23908312618732452\n",
      "Window 4 Epoch 20 Train Loss: -0.4864345822614782, Val Loss: -0.6234849095344543\n",
      "Window 4 Epoch 30 Train Loss: -0.690272728695589, Val Loss: -0.567009449005127\n",
      "Window 4 Epoch 40 Train Loss: -0.86290463700014, Val Loss: -0.7498782277107239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:10:59,458] Trial 93 finished with value: -0.479136118888855 and parameters: {'lstm_hidden_layer_size': 35, 'mlp_hidden_dim': 14, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 7, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.074207201565013, Val Loss: 1.1885191202163696\n",
      "Window 0 Epoch 10 Train Loss: 0.06636492883457858, Val Loss: -0.4357430040836334\n",
      "Window 0 Epoch 20 Train Loss: -0.48209287699531106, Val Loss: -1.0230761766433716\n",
      "Window 0 Epoch 30 Train Loss: -0.7061285037152908, Val Loss: -1.04988431930542\n",
      "Window 0 Epoch 40 Train Loss: -0.7017377619182362, Val Loss: -1.058132290840149\n",
      "Window 1 Epoch 0 Train Loss: 1.2763823906113119, Val Loss: 0.8108835816383362\n",
      "Window 1 Epoch 10 Train Loss: -0.2978721764508416, Val Loss: -0.4744882881641388\n",
      "Window 1 Epoch 20 Train Loss: -0.6459975242614746, Val Loss: -0.6277455687522888\n",
      "Window 1 Epoch 30 Train Loss: -0.6293596149893368, Val Loss: -0.6781821250915527\n",
      "Window 1 Epoch 40 Train Loss: -0.639204624821158, Val Loss: -0.6858614087104797\n",
      "Window 2 Epoch 0 Train Loss: 1.1931050000471228, Val Loss: 0.9117403030395508\n",
      "Window 2 Epoch 10 Train Loss: -0.2913948333263397, Val Loss: -0.7697990536689758\n",
      "Window 2 Epoch 20 Train Loss: -0.6730665951616623, Val Loss: -0.933100700378418\n",
      "Window 2 Epoch 30 Train Loss: -0.6660673417764551, Val Loss: -0.8928146362304688\n",
      "Window 2 Epoch 40 Train Loss: -0.8425916778340059, Val Loss: -0.9662637710571289\n",
      "Window 3 Epoch 0 Train Loss: 0.8016779620507184, Val Loss: 0.7413440346717834\n",
      "Window 3 Epoch 10 Train Loss: -0.2625930666222292, Val Loss: -0.10116881877183914\n",
      "Window 3 Epoch 20 Train Loss: -0.8174393423865823, Val Loss: -0.42381954193115234\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0233581349428962, Val Loss: 0.7833967208862305\n",
      "Window 4 Epoch 10 Train Loss: -0.7157789076075834, Val Loss: -0.724144697189331\n",
      "Window 4 Epoch 20 Train Loss: -0.9055967833014096, Val Loss: -0.7464444637298584\n",
      "Window 4 Epoch 30 Train Loss: -0.8968510958727668, Val Loss: -0.7127030491828918\n",
      "Window 4 Epoch 40 Train Loss: -0.9603226440093097, Val Loss: -0.7494967579841614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:11:03,236] Trial 94 finished with value: -0.6314291906356811 and parameters: {'lstm_hidden_layer_size': 15, 'mlp_hidden_dim': 10, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2275443424898036, Val Loss: 1.1664875745773315\n",
      "Window 0 Epoch 10 Train Loss: 1.247437611467698, Val Loss: 1.166243314743042\n",
      "Window 0 Epoch 20 Train Loss: 1.245737107781803, Val Loss: 1.165996789932251\n",
      "Window 0 Epoch 30 Train Loss: 1.230041467442232, Val Loss: 1.1657441854476929\n",
      "Window 0 Epoch 40 Train Loss: 1.2453576926624075, Val Loss: 1.1654945611953735\n",
      "Window 1 Epoch 0 Train Loss: 1.6589859771728515, Val Loss: 1.123745322227478\n",
      "Window 1 Epoch 10 Train Loss: 1.6624796937493718, Val Loss: 1.1235073804855347\n",
      "Window 1 Epoch 20 Train Loss: 1.6597571328107048, Val Loss: 1.1232696771621704\n",
      "Window 1 Epoch 30 Train Loss: 1.6630328537436092, Val Loss: 1.1230312585830688\n",
      "Window 1 Epoch 40 Train Loss: 1.6649212113548728, Val Loss: 1.122789978981018\n",
      "Window 2 Epoch 0 Train Loss: 1.9281033981547635, Val Loss: 1.1359678506851196\n",
      "Window 2 Epoch 10 Train Loss: 1.914617580245523, Val Loss: 1.135703206062317\n",
      "Window 2 Epoch 20 Train Loss: 1.950308191355537, Val Loss: 1.13543701171875\n",
      "Window 2 Epoch 30 Train Loss: 1.954795927440419, Val Loss: 1.1351799964904785\n",
      "Window 2 Epoch 40 Train Loss: 1.9396776272268856, Val Loss: 1.1349202394485474\n",
      "Window 3 Epoch 0 Train Loss: 1.3714663104450002, Val Loss: 1.0097981691360474\n",
      "Window 3 Epoch 10 Train Loss: 1.3636813320833094, Val Loss: 1.0093355178833008\n",
      "Window 3 Epoch 20 Train Loss: 1.3500435181225048, Val Loss: 1.0088683366775513\n",
      "Window 3 Epoch 30 Train Loss: 1.3783797227635104, Val Loss: 1.0084024667739868\n",
      "Window 3 Epoch 40 Train Loss: 1.3506505494959213, Val Loss: 1.007935643196106\n",
      "Window 4 Epoch 0 Train Loss: 1.3617809994080488, Val Loss: 1.0758494138717651\n",
      "Window 4 Epoch 10 Train Loss: 1.36772219321307, Val Loss: 1.0755573511123657\n",
      "Window 4 Epoch 20 Train Loss: 1.3642954815135282, Val Loss: 1.07526695728302\n",
      "Window 4 Epoch 30 Train Loss: 1.3504116142497342, Val Loss: 1.0749760866165161\n",
      "Window 4 Epoch 40 Train Loss: 1.3537099389468923, Val Loss: 1.0746848583221436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:11:08,720] Trial 95 finished with value: 1.0751359462738037 and parameters: {'lstm_hidden_layer_size': 25, 'mlp_hidden_dim': 10, 'learning_rate': 1e-06, 'dropout': 0.1, 'batch_size': 128, 'num_gaussians': 8, 'patience': 6}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.0486443292393404, Val Loss: 0.949917733669281\n",
      "Window 0 Epoch 10 Train Loss: -0.6094303689283483, Val Loss: -0.8361610770225525\n",
      "Window 0 Epoch 20 Train Loss: -0.7475489988046534, Val Loss: -1.0612823963165283\n",
      "Window 0 Epoch 30 Train Loss: -0.7652466013852288, Val Loss: -1.0665310621261597\n",
      "Window 0 Epoch 40 Train Loss: -0.8007334341722376, Val Loss: -1.0744596719741821\n",
      "Window 1 Epoch 0 Train Loss: 1.4345647727741915, Val Loss: 0.8627321124076843\n",
      "Window 1 Epoch 10 Train Loss: 0.21850306328605204, Val Loss: -0.4775780141353607\n",
      "Window 1 Epoch 20 Train Loss: -0.5087203076306511, Val Loss: -0.7158343195915222\n",
      "Window 1 Epoch 30 Train Loss: -0.6548692745320938, Val Loss: -0.7088972926139832\n",
      "Window 1 Epoch 40 Train Loss: -0.7296608037107131, Val Loss: -0.7243247032165527\n",
      "Window 2 Epoch 0 Train Loss: 0.9261525398142197, Val Loss: 0.906123161315918\n",
      "Window 2 Epoch 10 Train Loss: -0.4097757772838368, Val Loss: -0.7757682800292969\n",
      "Window 2 Epoch 20 Train Loss: -0.7146258838036481, Val Loss: -0.8369753956794739\n",
      "Window 2 Epoch 30 Train Loss: -0.772270493928124, Val Loss: -0.939555823802948\n",
      "Window 2 Epoch 40 Train Loss: -0.7895081952038934, Val Loss: -1.0074738264083862\n",
      "Window 3 Epoch 0 Train Loss: 1.3813180713092579, Val Loss: 0.9416090846061707\n",
      "Window 3 Epoch 10 Train Loss: -0.5494858771211961, Val Loss: -0.3020564317703247\n",
      "Window 3 Epoch 20 Train Loss: -0.6912185569370494, Val Loss: -0.48487064242362976\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.4992199017019834, Val Loss: 0.8038313984870911\n",
      "Window 4 Epoch 10 Train Loss: -0.24517655050053316, Val Loss: -0.6990341544151306\n",
      "Window 4 Epoch 20 Train Loss: -0.13703408746158374, Val Loss: -0.6093806028366089\n",
      "Window 4 Epoch 30 Train Loss: -0.9281290792016422, Val Loss: -0.6788073182106018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:11:12,276] Trial 96 finished with value: -0.5402718106657267 and parameters: {'lstm_hidden_layer_size': 14, 'mlp_hidden_dim': 9, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 8}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 40 Train Loss: -0.9543792724609375, Val Loss: -0.7332515716552734\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.070073642730713, Val Loss: 1.052308201789856\n",
      "Window 0 Epoch 10 Train Loss: 0.7169760349217583, Val Loss: -0.6396769881248474\n",
      "Window 0 Epoch 20 Train Loss: -0.6558881037375506, Val Loss: -1.0235390663146973\n",
      "Window 0 Epoch 30 Train Loss: -0.7533608003223644, Val Loss: -1.0608402490615845\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.4697559690475464, Val Loss: 0.5864526033401489\n",
      "Window 1 Epoch 10 Train Loss: 0.020500486808664658, Val Loss: -0.1545633226633072\n",
      "Window 1 Epoch 20 Train Loss: -0.09064655121634989, Val Loss: -0.642586886882782\n",
      "Window 1 Epoch 30 Train Loss: 0.5364294266700744, Val Loss: -0.6486380100250244\n",
      "Window 1 Epoch 40 Train Loss: -0.43126141099368825, Val Loss: -0.7623724937438965\n",
      "Window 2 Epoch 0 Train Loss: 0.9643268916186164, Val Loss: 0.8808086514472961\n",
      "Window 2 Epoch 10 Train Loss: 1.7142725949427662, Val Loss: -0.2850269377231598\n",
      "Window 2 Epoch 20 Train Loss: -0.6412950191077064, Val Loss: -0.8118448257446289\n",
      "Window 2 Epoch 30 Train Loss: -0.7488376407062306, Val Loss: -0.8650615811347961\n",
      "Window 2 Epoch 40 Train Loss: -0.8346585307401769, Val Loss: -0.9162808060646057\n",
      "Window 3 Epoch 0 Train Loss: 0.9459799943250768, Val Loss: 0.5179784893989563\n",
      "Window 3 Epoch 10 Train Loss: -0.34318314103519215, Val Loss: -0.3120464086532593\n",
      "Window 3 Epoch 20 Train Loss: -0.8561242522912867, Val Loss: -0.28886404633522034\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.8529903735834009, Val Loss: 0.7332666516304016\n",
      "Window 4 Epoch 10 Train Loss: -0.2059963187049417, Val Loss: -0.54075688123703\n",
      "Window 4 Epoch 20 Train Loss: -0.35036983742433436, Val Loss: -0.337496280670166\n",
      "Window 4 Epoch 30 Train Loss: -0.9326605136254255, Val Loss: -0.6948728561401367\n",
      "Window 4 Epoch 40 Train Loss: -0.9881647499869851, Val Loss: -0.6949832439422607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:11:17,833] Trial 97 finished with value: -0.4943706201016903 and parameters: {'lstm_hidden_layer_size': 29, 'mlp_hidden_dim': 4, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 7}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.191516090561362, Val Loss: 1.2931157350540161\n",
      "Window 0 Epoch 10 Train Loss: -0.2516399912273183, Val Loss: -0.8706125020980835\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.721667807522942, Val Loss: 0.8424975872039795\n",
      "Window 1 Epoch 10 Train Loss: -0.5510451436042786, Val Loss: -0.6590904394785563\n",
      "Window 1 Epoch 20 Train Loss: -0.6282308319035699, Val Loss: -0.7461199164390564\n",
      "Window 1 Epoch 30 Train Loss: -0.6351594104486353, Val Loss: -0.7252246141433716\n",
      "Window 1 Epoch 40 Train Loss: -0.3174410904155058, Val Loss: -0.4785103102525075\n",
      "Window 2 Epoch 0 Train Loss: 0.3898306080874275, Val Loss: 0.39556628465652466\n",
      "Window 2 Epoch 10 Train Loss: -0.24647487282752992, Val Loss: -0.406958947579066\n",
      "Window 2 Epoch 20 Train Loss: -0.6615226960006882, Val Loss: -0.896360456943512\n",
      "Window 2 Epoch 30 Train Loss: -0.6677088951012667, Val Loss: -0.9326153993606567\n",
      "Window 2 Epoch 40 Train Loss: -0.6899871315325008, Val Loss: -0.9444116950035095\n",
      "Window 3 Epoch 0 Train Loss: 0.14284286807565127, Val Loss: -0.0917610377073288\n",
      "Window 3 Epoch 10 Train Loss: -0.7161449140660903, Val Loss: -0.6165748635927836\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.43649611339849587, Val Loss: 0.09481269617875417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:11:25,967] Trial 98 finished with value: -0.25399596906370586 and parameters: {'lstm_hidden_layer_size': 42, 'mlp_hidden_dim': 8, 'learning_rate': 0.01, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 9, 'patience': 4}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.6752138642703787, Val Loss: 0.9709348678588867\n",
      "Window 0 Epoch 10 Train Loss: -0.30091240279814774, Val Loss: -0.6186115145683289\n",
      "Window 0 Epoch 20 Train Loss: -0.5827123633553, Val Loss: -0.9425094723701477\n",
      "Window 0 Epoch 30 Train Loss: -0.6838782878483043, Val Loss: -1.0726677179336548\n",
      "Window 0 Epoch 40 Train Loss: -0.7745294643850887, Val Loss: -1.0864163637161255\n",
      "Window 1 Epoch 0 Train Loss: 0.9914379975375007, Val Loss: 0.9044196009635925\n",
      "Window 1 Epoch 10 Train Loss: -0.44120049294303443, Val Loss: -0.6362171769142151\n",
      "Window 1 Epoch 20 Train Loss: -0.7534344842854668, Val Loss: -0.6894509196281433\n",
      "Window 1 Epoch 30 Train Loss: -0.6621597473761615, Val Loss: -0.5433099269866943\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.9754967179017908, Val Loss: 0.9215855598449707\n",
      "Window 2 Epoch 10 Train Loss: -0.5327323938818539, Val Loss: -0.8034361004829407\n",
      "Window 2 Epoch 20 Train Loss: -0.6241631439854117, Val Loss: -0.655228316783905\n",
      "Window 2 Epoch 30 Train Loss: -0.8223734008564668, Val Loss: -0.9512839913368225\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.0295631832235, Val Loss: 0.6682555079460144\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.1394628983385422, Val Loss: 0.7541001439094543\n",
      "Window 4 Epoch 10 Train Loss: 0.2809532744744245, Val Loss: -0.0016763409366831183\n",
      "Window 4 Epoch 20 Train Loss: -0.48157638044918283, Val Loss: -0.6248311400413513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-24 23:11:28,958] Trial 99 finished with value: -0.14814106917819353 and parameters: {'lstm_hidden_layer_size': 10, 'mlp_hidden_dim': 6, 'learning_rate': 0.01, 'dropout': 0.2, 'batch_size': 128, 'num_gaussians': 8, 'patience': 5}. Best is trial 41 with value: -0.7440888065099717.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Best trial:\n",
      "  Value: -0.7440888065099717\n",
      "  Params: \n",
      "    lstm_hidden_layer_size: 12\n",
      "    mlp_hidden_dim: 5\n",
      "    learning_rate: 0.01\n",
      "    dropout: 0.2\n",
      "    batch_size: 128\n",
      "    num_gaussians: 8\n",
      "    patience: 9\n"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "from test import test_model\n",
    "import torch\n",
    "from model import LSTMWithMLP\n",
    "import optuna\n",
    "\n",
    "def main():\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(train_model, n_trials=100)\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # # Train the model\n",
    "    # model = train_model()\n",
    "\n",
    "    # # model = LSTMWithMLP(lstm_input_size=1, output_size=1, num_gaussians=5, mlp_input_dim=11)\n",
    "    # # state_path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\4. Deep learning part\\\\daily_final_model_state.pth\"\n",
    "    # # model.load_state_dict(torch.load(state_path))\n",
    "\n",
    "    # # Test the model\n",
    "    # average_nll_loss, average_mae_loss, average_mape_loss, average_r2_score = test_model(model)\n",
    "\n",
    "    # # # Output the average losses and R^2 score\n",
    "    # print(f'Average NLL Loss on Test Set: {average_nll_loss:.4f}')\n",
    "    # # print(f'Average RMSE on Test Set: {average_rmse_loss:.4f}')\n",
    "    # print(f'Average MAE on Test Set: {average_mae_loss:.4f}')\n",
    "    # print(f'Average MAPE on Test Set: {average_mape_loss:.4f}')\n",
    "    # print(f'R^2 Score on Test Set: {average_r2_score:.4f}')\n",
    "\n",
    "    # # Save the model state\n",
    "    # state_path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\4. Deep learning part\\\\daily_final_model_state.pth\"\n",
    "    # torch.save(model.state_dict(), state_path)\n",
    "    # print(\"Model state saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
