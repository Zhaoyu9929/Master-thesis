[MODEL]
# Data parameter
seq_length = 7

# Model parameters
batch_size = 64
epochs = 100
learning_rate = 0.0001
num_gaussians = 5

# LSTM parameters
lstm_hidden_layer_size = 128
dropout = 0.2

# MLP parameters
mlp_hidden_dim = 8

# EarlyStopping
patience = 5
delta = 0.05
 
Average NLL Loss on Test Set: -0.0070
Average MAE on Test Set: 48697.6542
Average MAPE on Test Set: 21.0344
R^2 Score on Test Set: -3.2483
Model state saved successfully.