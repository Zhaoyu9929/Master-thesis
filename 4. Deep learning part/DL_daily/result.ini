[MODEL]
# Data parameter
seq_length = 7

# Model parameters
batch_size = 128
epochs = 30
learning_rate = 0.01
num_gaussians = 3

# LSTM parameters
lstm_hidden_layer_size = 12
dropout = 0.2

# MLP parameters
mlp_hidden_dim = 5

# EarlyStopping
patience = 9
delta = 0.05

# L2 regularization 
l2_lambda = 0.01

# Entropy regularization weight
entropy_weight = 0.05

Total windows created: 1
Total windows created: 2
Total windows created: 3
Total windows created: 4
Total windows created: 5
Average NLL Loss on Test Set: -0.6332
Average MAE on Test Set: 8752.1667
Average MAPE on Test Set: 24.65
R^2 Score on Test Set: -3.3135
Average PICP on Test Set: 60.42
Average Log-Likelihood on Test Set: -23.0259