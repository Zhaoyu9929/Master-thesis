[MODEL]
# Data parameter
seq_length = 7

# Model parameters
batch_size = 128
epochs = 25
learning_rate = 0.01
num_gaussians = 3

# LSTM parameters
lstm_hidden_layer_size = 50
dropout = 0.3
lstm_layer = 2

# MLP parameters
mlp_hidden_dim = 3

# EarlyStopping
patience = 9
delta = 0.05

# L2 regularization 
l2_lambda = 0.01

# Entropy regularization weight
entropy_weight = 0.05

# MDN 
mdn_hidden_layer = 64