{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from data_preprocessing import inverse_normalize_count, prepare_lstm_data\n",
    "import pickle\n",
    "from model import LSTMWithMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I wil predict the hourly traffic demand in a typical weekday to see traffic demand in each timeslots.\n",
    "I will choose 2020-01-01 as an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data needed for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanzh\\AppData\\Local\\Temp\\ipykernel_34648\\3770593789.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['total_trips'] = data['total_trips'].astype('float64')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n"
     ]
    }
   ],
   "source": [
    "# Load the data needed for lstm\n",
    "path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\4. Deep learning part\\2015-2019 total trips.csv\"\n",
    "df1 = pd.read_csv(path)\n",
    "df1['date'] = pd.to_datetime(df1['date'])\n",
    "df1['hour'] = df1['date'].dt.hour\n",
    "data = df1[df1['date'].dt.date == pd.to_datetime('2019-12-31').date()]\n",
    "# Convert the total_trip_count column to float64\n",
    "data['total_trips'] = data['total_trips'].astype('float64')\n",
    "\n",
    "# Normalize the total_trip_count column\n",
    "_, scaler = prepare_lstm_data()\n",
    "data.loc[:, 'total_trips'] = scaler.fit_transform(data[['total_trips']])\n",
    "\n",
    "# Create the sequence and convert the Pytorch tensor\n",
    "X_tensor = torch.tensor(data['total_trips'].values, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "X_lstm = X_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data needed for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scaler1.pkl', 'rb') as file:\n",
    "    loaded_scaler1 = pickle.load(file)\n",
    "\n",
    "with open('scaler2.pkl', 'rb') as file:\n",
    "    loaded_scaler2 = pickle.load(file)\n",
    "\n",
    "path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\4. Deep learning part\\predict MLP data.csv\"\n",
    "df2 = pd.read_csv(path)\n",
    "df2['date'] = pd.to_datetime(df2['date'])\n",
    "df2['hour'] = df2['date'].dt.hour\n",
    "df2['month'] = df2['date'].dt.month\n",
    "\n",
    "numeric_features1 = ['temperature_2m', 'CRASH COUNT']\n",
    "df2[numeric_features1] = loaded_scaler1.transform(df2[numeric_features1])\n",
    "\n",
    "numeric_features2 = ['precipitation', 'rain', 'snowfall', 'snow_depth', 'wind_speed_10m']\n",
    "df2[numeric_features2] = loaded_scaler2.transform(df2[numeric_features2])\n",
    "\n",
    "df2 = df2.drop(columns='date')\n",
    "mlp_tensor = torch.tensor(df2.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Predict the total traffic demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted total traffic demand is 1747.0\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = LSTMWithMLP(lstm_input_size=1, output_size=1, num_gaussians=5, mlp_input_dim=11)\n",
    "model.load_state_dict(torch.load('final_model_state.pth'))\n",
    "\n",
    "# Predict the demand\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pi, sigma, mu = model(X_lstm, mlp_tensor)\n",
    "\n",
    "mu = inverse_normalize_count(mu, scaler)\n",
    "mu = mu.flatten()  # Flatten mu to 1D array\n",
    "pi = pi.flatten()\n",
    "sigma = sigma.flatten()  # Convert sigma tensor to numpy and flatten\n",
    "\n",
    "# Create the DataFrame\n",
    "output = pd.DataFrame({\n",
    "    'demand': mu,\n",
    "    'probability': pi,\n",
    "    'volatility': sigma  \n",
    "})\n",
    "output\n",
    "\n",
    "max_demand = output.loc[output['probability'].idxmax(), 'demand']\n",
    "print(f'The predicted total traffic demand is {max_demand}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling remains necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Assign the traffic demand in specific route"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, given the total demand, we need calculate the probability of each route in specific route.\n",
    "\n",
    "We  will analyze the data from the first hour of January 1st for each year from 2015 to 2019, then get the probability of each specific scenario we defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>time_period</th>\n",
       "      <th>total_trip_count</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>last_20_min</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>middle_20_min</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>middle_20_min</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>41</td>\n",
       "      <td>middle_20_min</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>last_20_min</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8588</th>\n",
       "      <td>263</td>\n",
       "      <td>261</td>\n",
       "      <td>last_20_min</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8589</th>\n",
       "      <td>263</td>\n",
       "      <td>261</td>\n",
       "      <td>middle_20_min</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8590</th>\n",
       "      <td>263</td>\n",
       "      <td>262</td>\n",
       "      <td>first_20_min</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8591</th>\n",
       "      <td>263</td>\n",
       "      <td>262</td>\n",
       "      <td>last_20_min</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8592</th>\n",
       "      <td>263</td>\n",
       "      <td>262</td>\n",
       "      <td>middle_20_min</td>\n",
       "      <td>55</td>\n",
       "      <td>0.000662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8593 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PULocationID  DOLocationID    time_period  total_trip_count  probability\n",
       "0                4            13    last_20_min                 4     0.000048\n",
       "1                4            13  middle_20_min                 2     0.000024\n",
       "2                4            24  middle_20_min                 1     0.000012\n",
       "3                4            41  middle_20_min                 1     0.000012\n",
       "4                4            42    last_20_min                 2     0.000024\n",
       "...            ...           ...            ...               ...          ...\n",
       "8588           263           261    last_20_min                 1     0.000012\n",
       "8589           263           261  middle_20_min                 4     0.000048\n",
       "8590           263           262   first_20_min                33     0.000397\n",
       "8591           263           262    last_20_min                53     0.000638\n",
       "8592           263           262  middle_20_min                55     0.000662\n",
       "\n",
       "[8593 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\4. Deep learning part\\trip_counts_with_probability.csv\"\n",
    "data = pd.read_csv(path)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
