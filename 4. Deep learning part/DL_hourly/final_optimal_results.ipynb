{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e681720d-f277-4f74-8281-a1d702f2ff3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanzh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-07-18 16:19:33,058] A new study created in memory with name: no-name-81db34f6-90be-48a7-b329-8316f7a32b4c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.92465807229174, Val Loss: 0.6828830313620414\n",
      "Window 0 Epoch 5 Train Loss: -0.22461268436992746, Val Loss: 0.5528385698484608\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.5503601387935888, Val Loss: 0.5823238204086894\n",
      "Window 1 Epoch 5 Train Loss: -0.16337590852022701, Val Loss: 0.786279878675368\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.8741949364532889, Val Loss: 0.4774971008559707\n",
      "Window 2 Epoch 5 Train Loss: -0.24889930869214633, Val Loss: 0.19816763691610612\n",
      "Window 2 Epoch 10 Train Loss: -0.49802279006770717, Val Loss: 0.024458191874594817\n",
      "Window 3 Epoch 0 Train Loss: 0.9134904259740817, Val Loss: 0.5016491397063075\n",
      "Window 3 Epoch 5 Train Loss: -0.49637091315205845, Val Loss: 0.02272367705271412\n",
      "Window 3 Epoch 10 Train Loss: -0.8843126038827295, Val Loss: 0.045681293273779955\n",
      "Window 4 Epoch 0 Train Loss: 1.1418734201941123, Val Loss: 0.4999737666028153\n",
      "Window 4 Epoch 5 Train Loss: -0.3492102547048475, Val Loss: 0.085293860735451\n",
      "Window 4 Epoch 10 Train Loss: -0.4828149395133119, Val Loss: 0.19335370383295777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:24:08,071] Trial 0 finished with value: 0.1508722745607098 and parameters: {'lstm_hidden_layer_size': 119, 'mlp_hidden_dim': 16, 'learning_rate': 0.0001, 'dropout': 0.45, 'batch_size': 32, 'num_gaussians': 5, 'patience': 7}. Best is trial 0 with value: 0.1508722745607098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 3.0933344596208285, Val Loss: 3.595130668320312\n",
      "Window 0 Epoch 5 Train Loss: 2.84580007234319, Val Loss: 3.2226554088029107\n",
      "Window 0 Epoch 10 Train Loss: 2.6807538287179447, Val Loss: 2.8236386405189178\n",
      "Window 1 Epoch 0 Train Loss: 2.896763855878987, Val Loss: 1.136195549335198\n",
      "Window 1 Epoch 5 Train Loss: 2.694275432886667, Val Loss: 1.159430813416515\n",
      "Window 1 Epoch 10 Train Loss: 2.515027550365562, Val Loss: 1.173381917379298\n",
      "Window 2 Epoch 0 Train Loss: 3.8778690949270853, Val Loss: 3.3919873250038286\n",
      "Window 2 Epoch 5 Train Loss: 3.6004104018038716, Val Loss: 3.1458052700234953\n",
      "Window 2 Epoch 10 Train Loss: 3.3779924931277105, Val Loss: 2.913907512802336\n",
      "Window 3 Epoch 0 Train Loss: 2.9881690871684468, Val Loss: 1.4377946713817937\n",
      "Window 3 Epoch 5 Train Loss: 2.8370313397404123, Val Loss: 1.3442712537523562\n",
      "Window 3 Epoch 10 Train Loss: 2.636848453344198, Val Loss: 1.2728612736760794\n",
      "Window 4 Epoch 0 Train Loss: 1.618594182093562, Val Loss: 1.271640012722032\n",
      "Window 4 Epoch 5 Train Loss: 1.4932843096942023, Val Loss: 1.1746605744473733\n",
      "Window 4 Epoch 10 Train Loss: 1.3839179656445042, Val Loss: 1.081075454462517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:26:12,713] Trial 1 finished with value: 1.1378498184967483 and parameters: {'lstm_hidden_layer_size': 75, 'mlp_hidden_dim': 10, 'learning_rate': 1e-06, 'dropout': 0.4, 'batch_size': 64, 'num_gaussians': 5, 'patience': 9}. Best is trial 0 with value: 0.1508722745607098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.5175995042313246, Val Loss: 1.4218479638302668\n",
      "Window 0 Epoch 5 Train Loss: 0.517569745649895, Val Loss: 0.42155357343440053\n",
      "Window 0 Epoch 10 Train Loss: 0.14833181577954868, Val Loss: 0.2990528763531603\n",
      "Window 1 Epoch 0 Train Loss: 2.708625438672138, Val Loss: 1.8532221368040653\n",
      "Window 1 Epoch 5 Train Loss: 0.838248531802506, Val Loss: 0.5731948892724297\n",
      "Window 1 Epoch 10 Train Loss: 0.4761936348775092, Val Loss: 0.31104689253919754\n",
      "Window 2 Epoch 0 Train Loss: 1.9658806726280367, Val Loss: 1.4606336659705712\n",
      "Window 2 Epoch 5 Train Loss: 0.581196396469644, Val Loss: 1.152781023759618\n",
      "Window 2 Epoch 10 Train Loss: 0.15785146004889847, Val Loss: 1.244078441561045\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 3.8483827837625157, Val Loss: 2.4068825213832508\n",
      "Window 3 Epoch 5 Train Loss: 1.6725115426272468, Val Loss: 1.1825534729829152\n",
      "Window 3 Epoch 10 Train Loss: 1.1071582994624962, Val Loss: 0.85025354813328\n",
      "Window 4 Epoch 0 Train Loss: 2.4200033072719958, Val Loss: 2.199687253693515\n",
      "Window 4 Epoch 5 Train Loss: 0.6320694054751089, Val Loss: 0.3127301201470306\n",
      "Window 4 Epoch 10 Train Loss: -0.12051906758314902, Val Loss: -0.05782808690978381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:27:04,969] Trial 2 finished with value: 0.4394860436150017 and parameters: {'lstm_hidden_layer_size': 42, 'mlp_hidden_dim': 9, 'learning_rate': 0.0001, 'dropout': 0.15, 'batch_size': 256, 'num_gaussians': 3, 'patience': 7}. Best is trial 0 with value: 0.1508722745607098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.300139754921402, Val Loss: 1.573392678404973\n",
      "Window 0 Epoch 5 Train Loss: 1.9721302618630043, Val Loss: 1.3355700904446826\n",
      "Window 0 Epoch 10 Train Loss: 1.7664214649911298, Val Loss: 1.2303285499327499\n",
      "Window 1 Epoch 0 Train Loss: 2.1961536580811623, Val Loss: 2.126315247587905\n",
      "Window 1 Epoch 5 Train Loss: 1.9587718025072898, Val Loss: 1.9676966793530926\n",
      "Window 1 Epoch 10 Train Loss: 1.7544357286430043, Val Loss: 1.8165569154207444\n",
      "Window 2 Epoch 0 Train Loss: 1.8697450980378634, Val Loss: 1.9683107929992012\n",
      "Window 2 Epoch 5 Train Loss: 1.6326860152835998, Val Loss: 1.4615383728186429\n",
      "Window 2 Epoch 10 Train Loss: 1.4315042058461833, Val Loss: 1.1102963118424733\n",
      "Window 3 Epoch 0 Train Loss: 2.5612070818509998, Val Loss: 1.8401937751952302\n",
      "Window 3 Epoch 5 Train Loss: 2.1675953114137485, Val Loss: 1.4151249142132254\n",
      "Window 3 Epoch 10 Train Loss: 1.8912528367579828, Val Loss: 1.075151323857875\n",
      "Window 4 Epoch 0 Train Loss: 4.068033487050704, Val Loss: 3.07380011535333\n",
      "Window 4 Epoch 5 Train Loss: 3.2793190461783333, Val Loss: 2.6145052534926982\n",
      "Window 4 Epoch 10 Train Loss: 2.7291649771643685, Val Loss: 2.21293993207499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:27:55,110] Trial 3 finished with value: 2.461519036885451 and parameters: {'lstm_hidden_layer_size': 36, 'mlp_hidden_dim': 14, 'learning_rate': 1e-05, 'dropout': 0.1, 'batch_size': 256, 'num_gaussians': 9, 'patience': 7}. Best is trial 0 with value: 0.1508722745607098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 3.5512469360424856, Val Loss: 1.8281140559450841\n",
      "Window 0 Epoch 5 Train Loss: 1.5637403223244533, Val Loss: 1.4308824141475038\n",
      "Window 0 Epoch 10 Train Loss: 0.9817531813039299, Val Loss: 0.9166603409446498\n",
      "Window 1 Epoch 0 Train Loss: 1.6986581546592474, Val Loss: 0.9453126004630851\n",
      "Window 1 Epoch 5 Train Loss: 0.4530782322430341, Val Loss: 0.12887889139441616\n",
      "Window 1 Epoch 10 Train Loss: -0.08282809667638155, Val Loss: 0.36438068737163426\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 2.26063825768302, Val Loss: 1.3920565090626866\n",
      "Window 2 Epoch 5 Train Loss: 0.44085023691954156, Val Loss: 0.4377230315701429\n",
      "Window 2 Epoch 10 Train Loss: -0.0878013968295062, Val Loss: 0.31573485484027947\n",
      "Window 3 Epoch 0 Train Loss: 1.826181792264465, Val Loss: 1.3885963798915688\n",
      "Window 3 Epoch 5 Train Loss: 0.3243741159550964, Val Loss: 0.0975369679653365\n",
      "Window 3 Epoch 10 Train Loss: -0.1708940034060505, Val Loss: -0.05416537948328189\n",
      "Window 4 Epoch 0 Train Loss: 10.405911878164272, Val Loss: 2.212356258743644\n",
      "Window 4 Epoch 5 Train Loss: 1.6257712415853753, Val Loss: 1.6543482618679906\n",
      "Window 4 Epoch 10 Train Loss: 1.1948540753881778, Val Loss: 1.3694924638128405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:29:34,993] Trial 4 finished with value: 1.5664961872051117 and parameters: {'lstm_hidden_layer_size': 37, 'mlp_hidden_dim': 34, 'learning_rate': 0.0001, 'dropout': 0.3, 'batch_size': 64, 'num_gaussians': 2, 'patience': 4}. Best is trial 0 with value: 0.1508722745607098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 4.849369813199553, Val Loss: 2.1706267832466875\n",
      "Window 0 Epoch 5 Train Loss: 3.5158369652124817, Val Loss: 2.0104693484037055\n",
      "Window 0 Epoch 10 Train Loss: 2.9727038702956037, Val Loss: 1.965003137480788\n",
      "Window 1 Epoch 0 Train Loss: 6.823173098321517, Val Loss: 2.6224896597095824\n",
      "Window 1 Epoch 5 Train Loss: 5.057355143014006, Val Loss: 2.5754570695858847\n",
      "Window 1 Epoch 10 Train Loss: 4.54365498167651, Val Loss: 2.5674893868477007\n",
      "Window 2 Epoch 0 Train Loss: 3.816097115323939, Val Loss: 2.0795762621766065\n",
      "Window 2 Epoch 5 Train Loss: 3.909741749136883, Val Loss: 2.0862591339131216\n",
      "Window 2 Epoch 10 Train Loss: 3.5482288368008157, Val Loss: 2.0811988938693684\n",
      "Window 3 Epoch 0 Train Loss: 1103.0670038245182, Val Loss: 3.256154545486543\n",
      "Window 3 Epoch 5 Train Loss: 725.9985707271878, Val Loss: 2.352499045256839\n",
      "Window 3 Epoch 10 Train Loss: 297.66036541968157, Val Loss: 1.929285008424681\n",
      "Window 4 Epoch 0 Train Loss: 29.601500555644154, Val Loss: 3.765279875953336\n",
      "Window 4 Epoch 5 Train Loss: 15.072942389638035, Val Loss: 2.020771427220826\n",
      "Window 4 Epoch 10 Train Loss: 8.384179232973867, Val Loss: 1.3787187140056303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:33:08,224] Trial 5 finished with value: 1.961417133215024 and parameters: {'lstm_hidden_layer_size': 68, 'mlp_hidden_dim': 35, 'learning_rate': 1e-06, 'dropout': 0.25, 'batch_size': 32, 'num_gaussians': 1, 'patience': 3}. Best is trial 0 with value: 0.1508722745607098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.4397936711109225, Val Loss: 0.8233036447047773\n",
      "Window 0 Epoch 5 Train Loss: 0.06931508956981508, Val Loss: 0.37087001946700543\n",
      "Window 0 Epoch 10 Train Loss: -0.23580105321779826, Val Loss: 0.9522609076325941\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.3563726567687981, Val Loss: 0.7603086931202123\n",
      "Window 1 Epoch 5 Train Loss: -0.16608304772811977, Val Loss: 0.6244209855147593\n",
      "Window 1 Epoch 10 Train Loss: -0.348196128516903, Val Loss: 1.069513852755781\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.4632827734192146, Val Loss: 0.805721100312953\n",
      "Window 2 Epoch 5 Train Loss: 0.06239537721428043, Val Loss: 0.2232088275078998\n",
      "Window 2 Epoch 10 Train Loss: -0.1975363919009133, Val Loss: 0.20314878366440922\n",
      "Window 3 Epoch 0 Train Loss: 1.552731561870249, Val Loss: 0.7195407272835176\n",
      "Window 3 Epoch 5 Train Loss: -0.17602498932523342, Val Loss: 0.8767983432338095\n",
      "Window 3 Epoch 10 Train Loss: -0.4805194023402027, Val Loss: 1.638553766143726\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.0364704184047824, Val Loss: 0.5138847638636853\n",
      "Window 4 Epoch 5 Train Loss: -0.10730799001608322, Val Loss: 0.009007829179150658\n",
      "Window 4 Epoch 10 Train Loss: -0.464611648894581, Val Loss: -0.10657871932076124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:35:52,788] Trial 6 finished with value: 0.025518949258136095 and parameters: {'lstm_hidden_layer_size': 105, 'mlp_hidden_dim': 19, 'learning_rate': 0.0001, 'dropout': 0.3, 'batch_size': 64, 'num_gaussians': 10, 'patience': 10}. Best is trial 6 with value: 0.025518949258136095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.142795419686087, Val Loss: 1.2244746315282495\n",
      "Window 0 Epoch 5 Train Loss: 1.629778172618302, Val Loss: 1.3627877766727676\n",
      "Window 0 Epoch 10 Train Loss: 1.3901287923854118, Val Loss: 1.3137569176850372\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.764146916456776, Val Loss: 1.44484429231009\n",
      "Window 1 Epoch 5 Train Loss: 1.3382559034301125, Val Loss: 1.0754874264748588\n",
      "Window 1 Epoch 10 Train Loss: 1.1724801332872095, Val Loss: 1.0086520739372247\n",
      "Window 2 Epoch 0 Train Loss: 2.5665816525942433, Val Loss: 1.6821310170104875\n",
      "Window 2 Epoch 5 Train Loss: 1.6947956879972041, Val Loss: 0.9223235162002537\n",
      "Window 2 Epoch 10 Train Loss: 1.2728998982401052, Val Loss: 0.5255116023103845\n",
      "Window 3 Epoch 0 Train Loss: 2.4850336080399953, Val Loss: 1.5816775840018544\n",
      "Window 3 Epoch 5 Train Loss: 1.855332647107036, Val Loss: 1.335138364629472\n",
      "Window 3 Epoch 10 Train Loss: 1.6322856822897365, Val Loss: 1.2318459538974313\n",
      "Window 4 Epoch 0 Train Loss: 1.9788961873455513, Val Loss: 1.256122201862385\n",
      "Window 4 Epoch 5 Train Loss: 1.3446868721370913, Val Loss: 0.9700033000818447\n",
      "Window 4 Epoch 10 Train Loss: 1.0262493611912913, Val Loss: 0.7977666352025122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:37:21,247] Trial 7 finished with value: 0.9220558168989591 and parameters: {'lstm_hidden_layer_size': 72, 'mlp_hidden_dim': 13, 'learning_rate': 1e-05, 'dropout': 0.3, 'batch_size': 128, 'num_gaussians': 10, 'patience': 10}. Best is trial 6 with value: 0.025518949258136095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.7879854143874415, Val Loss: 0.7490147321147571\n",
      "Window 0 Epoch 5 Train Loss: -0.09678219832487867, Val Loss: 0.2545865800823987\n",
      "Window 0 Epoch 10 Train Loss: -0.29692464264373564, Val Loss: 0.42138681455242644\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.2059785298678685, Val Loss: 0.9095380317118766\n",
      "Window 1 Epoch 5 Train Loss: -0.11582177288832439, Val Loss: 0.42780973292971364\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.1936421524296283, Val Loss: 0.686734922858138\n",
      "Window 2 Epoch 5 Train Loss: -0.08260217173467609, Val Loss: 0.3395390315070347\n",
      "Window 2 Epoch 10 Train Loss: -0.3414696326319794, Val Loss: 0.5717273112693939\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.1001618204055128, Val Loss: 0.4692804006055373\n",
      "Window 3 Epoch 5 Train Loss: -0.2306750914477768, Val Loss: 0.07869178830904094\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.560137252607573, Val Loss: 0.4039610679982332\n",
      "Window 4 Epoch 5 Train Loss: -0.3881117587840222, Val Loss: -0.08010153556574333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:39:24,379] Trial 8 finished with value: 0.09018946598737726 and parameters: {'lstm_hidden_layer_size': 97, 'mlp_hidden_dim': 23, 'learning_rate': 0.0001, 'dropout': 0.2, 'batch_size': 64, 'num_gaussians': 8, 'patience': 4}. Best is trial 6 with value: 0.025518949258136095.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 10 Train Loss: -0.641301676908653, Val Loss: 0.29466195037826365\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.2879746463496885, Val Loss: 0.5972886918732438\n",
      "Window 0 Epoch 5 Train Loss: -0.4060819288288591, Val Loss: 0.7247188714252774\n",
      "Window 0 Epoch 10 Train Loss: -1.135471629293036, Val Loss: 0.1797159695034955\n",
      "Window 1 Epoch 0 Train Loss: 0.008716878208835417, Val Loss: 0.7243121835742174\n",
      "Window 1 Epoch 5 Train Loss: -1.0043109392261165, Val Loss: -0.7188176901624267\n",
      "Window 1 Epoch 10 Train Loss: -1.3737610876531436, Val Loss: -0.532465301110991\n",
      "Window 2 Epoch 0 Train Loss: 0.21217292421047346, Val Loss: 0.5468289056205418\n",
      "Window 2 Epoch 5 Train Loss: -0.8809987313846162, Val Loss: -0.45367892152531886\n",
      "Window 2 Epoch 10 Train Loss: -1.5143705662629474, Val Loss: -1.0711051863136756\n",
      "Window 3 Epoch 0 Train Loss: 0.22386128106574887, Val Loss: 0.9968222701787741\n",
      "Window 3 Epoch 5 Train Loss: -1.188615875963747, Val Loss: -0.3346357063740673\n",
      "Window 3 Epoch 10 Train Loss: -1.5501067896682093, Val Loss: -0.15979577438480227\n",
      "Window 4 Epoch 0 Train Loss: 0.3276322729395683, Val Loss: 0.2707842856671477\n",
      "Window 4 Epoch 5 Train Loss: -1.0264434804784708, Val Loss: -0.8519252962800962\n",
      "Window 4 Epoch 10 Train Loss: -1.5164246997099373, Val Loss: -1.10380358316917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:43:46,620] Trial 9 finished with value: -0.649362935773573 and parameters: {'lstm_hidden_layer_size': 96, 'mlp_hidden_dim': 25, 'learning_rate': 0.001, 'dropout': 0.1, 'batch_size': 32, 'num_gaussians': 6, 'patience': 6}. Best is trial 9 with value: -0.649362935773573.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.33675449687483644, Val Loss: 0.27451278253755396\n",
      "Window 0 Epoch 5 Train Loss: -0.43174945000597575, Val Loss: 1.248979367969556\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.2548982863387017, Val Loss: 0.3672082340271964\n",
      "Window 1 Epoch 5 Train Loss: -0.9694519232711449, Val Loss: -0.5818125457477819\n",
      "Window 1 Epoch 10 Train Loss: -1.2412642852281919, Val Loss: -1.2058645018694403\n",
      "Window 2 Epoch 0 Train Loss: 0.13215695498490512, Val Loss: 0.40933968156550266\n",
      "Window 2 Epoch 5 Train Loss: -1.066644006902513, Val Loss: -0.3967096124857431\n",
      "Window 2 Epoch 10 Train Loss: -1.4053600874257455, Val Loss: -0.6672360454042718\n",
      "Window 3 Epoch 0 Train Loss: 0.1448096526288337, Val Loss: 0.707966274846439\n",
      "Window 3 Epoch 5 Train Loss: -1.035154235939083, Val Loss: -0.19472792417095808\n",
      "Window 3 Epoch 10 Train Loss: -1.538147541124687, Val Loss: 0.01741394788984834\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.22411180123797575, Val Loss: 1.4351855031725222\n",
      "Window 4 Epoch 5 Train Loss: -0.9264964623617898, Val Loss: -0.8633233837517938\n",
      "Window 4 Epoch 10 Train Loss: -1.5378748931007242, Val Loss: -1.125724860008233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:48:43,481] Trial 10 finished with value: -0.662918860252322 and parameters: {'lstm_hidden_layer_size': 127, 'mlp_hidden_dim': 26, 'learning_rate': 0.001, 'dropout': 0.1, 'batch_size': 32, 'num_gaussians': 7, 'patience': 5}. Best is trial 10 with value: -0.662918860252322.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.18676981680110302, Val Loss: 0.6008562843867947\n",
      "Window 0 Epoch 5 Train Loss: -0.5016356492302668, Val Loss: 0.797514996846586\n",
      "Window 0 Epoch 10 Train Loss: -1.1877166420563752, Val Loss: 0.1772125402900781\n",
      "Window 1 Epoch 0 Train Loss: 0.5053321592588158, Val Loss: 0.5560274925778784\n",
      "Window 1 Epoch 5 Train Loss: -0.6239855853910669, Val Loss: -0.5081750456920197\n",
      "Window 1 Epoch 10 Train Loss: -1.3117711229813287, Val Loss: -1.2414772517778478\n",
      "Window 2 Epoch 0 Train Loss: 0.4112020485808838, Val Loss: 0.7200356257365746\n",
      "Window 2 Epoch 5 Train Loss: -0.8079344048611248, Val Loss: -0.5406173113296593\n",
      "Window 2 Epoch 10 Train Loss: -1.3991212933590895, Val Loss: -0.8607961137744264\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.24813571559498873, Val Loss: 0.49262792881833894\n",
      "Window 3 Epoch 5 Train Loss: -0.52436746221672, Val Loss: 0.9228887473055842\n",
      "Window 3 Epoch 10 Train Loss: -1.3756674274095781, Val Loss: 0.3703827357209319\n",
      "Window 4 Epoch 0 Train Loss: 0.18647736677121413, Val Loss: 0.24990284634506466\n",
      "Window 4 Epoch 5 Train Loss: -1.0917715359933475, Val Loss: -0.7948697737048337\n",
      "Window 4 Epoch 10 Train Loss: -1.6832430900104305, Val Loss: -1.4916678973636246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:54:12,031] Trial 11 finished with value: -0.7937419632224804 and parameters: {'lstm_hidden_layer_size': 123, 'mlp_hidden_dim': 27, 'learning_rate': 0.001, 'dropout': 0.1, 'batch_size': 32, 'num_gaussians': 7, 'patience': 5}. Best is trial 11 with value: -0.7937419632224804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.5122624073635099, Val Loss: 0.3494618038163819\n",
      "Window 0 Epoch 5 Train Loss: 0.07878256253585215, Val Loss: 1.1374967413089463\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.28534679330199847, Val Loss: 0.44343245767387074\n",
      "Window 1 Epoch 5 Train Loss: -0.899252654060015, Val Loss: -0.8430533336619519\n",
      "Window 1 Epoch 10 Train Loss: -1.320949740468322, Val Loss: -1.0400647886103904\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.16850630038995085, Val Loss: 0.5290057943449343\n",
      "Window 2 Epoch 5 Train Loss: -0.49544016352327813, Val Loss: 1.8940367137319\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.315482178072597, Val Loss: 0.07793539554061939\n",
      "Window 3 Epoch 5 Train Loss: -0.9248975120140248, Val Loss: -0.16221191008436897\n",
      "Window 3 Epoch 10 Train Loss: -1.4749850877132196, Val Loss: -0.17691229819785398\n",
      "Window 4 Epoch 0 Train Loss: 0.1277943801538035, Val Loss: 0.6623072251871708\n",
      "Window 4 Epoch 5 Train Loss: -1.1250704802911553, Val Loss: -0.7632250028729543\n",
      "Window 4 Epoch 10 Train Loss: -1.546920575643928, Val Loss: -1.1421427039039538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 16:58:28,281] Trial 12 finished with value: -0.6257515501050787 and parameters: {'lstm_hidden_layer_size': 128, 'mlp_hidden_dim': 29, 'learning_rate': 0.001, 'dropout': 0.1, 'batch_size': 32, 'num_gaussians': 7, 'patience': 5}. Best is trial 11 with value: -0.7937419632224804.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.6223709744393993, Val Loss: 0.6274336437159885\n",
      "Window 0 Epoch 5 Train Loss: -0.4931576987330122, Val Loss: 1.0048330017631724\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.17661135118072346, Val Loss: 0.8886686030105339\n",
      "Window 1 Epoch 5 Train Loss: -0.7358323299160816, Val Loss: -0.268886234737499\n",
      "Window 1 Epoch 10 Train Loss: -1.373445743919167, Val Loss: -1.2131750911966186\n",
      "Window 2 Epoch 0 Train Loss: 0.43196254683770163, Val Loss: 0.3646527473870616\n",
      "Window 2 Epoch 5 Train Loss: -0.3763123727350077, Val Loss: 0.2010859247640125\n",
      "Window 2 Epoch 10 Train Loss: -0.5126245961066573, Val Loss: 0.23388173596708542\n",
      "Window 3 Epoch 0 Train Loss: 0.4761348880947563, Val Loss: 0.474198131277497\n",
      "Window 3 Epoch 5 Train Loss: -1.2013942720554642, Val Loss: -0.9940254238768311\n",
      "Window 3 Epoch 10 Train Loss: -1.515120887855334, Val Loss: -0.6648097724421557\n",
      "Window 4 Epoch 0 Train Loss: 0.291848049946097, Val Loss: 0.32269401932466973\n",
      "Window 4 Epoch 5 Train Loss: -1.1883069533137864, Val Loss: -1.1580099855476003\n",
      "Window 4 Epoch 10 Train Loss: -1.7602661488495175, Val Loss: -1.411128312375212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:03:21,722] Trial 13 finished with value: -1.0391965232921139 and parameters: {'lstm_hidden_layer_size': 115, 'mlp_hidden_dim': 28, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 7, 'patience': 5}. Best is trial 13 with value: -1.0391965232921139.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.9414619330654529, Val Loss: 0.5144970929954075\n",
      "Window 0 Epoch 5 Train Loss: -0.2651999904749401, Val Loss: 0.7513797649293231\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.652655861150278, Val Loss: 0.713803800730784\n",
      "Window 1 Epoch 5 Train Loss: -0.2782830765886842, Val Loss: 0.5384612942549791\n",
      "Window 1 Epoch 10 Train Loss: -0.4078675676603005, Val Loss: 0.6782528233983846\n",
      "Window 2 Epoch 0 Train Loss: 1.9040981746840986, Val Loss: 0.5971804663059921\n",
      "Window 2 Epoch 5 Train Loss: -0.2086403540165553, Val Loss: 0.1492956022818538\n",
      "Window 2 Epoch 10 Train Loss: -0.8932262859289695, Val Loss: -0.5919570366161787\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 1.2833100176115368, Val Loss: 0.6231723504932314\n",
      "Window 3 Epoch 5 Train Loss: -0.30360261595673893, Val Loss: 0.4100277046086372\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.7420457740127896, Val Loss: 0.5060113636076088\n",
      "Window 4 Epoch 5 Train Loss: -0.35379609356757424, Val Loss: -0.2158836477948312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:04:56,766] Trial 14 finished with value: 0.4882559541410725 and parameters: {'lstm_hidden_layer_size': 110, 'mlp_hidden_dim': 30, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 128, 'num_gaussians': 4, 'patience': 5}. Best is trial 13 with value: -1.0391965232921139.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 10 Train Loss: -0.5188659687345871, Val Loss: 0.533387009109444\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.49261431282777707, Val Loss: 0.46615105215540975\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.41300438089243885, Val Loss: 0.6038188730551821\n",
      "Window 1 Epoch 5 Train Loss: -0.9600299694161278, Val Loss: -0.9752745762998182\n",
      "Window 1 Epoch 10 Train Loss: -1.5208595438538526, Val Loss: -1.5923435660054848\n",
      "Window 2 Epoch 0 Train Loss: 0.6777530432299917, Val Loss: 0.49849642325131194\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.5062185446510987, Val Loss: 0.18040864967088094\n",
      "Window 3 Epoch 5 Train Loss: -1.2673885767853743, Val Loss: -1.0127701306736645\n",
      "Window 3 Epoch 10 Train Loss: -1.5030675600011734, Val Loss: -1.0651968652325854\n",
      "Window 4 Epoch 0 Train Loss: 0.41400383160768517, Val Loss: 0.03241230122790349\n",
      "Window 4 Epoch 5 Train Loss: -1.2897752812208674, Val Loss: -1.245531072832003\n",
      "Window 4 Epoch 10 Train Loss: -1.7922085771646303, Val Loss: -1.6801634642686356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:08:16,316] Trial 15 finished with value: -1.1308255674962098 and parameters: {'lstm_hidden_layer_size': 87, 'mlp_hidden_dim': 22, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 8, 'patience': 3}. Best is trial 15 with value: -1.1308255674962098.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: -0.08036827694193396, Val Loss: 0.29397217146113686\n",
      "Window 0 Epoch 5 Train Loss: -1.2614966682270363, Val Loss: -1.3602253155124178\n",
      "Window 0 Epoch 10 Train Loss: -1.513135884194182, Val Loss: -1.6121374507451658\n",
      "Window 1 Epoch 0 Train Loss: -0.011223755579053682, Val Loss: 1.1904647359632596\n",
      "Window 1 Epoch 5 Train Loss: -0.9423624573152614, Val Loss: -0.9316563290373125\n",
      "Window 1 Epoch 10 Train Loss: -1.4360339767030277, Val Loss: -1.5199627070505655\n",
      "Window 2 Epoch 0 Train Loss: 0.09674907236229537, Val Loss: 0.5743334257633763\n",
      "Window 2 Epoch 5 Train Loss: -0.3706401896785214, Val Loss: 0.29280756810092595\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.4825250626781496, Val Loss: -0.09316498843821933\n",
      "Window 3 Epoch 5 Train Loss: -1.0347498284754082, Val Loss: -1.2017709236368732\n",
      "Window 3 Epoch 10 Train Loss: -1.687803195574183, Val Loss: -1.7453077909327093\n",
      "Window 4 Epoch 0 Train Loss: 0.18106770104678013, Val Loss: -0.0076530821440170165\n",
      "Window 4 Epoch 5 Train Loss: -1.3366802200751264, Val Loss: -1.2893900521209611\n",
      "Window 4 Epoch 10 Train Loss: -1.8154614151266535, Val Loss: -1.8318852362272326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:12:12,810] Trial 16 finished with value: -1.233438421162037 and parameters: {'lstm_hidden_layer_size': 87, 'mlp_hidden_dim': 4, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 8, 'patience': 3}. Best is trial 16 with value: -1.233438421162037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.22516632859162686, Val Loss: 0.3018550583582977\n",
      "Window 0 Epoch 5 Train Loss: -1.12775700157002, Val Loss: -0.6041556706022533\n",
      "Window 0 Epoch 10 Train Loss: -1.4697796270241203, Val Loss: -1.5473752273465113\n",
      "Window 1 Epoch 0 Train Loss: 0.3009096924846808, Val Loss: 0.8891302933390507\n",
      "Window 1 Epoch 5 Train Loss: -0.959400543975959, Val Loss: -1.0124676883168888\n",
      "Window 1 Epoch 10 Train Loss: -1.4517849230266762, Val Loss: -1.5103569684289622\n",
      "Window 2 Epoch 0 Train Loss: -0.023124791839309926, Val Loss: 0.3110622387673936\n",
      "Window 2 Epoch 5 Train Loss: -1.4482633972807926, Val Loss: -1.394018183885503\n",
      "Window 2 Epoch 10 Train Loss: -1.6849763542802174, Val Loss: -1.6117379299771983\n",
      "Window 3 Epoch 0 Train Loss: 0.13565727259916632, Val Loss: 0.36291599542964137\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.14456561076849306, Val Loss: 0.2035254556701869\n",
      "Window 4 Epoch 5 Train Loss: -0.5524366539371995, Val Loss: -0.26758205095754306\n",
      "Window 4 Epoch 10 Train Loss: -1.4726723310764869, Val Loss: -1.4453714532918458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:15:51,760] Trial 17 finished with value: -0.7385477439138705 and parameters: {'lstm_hidden_layer_size': 85, 'mlp_hidden_dim': 4, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 9, 'patience': 3}. Best is trial 16 with value: -1.233438421162037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.652455829404042, Val Loss: 0.49044646999817326\n",
      "Window 0 Epoch 5 Train Loss: -0.36898062105884166, Val Loss: 1.2138150230270173\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 1.5076045755531102, Val Loss: 0.4905905815231396\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.9252616223525135, Val Loss: 0.3044241229986544\n",
      "Window 2 Epoch 5 Train Loss: -0.3477215505801907, Val Loss: 0.10241780454029113\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.6233043308520255, Val Loss: 0.31741053896505456\n",
      "Window 3 Epoch 5 Train Loss: -0.5470691754618379, Val Loss: 0.7491730376495473\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.4693483985925234, Val Loss: 0.24438107765476333\n",
      "Window 4 Epoch 5 Train Loss: -0.9356078283833044, Val Loss: -0.7943847932368129\n",
      "Window 4 Epoch 10 Train Loss: -1.3269350117694183, Val Loss: -1.2501403875292953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:16:46,167] Trial 18 finished with value: -0.8068964899969907 and parameters: {'lstm_hidden_layer_size': 57, 'mlp_hidden_dim': 20, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 128, 'num_gaussians': 9, 'patience': 3}. Best is trial 16 with value: -1.233438421162037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 3.2707890305634666, Val Loss: 3.8717347670388573\n",
      "Window 0 Epoch 5 Train Loss: 2.9694121092963637, Val Loss: 3.445105152685263\n",
      "Window 0 Epoch 10 Train Loss: 2.763145476196958, Val Loss: 3.16915390493557\n",
      "Window 1 Epoch 0 Train Loss: 3.2062127172595876, Val Loss: 2.7411324544951357\n",
      "Window 1 Epoch 5 Train Loss: 3.1243123837830398, Val Loss: 2.67072462227736\n",
      "Window 1 Epoch 10 Train Loss: 3.0713619666519896, Val Loss: 2.6051646614986126\n",
      "Window 2 Epoch 0 Train Loss: 1.9227068805206555, Val Loss: 1.3417887459828686\n",
      "Window 2 Epoch 5 Train Loss: 1.8333485436230033, Val Loss: 1.3121985651740398\n",
      "Window 2 Epoch 10 Train Loss: 1.754563527147754, Val Loss: 1.2834322309618302\n",
      "Window 3 Epoch 0 Train Loss: 1.6727324087117714, Val Loss: 1.5159997004824655\n",
      "Window 3 Epoch 5 Train Loss: 1.6254674185193665, Val Loss: 1.4803523292342649\n",
      "Window 3 Epoch 10 Train Loss: 1.59663303553097, Val Loss: 1.4444331063279683\n",
      "Window 4 Epoch 0 Train Loss: 1.8453799897643537, Val Loss: 1.6723790537472085\n",
      "Window 4 Epoch 5 Train Loss: 1.8157559889928478, Val Loss: 1.609709988564227\n",
      "Window 4 Epoch 10 Train Loss: 1.771029517309217, Val Loss: 1.55116080709585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:17:54,915] Trial 19 finished with value: 1.587412983771169 and parameters: {'lstm_hidden_layer_size': 84, 'mlp_hidden_dim': 4, 'learning_rate': 1e-06, 'dropout': 0.35, 'batch_size': 256, 'num_gaussians': 8, 'patience': 4}. Best is trial 16 with value: -1.233438421162037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 3.0060270403968534, Val Loss: 1.0470353960473056\n",
      "Window 0 Epoch 5 Train Loss: 1.1798152157994923, Val Loss: 0.5348120156730599\n",
      "Window 0 Epoch 10 Train Loss: 0.8325338483294131, Val Loss: 0.5634021374787795\n",
      "Window 1 Epoch 0 Train Loss: 2.329603971242099, Val Loss: 1.8145370019403984\n",
      "Window 1 Epoch 5 Train Loss: 0.8838551401389869, Val Loss: 0.8645173629711858\n",
      "Window 1 Epoch 10 Train Loss: 0.6210248708160985, Val Loss: 0.6768274011040231\n",
      "Window 2 Epoch 0 Train Loss: 0.9447922010535472, Val Loss: 1.1215191780226217\n",
      "Window 2 Epoch 5 Train Loss: 0.22316631622108193, Val Loss: 0.5182681531361348\n",
      "Window 2 Epoch 10 Train Loss: -0.010829052156700849, Val Loss: 0.38222860370792583\n",
      "Window 3 Epoch 0 Train Loss: 2.0293770890398424, Val Loss: 1.4061210157558464\n",
      "Window 3 Epoch 5 Train Loss: 0.8276857458406794, Val Loss: 0.6218170773765505\n",
      "Window 3 Epoch 10 Train Loss: 0.5007069282599877, Val Loss: 0.4463038065969996\n",
      "Window 4 Epoch 0 Train Loss: 1.946454083331363, Val Loss: 1.4278757520388976\n",
      "Window 4 Epoch 5 Train Loss: 0.5634421185025886, Val Loss: 0.20969199348438522\n",
      "Window 4 Epoch 10 Train Loss: 0.16001503297729452, Val Loss: -0.03320982744779719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:22:41,753] Trial 20 finished with value: 0.2408753731742484 and parameters: {'lstm_hidden_layer_size': 60, 'mlp_hidden_dim': 20, 'learning_rate': 1e-05, 'dropout': 0.2, 'batch_size': 32, 'num_gaussians': 6, 'patience': 3}. Best is trial 16 with value: -1.233438421162037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.37658175483973283, Val Loss: 0.2694414299722602\n",
      "Window 0 Epoch 5 Train Loss: -1.03688119231728, Val Loss: -0.37984642725628837\n",
      "Window 0 Epoch 10 Train Loss: -1.4039543398423142, Val Loss: -1.2815176454655095\n",
      "Window 1 Epoch 0 Train Loss: 0.7768806757712394, Val Loss: 0.7346396042304283\n",
      "Window 1 Epoch 5 Train Loss: -0.6787219181868334, Val Loss: -0.04919164883479359\n",
      "Window 1 Epoch 10 Train Loss: -1.4234345905152574, Val Loss: -1.4929559099270302\n",
      "Window 2 Epoch 0 Train Loss: 0.597343415361442, Val Loss: 0.6143286080851336\n",
      "Window 2 Epoch 5 Train Loss: -0.428872847883377, Val Loss: 0.4610242910042314\n",
      "Window 2 Epoch 10 Train Loss: -1.3224559700649035, Val Loss: -0.9418316701512871\n",
      "Window 3 Epoch 0 Train Loss: 0.42209230396604175, Val Loss: 0.3662765698780918\n",
      "Window 3 Epoch 5 Train Loss: -1.2454322469940031, Val Loss: -0.44505401500715164\n",
      "Window 3 Epoch 10 Train Loss: -1.5226851910643335, Val Loss: -0.2550161961857699\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.5469518658570443, Val Loss: -0.06365524834389276\n",
      "Window 4 Epoch 5 Train Loss: -0.8324103266723002, Val Loss: -0.42660837552528813\n",
      "Window 4 Epoch 10 Train Loss: -1.636298900798353, Val Loss: -1.358987487263518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:26:59,816] Trial 21 finished with value: -0.6961690977618488 and parameters: {'lstm_hidden_layer_size': 93, 'mlp_hidden_dim': 23, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 8, 'patience': 4}. Best is trial 16 with value: -1.233438421162037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.42138591971641526, Val Loss: 0.7111977419057791\n",
      "Window 0 Epoch 5 Train Loss: -0.616801440836645, Val Loss: 1.9194420865056414\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.5017618887342978, Val Loss: 0.6899590959609021\n",
      "Window 1 Epoch 5 Train Loss: -0.7658358715360225, Val Loss: -0.3691329144582243\n",
      "Window 1 Epoch 10 Train Loss: -1.4731922395512256, Val Loss: -1.5727843783608113\n",
      "Window 2 Epoch 0 Train Loss: 0.48841291405616655, Val Loss: 0.48178550645022883\n",
      "Window 2 Epoch 5 Train Loss: -1.0478179183742466, Val Loss: -0.9552847368110272\n",
      "Window 2 Epoch 10 Train Loss: -1.4867575481451996, Val Loss: -1.228684572009394\n",
      "Window 3 Epoch 0 Train Loss: 0.4832674109270769, Val Loss: 0.09843240115794796\n",
      "Window 3 Epoch 5 Train Loss: -0.7124345235478363, Val Loss: 0.7301249422268905\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.5848651031470844, Val Loss: 0.3935274303891574\n",
      "Window 4 Epoch 5 Train Loss: -0.5716132648642417, Val Loss: 0.70620638626643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:30:25,093] Trial 22 finished with value: 0.5277156936377773 and parameters: {'lstm_hidden_layer_size': 112, 'mlp_hidden_dim': 30, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 7, 'patience': 6}. Best is trial 16 with value: -1.233438421162037.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.41042694582509365, Val Loss: 0.48802241248011485\n",
      "Window 0 Epoch 5 Train Loss: -0.6089088572053429, Val Loss: 0.1984848396918962\n",
      "Window 0 Epoch 10 Train Loss: -1.3349736816717113, Val Loss: -1.0651402395772065\n",
      "Window 1 Epoch 0 Train Loss: 0.26699710306202085, Val Loss: 0.16825764606845162\n",
      "Window 1 Epoch 5 Train Loss: -1.1764708390345937, Val Loss: -0.9508397695191729\n",
      "Window 1 Epoch 10 Train Loss: -1.5012855917212469, Val Loss: -1.400078709906438\n",
      "Window 2 Epoch 0 Train Loss: 0.5574003411457842, Val Loss: 0.464474305135079\n",
      "Window 2 Epoch 5 Train Loss: -1.1110971881303477, Val Loss: -0.9895614066608671\n",
      "Window 2 Epoch 10 Train Loss: -1.4620141242937863, Val Loss: -1.0699912378002931\n",
      "Window 3 Epoch 0 Train Loss: 0.34857220851849596, Val Loss: 0.11563720306192243\n",
      "Window 3 Epoch 5 Train Loss: -1.1599347993099887, Val Loss: -0.325007424574122\n",
      "Window 3 Epoch 10 Train Loss: -1.4953278939075034, Val Loss: -0.2841455957663774\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.07106294733145482, Val Loss: 0.18696676028308198\n",
      "Window 4 Epoch 5 Train Loss: -1.3348247135561429, Val Loss: -1.397139006754712\n",
      "Window 4 Epoch 10 Train Loss: -1.8662426252099, Val Loss: -1.8592662445676524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:34:59,060] Trial 23 finished with value: -1.4128742150589069 and parameters: {'lstm_hidden_layer_size': 89, 'mlp_hidden_dim': 17, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 8, 'patience': 8}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.45368832516528657, Val Loss: 0.29910471882641987\n",
      "Window 0 Epoch 5 Train Loss: -1.0071365433884736, Val Loss: -0.29999502535284756\n",
      "Window 0 Epoch 10 Train Loss: -1.332373717467251, Val Loss: -0.09561674124670484\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: -0.06280958537827752, Val Loss: 0.34361976152083645\n",
      "Window 1 Epoch 5 Train Loss: -1.0661901915707597, Val Loss: -0.8323602087077216\n",
      "Window 1 Epoch 10 Train Loss: -1.4067783640585916, Val Loss: -0.9293131214136874\n",
      "Window 2 Epoch 0 Train Loss: 0.30420122607755445, Val Loss: 0.45471807918167445\n",
      "Window 2 Epoch 5 Train Loss: -0.5738935211893328, Val Loss: -0.5515509752166675\n",
      "Window 2 Epoch 10 Train Loss: -1.3907129619875918, Val Loss: -0.7445947422761693\n",
      "Window 3 Epoch 0 Train Loss: 0.011264615350044912, Val Loss: 0.901574149947908\n",
      "Window 3 Epoch 5 Train Loss: -1.119121620573799, Val Loss: -0.43174252494017423\n",
      "Window 3 Epoch 10 Train Loss: -1.503091380427424, Val Loss: 0.013788220521991508\n",
      "Window 4 Epoch 0 Train Loss: -0.09366006917364524, Val Loss: 0.5696729068311788\n",
      "Window 4 Epoch 5 Train Loss: -1.0836793130643696, Val Loss: -0.6975418006617747\n",
      "Window 4 Epoch 10 Train Loss: -1.7790700250050846, Val Loss: -1.2026935064927273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:39:31,029] Trial 24 finished with value: -0.7480555908630938 and parameters: {'lstm_hidden_layer_size': 89, 'mlp_hidden_dim': 9, 'learning_rate': 0.001, 'dropout': 0.15, 'batch_size': 32, 'num_gaussians': 9, 'patience': 8}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.7003683552089847, Val Loss: 0.37836425652408684\n",
      "Window 0 Epoch 5 Train Loss: -0.5288139133422523, Val Loss: 1.9500663856337321\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.3714871530086478, Val Loss: 0.6389932696918733\n",
      "Window 1 Epoch 5 Train Loss: -0.8738186552140823, Val Loss: -0.7864865952217507\n",
      "Window 1 Epoch 10 Train Loss: -1.4451647015442959, Val Loss: -1.5327215655589497\n",
      "Window 2 Epoch 0 Train Loss: 0.5734825391324893, Val Loss: 0.3779075169413117\n",
      "Window 2 Epoch 5 Train Loss: -0.7110956254337611, Val Loss: -0.22707294035123599\n",
      "Window 2 Epoch 10 Train Loss: -1.4713822043608478, Val Loss: -1.3074450855354554\n",
      "Window 3 Epoch 0 Train Loss: 0.8627956303891683, Val Loss: 0.2889295607339186\n",
      "Window 3 Epoch 5 Train Loss: -0.7149066367560951, Val Loss: 1.7152163519432604\n",
      "Window 3 Epoch 10 Train Loss: -1.480848775633263, Val Loss: -0.5840587407272863\n",
      "Window 4 Epoch 0 Train Loss: 0.4840147540072533, Val Loss: 0.09171931307720786\n",
      "Window 4 Epoch 5 Train Loss: -0.551569027014194, Val Loss: 0.7335627697324049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:43:36,585] Trial 25 finished with value: 0.8003054683709228 and parameters: {'lstm_hidden_layer_size': 102, 'mlp_hidden_dim': 18, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 8, 'patience': 8}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: -0.062848506477552, Val Loss: 0.647949440338423\n",
      "Window 0 Epoch 5 Train Loss: -0.6151598340712011, Val Loss: 1.145598344343005\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.32385997826616036, Val Loss: 0.20571329809084443\n",
      "Window 1 Epoch 5 Train Loss: -1.1771468555097404, Val Loss: -0.830752504586552\n",
      "Window 1 Epoch 10 Train Loss: -1.540093623752747, Val Loss: -1.5568201221868745\n",
      "Window 2 Epoch 0 Train Loss: 0.5043912577654411, Val Loss: 0.35474195513230217\n",
      "Window 2 Epoch 5 Train Loss: -1.0496581935383034, Val Loss: -0.519888724532985\n",
      "Window 2 Epoch 10 Train Loss: -1.4413286822291314, Val Loss: -0.8595532317144989\n",
      "Window 3 Epoch 0 Train Loss: 0.5077796129487686, Val Loss: 0.3889299617913575\n",
      "Window 3 Epoch 5 Train Loss: -0.7665124649164518, Val Loss: -0.6349865634165879\n",
      "Window 3 Epoch 10 Train Loss: -1.4118699841694078, Val Loss: -0.8350991243698823\n",
      "Window 4 Epoch 0 Train Loss: 0.05017668461795593, Val Loss: 0.027769082207248896\n",
      "Window 4 Epoch 5 Train Loss: -1.5031847438147437, Val Loss: -1.3414174184708052\n",
      "Window 4 Epoch 10 Train Loss: -1.693155259875196, Val Loss: -1.486745904467605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:47:17,031] Trial 26 finished with value: -1.1796417220801227 and parameters: {'lstm_hidden_layer_size': 79, 'mlp_hidden_dim': 7, 'learning_rate': 0.001, 'dropout': 0.25, 'batch_size': 32, 'num_gaussians': 10, 'patience': 8}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.5403831002449131, Val Loss: 0.4445683987994074\n",
      "Window 0 Epoch 5 Train Loss: -0.467215685240951, Val Loss: 0.720641747233559\n",
      "Window 0 Epoch 10 Train Loss: -0.5884773838274887, Val Loss: 1.0713866277946584\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.49952173346405937, Val Loss: 0.37559566023451263\n",
      "Window 1 Epoch 5 Train Loss: -0.24404664189587394, Val Loss: 0.5709082907329529\n",
      "Window 1 Epoch 10 Train Loss: -0.3557465369434123, Val Loss: 0.4528516089263737\n",
      "Window 2 Epoch 0 Train Loss: 1.0090472125415464, Val Loss: 0.48634446286098737\n",
      "Window 2 Epoch 5 Train Loss: -0.015012974937967874, Val Loss: 0.30372975700632787\n",
      "Window 2 Epoch 10 Train Loss: 0.04374749849024334, Val Loss: 0.3983899123973167\n",
      "Window 3 Epoch 0 Train Loss: 0.6884542067699869, Val Loss: 0.574872653656271\n",
      "Window 3 Epoch 5 Train Loss: -0.3694107960263965, Val Loss: 0.3320238232664395\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.5416828750746815, Val Loss: 0.6800720816482988\n",
      "Window 4 Epoch 5 Train Loss: -0.32497014845558214, Val Loss: 0.21494501157559384\n",
      "Window 4 Epoch 10 Train Loss: -0.7617299805463735, Val Loss: 0.4147018715803982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:48:16,755] Trial 27 finished with value: 0.2286307146995526 and parameters: {'lstm_hidden_layer_size': 78, 'mlp_hidden_dim': 6, 'learning_rate': 0.001, 'dropout': 0.25, 'batch_size': 256, 'num_gaussians': 10, 'patience': 8}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.2883786828612065, Val Loss: 1.497367809587308\n",
      "Window 0 Epoch 5 Train Loss: 1.2381933384953612, Val Loss: 1.4719305482768266\n",
      "Window 0 Epoch 10 Train Loss: 1.1907222612928305, Val Loss: 1.4442545574297603\n",
      "Window 1 Epoch 0 Train Loss: 4.963063736961905, Val Loss: 3.7619833819872395\n",
      "Window 1 Epoch 5 Train Loss: 4.750603240118923, Val Loss: 3.5883002770040267\n",
      "Window 1 Epoch 10 Train Loss: 4.535636146038417, Val Loss: 3.42297024482442\n",
      "Window 2 Epoch 0 Train Loss: 2.177534861466571, Val Loss: 1.158156021898669\n",
      "Window 2 Epoch 5 Train Loss: 1.9729499867078224, Val Loss: 1.136942883867683\n",
      "Window 2 Epoch 10 Train Loss: 1.842119102774065, Val Loss: 1.1276997959582729\n",
      "Window 3 Epoch 0 Train Loss: 1.109670857774529, Val Loss: 1.1296967937053544\n",
      "Window 3 Epoch 5 Train Loss: 1.078687723935013, Val Loss: 1.090502318354092\n",
      "Window 3 Epoch 10 Train Loss: 1.049957651687748, Val Loss: 1.052267061638687\n",
      "Window 4 Epoch 0 Train Loss: 1.9435033902153265, Val Loss: 1.6720949148323927\n",
      "Window 4 Epoch 5 Train Loss: 1.8510837916921807, Val Loss: 1.617563689614668\n",
      "Window 4 Epoch 10 Train Loss: 1.7539400693312959, Val Loss: 1.5638810714154943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:49:56,507] Trial 28 finished with value: 1.5963507548643474 and parameters: {'lstm_hidden_layer_size': 61, 'mlp_hidden_dim': 7, 'learning_rate': 1e-06, 'dropout': 0.25, 'batch_size': 128, 'num_gaussians': 10, 'patience': 9}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.6445871272395105, Val Loss: 1.5539554575026087\n",
      "Window 0 Epoch 5 Train Loss: 0.996870364676206, Val Loss: 0.8250542428574285\n",
      "Window 0 Epoch 10 Train Loss: 0.7026433555145482, Val Loss: 0.6965300556786883\n",
      "Window 1 Epoch 0 Train Loss: 1.563656292839194, Val Loss: 1.1356871416007406\n",
      "Window 1 Epoch 5 Train Loss: 0.6301675198494128, Val Loss: 0.6443496009352723\n",
      "Window 1 Epoch 10 Train Loss: 0.41097258353217225, Val Loss: 0.5205537928486782\n",
      "Window 2 Epoch 0 Train Loss: 2.0788093210590315, Val Loss: 1.2593245037113656\n",
      "Window 2 Epoch 5 Train Loss: 0.7009776626082591, Val Loss: 0.5885657665006603\n",
      "Window 2 Epoch 10 Train Loss: 0.4375782978313706, Val Loss: 0.4875260588917703\n",
      "Window 3 Epoch 0 Train Loss: 2.397464488019259, Val Loss: 2.3183694768221246\n",
      "Window 3 Epoch 5 Train Loss: 1.0001724272825387, Val Loss: 1.1032116689648865\n",
      "Window 3 Epoch 10 Train Loss: 0.5534967470810176, Val Loss: 0.6954660356614405\n",
      "Window 4 Epoch 0 Train Loss: 2.744002698378707, Val Loss: 1.3439607462812568\n",
      "Window 4 Epoch 5 Train Loss: 1.4745788011724015, Val Loss: 0.728299037877836\n",
      "Window 4 Epoch 10 Train Loss: 1.1649132784446303, Val Loss: 0.5149885821249255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:53:37,023] Trial 29 finished with value: 0.7202997674760424 and parameters: {'lstm_hidden_layer_size': 68, 'mlp_hidden_dim': 13, 'learning_rate': 1e-05, 'dropout': 0.45, 'batch_size': 32, 'num_gaussians': 6, 'patience': 9}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.15437431272777152, Val Loss: 0.46876931413166634\n",
      "Window 0 Epoch 5 Train Loss: -0.5896542907693482, Val Loss: 0.8573282288013594\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.9508793283463607, Val Loss: 0.5402098228421862\n",
      "Window 1 Epoch 5 Train Loss: -0.48396539243823533, Val Loss: 0.31281446668762003\n",
      "Window 1 Epoch 10 Train Loss: -1.232353881069094, Val Loss: -1.089232396085194\n",
      "Window 2 Epoch 0 Train Loss: 0.7333159653608939, Val Loss: 0.36726338775597067\n",
      "Window 2 Epoch 5 Train Loss: -0.8259832608351045, Val Loss: -0.35109259044471564\n",
      "Window 2 Epoch 10 Train Loss: -1.5346459011618576, Val Loss: -0.9274647918397918\n",
      "Window 3 Epoch 0 Train Loss: 0.23618033679828596, Val Loss: -0.00022461811496474036\n",
      "Window 3 Epoch 5 Train Loss: -1.156048671969279, Val Loss: -1.0849280621464825\n",
      "Window 3 Epoch 10 Train Loss: -1.6453096728832712, Val Loss: -1.7630911579761788\n",
      "Window 4 Epoch 0 Train Loss: 0.568990163521623, Val Loss: 0.45198765345286745\n",
      "Window 4 Epoch 5 Train Loss: -0.5500272817509025, Val Loss: 0.34930801890033103\n",
      "Window 4 Epoch 10 Train Loss: -1.5152046396958618, Val Loss: -1.4362591413908892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:56:01,704] Trial 30 finished with value: -0.597101676851606 and parameters: {'lstm_hidden_layer_size': 48, 'mlp_hidden_dim': 16, 'learning_rate': 0.001, 'dropout': 0.45, 'batch_size': 32, 'num_gaussians': 9, 'patience': 8}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.24364807333633018, Val Loss: 0.49443166891354046\n",
      "Window 0 Epoch 5 Train Loss: -0.5710000067393937, Val Loss: 1.5996778937239526\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: -0.0919659305484389, Val Loss: 0.211663194615669\n",
      "Window 1 Epoch 5 Train Loss: -1.3500672376465472, Val Loss: -1.0903419915952441\n",
      "Window 1 Epoch 10 Train Loss: -1.5649688114263127, Val Loss: -1.1785394807777438\n",
      "Window 2 Epoch 0 Train Loss: 0.35914161230153396, Val Loss: 0.44909691448112243\n",
      "Window 2 Epoch 5 Train Loss: -0.9320939253388748, Val Loss: -1.1354142362195239\n",
      "Window 2 Epoch 10 Train Loss: -1.3768552111142895, Val Loss: -1.0995168907553294\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: -0.2695304405951668, Val Loss: 0.26948615613447696\n",
      "Window 3 Epoch 5 Train Loss: -0.9823618644773471, Val Loss: 0.7277990223453109\n",
      "Window 3 Epoch 10 Train Loss: -1.5491316726887514, Val Loss: -0.026565692406131537\n",
      "Window 4 Epoch 0 Train Loss: 0.21732258918266492, Val Loss: 0.4768825347893762\n",
      "Window 4 Epoch 5 Train Loss: -1.1529956210174075, Val Loss: -1.1358805504392064\n",
      "Window 4 Epoch 10 Train Loss: -1.8829848495150805, Val Loss: -1.9131605536082223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 17:59:44,170] Trial 31 finished with value: -1.1274761056049023 and parameters: {'lstm_hidden_layer_size': 81, 'mlp_hidden_dim': 7, 'learning_rate': 0.001, 'dropout': 0.25, 'batch_size': 32, 'num_gaussians': 8, 'patience': 6}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.354924525976745, Val Loss: 0.643728912187389\n",
      "Window 0 Epoch 5 Train Loss: -0.5822454946714674, Val Loss: 1.4883148097453378\n",
      "Window 0 Epoch 10 Train Loss: -1.1972122504074187, Val Loss: -0.37417631471395285\n",
      "Window 1 Epoch 0 Train Loss: -0.04387534346096624, Val Loss: 1.8112664474392848\n",
      "Window 1 Epoch 5 Train Loss: -1.1000655828738197, Val Loss: -1.2955331411908544\n",
      "Window 1 Epoch 10 Train Loss: -1.5669823476128035, Val Loss: -1.6201346641411272\n",
      "Window 2 Epoch 0 Train Loss: 0.08269331317139234, Val Loss: -0.11639515684025895\n",
      "Window 2 Epoch 5 Train Loss: -1.2202319676689375, Val Loss: -1.060066171980857\n",
      "Window 2 Epoch 10 Train Loss: -1.609413069130383, Val Loss: -1.4281409972652366\n",
      "Window 3 Epoch 0 Train Loss: 0.27357331467915585, Val Loss: -0.026688423619438108\n",
      "Window 3 Epoch 5 Train Loss: -1.1576824776164305, Val Loss: -1.0452092541082334\n",
      "Window 3 Epoch 10 Train Loss: -1.4769089090049503, Val Loss: -1.0016751816539946\n",
      "Window 4 Epoch 0 Train Loss: 0.15523640400391697, Val Loss: -0.16276287518564667\n",
      "Window 4 Epoch 5 Train Loss: -1.2676676083361538, Val Loss: -1.1502890428390635\n",
      "Window 4 Epoch 10 Train Loss: -1.8784918419767143, Val Loss: -1.875077857440912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:04:06,787] Trial 32 finished with value: -1.3199268103770043 and parameters: {'lstm_hidden_layer_size': 91, 'mlp_hidden_dim': 11, 'learning_rate': 0.001, 'dropout': 0.35, 'batch_size': 32, 'num_gaussians': 5, 'patience': 9}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: -0.12053244850433988, Val Loss: 0.6529693299537115\n",
      "Window 0 Epoch 5 Train Loss: -1.186437267173818, Val Loss: -1.1374293285074906\n",
      "Window 0 Epoch 10 Train Loss: -1.4361816048334382, Val Loss: -1.4384542936661469\n",
      "Window 1 Epoch 0 Train Loss: 0.32486310116051076, Val Loss: 0.2901565471128419\n",
      "Window 1 Epoch 5 Train Loss: -0.8565809158868192, Val Loss: -1.0859178560490612\n",
      "Window 1 Epoch 10 Train Loss: -1.453518189391287, Val Loss: -1.3463884197453848\n",
      "Window 2 Epoch 0 Train Loss: 0.22884898314296917, Val Loss: 0.2255413316054307\n",
      "Window 2 Epoch 5 Train Loss: -0.48923571492249734, Val Loss: 0.4225873736766605\n",
      "Window 2 Epoch 10 Train Loss: -1.4347607384228023, Val Loss: -1.4170932125568805\n",
      "Window 3 Epoch 0 Train Loss: 0.07032523967417048, Val Loss: -0.004849254120494054\n",
      "Window 3 Epoch 5 Train Loss: -1.308198612330445, Val Loss: -0.9369034600402871\n",
      "Window 3 Epoch 10 Train Loss: -1.723661539982078, Val Loss: -1.757527523720192\n",
      "Window 4 Epoch 0 Train Loss: 0.17182530347785516, Val Loss: 0.06984324275243292\n",
      "Window 4 Epoch 5 Train Loss: -1.1356393354094672, Val Loss: -0.7546262392057325\n",
      "Window 4 Epoch 10 Train Loss: -1.8001549149659928, Val Loss: -1.7363456790080596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:08:58,827] Trial 33 finished with value: -1.2143503535376006 and parameters: {'lstm_hidden_layer_size': 101, 'mlp_hidden_dim': 10, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 9}. Best is trial 23 with value: -1.4128742150589069.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.14098003504358458, Val Loss: 0.1608618213548337\n",
      "Window 0 Epoch 5 Train Loss: -1.1331591193275676, Val Loss: -0.9572406974074946\n",
      "Window 0 Epoch 10 Train Loss: -1.4180192127643985, Val Loss: -1.3493946696446317\n",
      "Window 1 Epoch 0 Train Loss: 0.23165945035847063, Val Loss: 0.49233793357887234\n",
      "Window 1 Epoch 5 Train Loss: -1.1254027122073254, Val Loss: -1.3012639498524206\n",
      "Window 1 Epoch 10 Train Loss: -1.5036103245465466, Val Loss: -1.5954139973162362\n",
      "Window 2 Epoch 0 Train Loss: 0.3961374763155854, Val Loss: 0.5302532926577262\n",
      "Window 2 Epoch 5 Train Loss: -1.0867488116293533, Val Loss: -0.9679647258423806\n",
      "Window 2 Epoch 10 Train Loss: -1.6266704230991307, Val Loss: -1.420312982657803\n",
      "Window 3 Epoch 0 Train Loss: 0.7318244151691218, Val Loss: 0.032940922319552465\n",
      "Window 3 Epoch 5 Train Loss: -1.2582463959164172, Val Loss: -1.0421957561598976\n",
      "Window 3 Epoch 10 Train Loss: -1.601316509449863, Val Loss: -1.6574641067395512\n",
      "Window 4 Epoch 0 Train Loss: 0.12915062754727635, Val Loss: 0.016416719952010776\n",
      "Window 4 Epoch 5 Train Loss: -1.574101868232406, Val Loss: -1.804821346761039\n",
      "Window 4 Epoch 10 Train Loss: -1.8952037745994457, Val Loss: -1.95092933619157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:13:47,425] Trial 34 finished with value: -1.5291897180786074 and parameters: {'lstm_hidden_layer_size': 103, 'mlp_hidden_dim': 11, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 9}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.6566542196748015, Val Loss: 2.0508841928661026\n",
      "Window 0 Epoch 5 Train Loss: 2.214979783211296, Val Loss: 1.7118569540003918\n",
      "Window 0 Epoch 10 Train Loss: 1.831664315830318, Val Loss: 1.461993457129683\n",
      "Window 1 Epoch 0 Train Loss: 2.451543388512186, Val Loss: 1.6938647502510575\n",
      "Window 1 Epoch 5 Train Loss: 2.1921656724050074, Val Loss: 1.5042773599110926\n",
      "Window 1 Epoch 10 Train Loss: 1.9680072466609122, Val Loss: 1.3144823722897354\n",
      "Window 2 Epoch 0 Train Loss: 4.039524094114849, Val Loss: 3.3639509874670326\n",
      "Window 2 Epoch 5 Train Loss: 3.6544522346188297, Val Loss: 3.068579660924386\n",
      "Window 2 Epoch 10 Train Loss: 3.343249780924334, Val Loss: 2.802155007495764\n",
      "Window 3 Epoch 0 Train Loss: 5.801216769635108, Val Loss: 4.382028591311776\n",
      "Window 3 Epoch 5 Train Loss: 5.115434815527516, Val Loss: 4.083574365471675\n",
      "Window 3 Epoch 10 Train Loss: 4.460311987759858, Val Loss: 3.729513573915828\n",
      "Window 4 Epoch 0 Train Loss: 1.9621915647027528, Val Loss: 1.7610223703442398\n",
      "Window 4 Epoch 5 Train Loss: 1.8280542088001521, Val Loss: 1.6522760104345924\n",
      "Window 4 Epoch 10 Train Loss: 1.6949797415694203, Val Loss: 1.5502587669730497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:16:11,663] Trial 35 finished with value: 1.6126337756980786 and parameters: {'lstm_hidden_layer_size': 92, 'mlp_hidden_dim': 12, 'learning_rate': 1e-06, 'dropout': 0.4, 'batch_size': 64, 'num_gaussians': 5, 'patience': 9}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 28.04694019902152, Val Loss: 0.938755745270478\n",
      "Window 0 Epoch 5 Train Loss: 1.0538140773496953, Val Loss: 0.8851028829942467\n",
      "Window 0 Epoch 10 Train Loss: 0.6662031658439087, Val Loss: 0.7821772969566564\n",
      "Window 1 Epoch 0 Train Loss: 1.1805951706550752, Val Loss: 0.8185917581298059\n",
      "Window 1 Epoch 5 Train Loss: -0.26433843568196175, Val Loss: 0.7529632054288733\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 1.647985735592884, Val Loss: 1.0237526314658356\n",
      "Window 2 Epoch 5 Train Loss: 0.13963378437113047, Val Loss: 0.2736960956058121\n",
      "Window 2 Epoch 10 Train Loss: -0.17622994266157618, Val Loss: 0.4961952997175742\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 2.8575504573141735, Val Loss: 0.965399121067816\n",
      "Window 3 Epoch 5 Train Loss: 0.13797561625917756, Val Loss: -0.08252732915323159\n",
      "Window 3 Epoch 10 Train Loss: -0.20817111117897133, Val Loss: 0.18379305119745168\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.8084128313201775, Val Loss: 0.5541823692522704\n",
      "Window 4 Epoch 5 Train Loss: -0.1914751493523362, Val Loss: 0.36643595180492833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:20:23,100] Trial 36 finished with value: 0.3498095896210672 and parameters: {'lstm_hidden_layer_size': 109, 'mlp_hidden_dim': 15, 'learning_rate': 0.0001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 7}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window 4 Epoch 10 Train Loss: -0.40857036299971156, Val Loss: 0.345764152828659\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 2.015062639781657, Val Loss: 1.3199970823697273\n",
      "Window 0 Epoch 5 Train Loss: 0.00021985670889944394, Val Loss: 0.3237269907076394\n",
      "Window 0 Epoch 10 Train Loss: -0.15595428046981802, Val Loss: 0.2254357668599494\n",
      "Window 1 Epoch 0 Train Loss: 0.6050936206261647, Val Loss: 0.23567486722038478\n",
      "Window 1 Epoch 5 Train Loss: -0.22482597900712262, Val Loss: 0.2297089497981954\n",
      "Window 1 Epoch 10 Train Loss: -0.5040292824006419, Val Loss: -0.0714149697514641\n",
      "Window 2 Epoch 0 Train Loss: 0.4106394256837145, Val Loss: 0.6876133977590075\n",
      "Window 2 Epoch 5 Train Loss: -0.2099319428415548, Val Loss: 0.3214139100730575\n",
      "Window 2 Epoch 10 Train Loss: -0.3586758578434821, Val Loss: -0.015536755038592009\n",
      "Window 3 Epoch 0 Train Loss: 0.8672802193037985, Val Loss: 1.249445974360747\n",
      "Window 3 Epoch 5 Train Loss: -0.06863145826463017, Val Loss: 0.6043391934070869\n",
      "Window 3 Epoch 10 Train Loss: -0.34084105482430166, Val Loss: 0.428620580664725\n",
      "Window 4 Epoch 0 Train Loss: 1.214667655388752, Val Loss: 0.45197442886002887\n",
      "Window 4 Epoch 5 Train Loss: -0.47202599950136914, Val Loss: 0.5505998178630368\n",
      "Window 4 Epoch 10 Train Loss: -0.5384455188120425, Val Loss: 0.542379982050971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:21:41,147] Trial 37 finished with value: 0.4589344264804612 and parameters: {'lstm_hidden_layer_size': 98, 'mlp_hidden_dim': 11, 'learning_rate': 0.001, 'dropout': 0.15, 'batch_size': 256, 'num_gaussians': 3, 'patience': 10}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 72.50958681230875, Val Loss: 3.6688333823305954\n",
      "Window 0 Epoch 5 Train Loss: 10.351724359465921, Val Loss: 3.665386023467567\n",
      "Window 0 Epoch 10 Train Loss: 5.703372221443314, Val Loss: 3.738983798710602\n",
      "Window 1 Epoch 0 Train Loss: 2.402233894260116, Val Loss: 1.581253018304641\n",
      "Window 1 Epoch 5 Train Loss: 1.4101142552963173, Val Loss: 0.952966622483927\n",
      "Window 1 Epoch 10 Train Loss: 0.8487021269008231, Val Loss: 0.7368256425878258\n",
      "Window 2 Epoch 0 Train Loss: 3.8694870279736993, Val Loss: 2.4050954459129885\n",
      "Window 2 Epoch 5 Train Loss: 2.53738491542323, Val Loss: 1.8541116890546863\n",
      "Window 2 Epoch 10 Train Loss: 2.084101093808714, Val Loss: 1.4571723913131436\n",
      "Window 3 Epoch 0 Train Loss: 2.184280594493059, Val Loss: 1.6116036705925194\n",
      "Window 3 Epoch 5 Train Loss: 1.2313005589398336, Val Loss: 1.0682877722664774\n",
      "Window 3 Epoch 10 Train Loss: 0.6730957772552916, Val Loss: 0.601100026629056\n",
      "Window 4 Epoch 0 Train Loss: 2.1657233906722246, Val Loss: 1.6391251669253193\n",
      "Window 4 Epoch 5 Train Loss: 1.3283908266674498, Val Loss: 0.9847002667929171\n",
      "Window 4 Epoch 10 Train Loss: 1.0424220011169136, Val Loss: 0.773518838901089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:24:28,828] Trial 38 finished with value: 0.9867273379297419 and parameters: {'lstm_hidden_layer_size': 104, 'mlp_hidden_dim': 17, 'learning_rate': 1e-05, 'dropout': 0.35, 'batch_size': 64, 'num_gaussians': 3, 'patience': 10}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.5859495807973946, Val Loss: 0.35739456187063046\n",
      "Window 0 Epoch 5 Train Loss: -0.36360932118738204, Val Loss: 0.5508755310321247\n",
      "Window 0 Epoch 10 Train Loss: -0.4424050634226376, Val Loss: 0.5380746655936453\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.8801090138937109, Val Loss: 0.8182670439356415\n",
      "Window 1 Epoch 5 Train Loss: -0.34564114998433654, Val Loss: 1.0768536023219495\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.2768434794466632, Val Loss: 0.25541901670001466\n",
      "Window 2 Epoch 5 Train Loss: -0.4524123963845148, Val Loss: 0.2714312729190268\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.7165401435225262, Val Loss: 0.7822994955408377\n",
      "Window 3 Epoch 5 Train Loss: -0.461798989963863, Val Loss: 0.5253037047013317\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 0.2936570278590188, Val Loss: 0.3550086989934086\n",
      "Window 4 Epoch 5 Train Loss: -0.5666499465223421, Val Loss: 0.15118486620000296\n",
      "Window 4 Epoch 10 Train Loss: -0.6975500953810964, Val Loss: 0.41317186973904857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:28:20,173] Trial 39 finished with value: 0.2187185419651648 and parameters: {'lstm_hidden_layer_size': 118, 'mlp_hidden_dim': 9, 'learning_rate': 0.0001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 5, 'patience': 7}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 4.233432192294607, Val Loss: 2.1438899734142445\n",
      "Window 0 Epoch 5 Train Loss: 4.197273130707844, Val Loss: 2.1017492871818906\n",
      "Window 0 Epoch 10 Train Loss: 4.112659274305951, Val Loss: 2.0693452327174793\n",
      "Window 1 Epoch 0 Train Loss: 4.314762192825858, Val Loss: 3.532320506462939\n",
      "Window 1 Epoch 5 Train Loss: 4.1424114100086165, Val Loss: 3.456264699882885\n",
      "Window 1 Epoch 10 Train Loss: 4.018102892579818, Val Loss: 3.3826959367216825\n",
      "Window 2 Epoch 0 Train Loss: 3.2142549026331246, Val Loss: 3.3183586949581274\n",
      "Window 2 Epoch 5 Train Loss: 3.1451903355447346, Val Loss: 3.2360614976294655\n",
      "Window 2 Epoch 10 Train Loss: 3.070026082882978, Val Loss: 3.155996663584904\n",
      "Window 3 Epoch 0 Train Loss: 4.646999225844814, Val Loss: 1.1452585238150987\n",
      "Window 3 Epoch 5 Train Loss: 4.433167135760374, Val Loss: 1.1738956208647489\n",
      "Window 3 Epoch 10 Train Loss: 4.152668885700351, Val Loss: 1.2020773327319545\n",
      "Window 4 Epoch 0 Train Loss: 6.0763589393175215, Val Loss: 0.5516336791210854\n",
      "Window 4 Epoch 5 Train Loss: 4.947990980090305, Val Loss: 0.5312199834944579\n",
      "Window 4 Epoch 10 Train Loss: 4.699702970652641, Val Loss: 0.5173386285400308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:29:24,007] Trial 40 finished with value: 0.527473080862511 and parameters: {'lstm_hidden_layer_size': 74, 'mlp_hidden_dim': 14, 'learning_rate': 1e-06, 'dropout': 0.3, 'batch_size': 256, 'num_gaussians': 2, 'patience': 9}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.22844150497505158, Val Loss: 0.5880481618627271\n",
      "Window 0 Epoch 5 Train Loss: -0.5756120547901149, Val Loss: 1.805263907882465\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 1 Epoch 0 Train Loss: 0.11552634143203201, Val Loss: 0.9419590875855951\n",
      "Window 1 Epoch 5 Train Loss: -1.0871588425296976, Val Loss: -1.1401026759532926\n",
      "Window 1 Epoch 10 Train Loss: -1.4286439254429621, Val Loss: -1.5589119202152322\n",
      "Window 2 Epoch 0 Train Loss: 0.5058657148470056, Val Loss: 0.2768227092656335\n",
      "Window 2 Epoch 5 Train Loss: -1.1558139362401503, Val Loss: -1.0473814958287362\n",
      "Window 2 Epoch 10 Train Loss: -1.615994426358606, Val Loss: -1.4584900769433387\n",
      "Window 3 Epoch 0 Train Loss: 0.14266799693748944, Val Loss: 0.6394917224408438\n",
      "Window 3 Epoch 5 Train Loss: -1.2361024622522612, Val Loss: -1.0105625398256384\n",
      "Window 3 Epoch 10 Train Loss: -1.660315697195678, Val Loss: -1.7318282798515208\n",
      "Window 4 Epoch 0 Train Loss: 0.09614738392947297, Val Loss: 0.3959172994325619\n",
      "Window 4 Epoch 5 Train Loss: -1.043413155567143, Val Loss: -0.14978879136069767\n",
      "Window 4 Epoch 10 Train Loss: -1.664244743230042, Val Loss: -1.1450363614059966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:33:52,769] Trial 41 finished with value: -0.4499701689450836 and parameters: {'lstm_hidden_layer_size': 100, 'mlp_hidden_dim': 11, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 9}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.12160186320931753, Val Loss: 0.5844585845047862\n",
      "Window 0 Epoch 5 Train Loss: -0.5545553654429419, Val Loss: 0.4975944311074026\n",
      "Window 0 Epoch 10 Train Loss: -1.3132950162017416, Val Loss: -0.37963010504077976\n",
      "Window 1 Epoch 0 Train Loss: 0.12337407706568136, Val Loss: 0.5202217076352428\n",
      "Window 1 Epoch 5 Train Loss: -1.0476863482082006, Val Loss: -1.057921253423086\n",
      "Window 1 Epoch 10 Train Loss: -1.5180656065222171, Val Loss: -1.488546836282977\n",
      "Window 2 Epoch 0 Train Loss: 0.45393143958269405, Val Loss: 0.23063224248529826\n",
      "Window 2 Epoch 5 Train Loss: -1.2230294312221774, Val Loss: -1.0308598812303784\n",
      "Window 2 Epoch 10 Train Loss: -1.6709210308889308, Val Loss: -1.6231460085544869\n",
      "Window 3 Epoch 0 Train Loss: 0.36731865834036515, Val Loss: 0.014747505552814278\n",
      "Window 3 Epoch 5 Train Loss: -1.2156845829000433, Val Loss: -0.206289318569011\n",
      "Window 3 Epoch 10 Train Loss: -1.4343808729745045, Val Loss: -0.5664574945625485\n",
      "Window 4 Epoch 0 Train Loss: 0.004516685116621384, Val Loss: 0.2909954458209714\n",
      "Window 4 Epoch 5 Train Loss: -1.5098526457325883, Val Loss: -1.4203576394312285\n",
      "Window 4 Epoch 10 Train Loss: -1.9060322309168791, Val Loss: -1.9946875548383447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:37:59,413] Trial 42 finished with value: -1.438428916413172 and parameters: {'lstm_hidden_layer_size': 91, 'mlp_hidden_dim': 10, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 9}. Best is trial 34 with value: -1.5291897180786074.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.44093053858517517, Val Loss: 0.2568627405850189\n",
      "Window 0 Epoch 5 Train Loss: -0.6750439201483709, Val Loss: 0.2398234693176533\n",
      "Window 0 Epoch 10 Train Loss: -1.3644945205863612, Val Loss: -0.7227418814712147\n",
      "Window 1 Epoch 0 Train Loss: 0.2436067724712477, Val Loss: 0.5831408679329966\n",
      "Window 1 Epoch 5 Train Loss: -0.9201010006084351, Val Loss: -0.9051401453573324\n",
      "Window 1 Epoch 10 Train Loss: -1.4203117174727928, Val Loss: -1.5406140566493614\n",
      "Window 2 Epoch 0 Train Loss: 0.08812024014514305, Val Loss: 0.4595962260258291\n",
      "Window 2 Epoch 5 Train Loss: -0.6078403100689325, Val Loss: -0.5161006636043718\n",
      "Window 2 Epoch 10 Train Loss: -1.4686731961377284, Val Loss: -1.5190846852692803\n",
      "Window 3 Epoch 0 Train Loss: -0.23586058237958485, Val Loss: 0.14710804827828494\n",
      "Window 3 Epoch 5 Train Loss: -1.578830565554048, Val Loss: -1.223999851377605\n",
      "Window 3 Epoch 10 Train Loss: -1.7528392868151568, Val Loss: -1.8911414579346737\n",
      "Window 4 Epoch 0 Train Loss: 0.015425514840211856, Val Loss: -0.12449807587599983\n",
      "Window 4 Epoch 5 Train Loss: -1.5718965055146732, Val Loss: -1.7330814274780446\n",
      "Window 4 Epoch 10 Train Loss: -1.9204506471463931, Val Loss: -1.923143879731358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:42:11,866] Trial 43 finished with value: -1.6260697724135271 and parameters: {'lstm_hidden_layer_size': 88, 'mlp_hidden_dim': 5, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 5, 'patience': 10}. Best is trial 43 with value: -1.6260697724135271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.537498164041842, Val Loss: 0.4050309077410155\n",
      "Window 0 Epoch 5 Train Loss: -0.888092819634029, Val Loss: -0.5699270807277835\n",
      "Window 0 Epoch 10 Train Loss: -1.252123924172775, Val Loss: -1.0696160483629573\n",
      "Window 1 Epoch 0 Train Loss: 0.42624004496401935, Val Loss: 0.5665286148661225\n",
      "Window 1 Epoch 5 Train Loss: -0.4842726043479903, Val Loss: 0.6201688535284934\n",
      "Window 1 Epoch 10 Train Loss: -1.2711694135368474, Val Loss: -1.2371436332641323\n",
      "Window 2 Epoch 0 Train Loss: -0.008938236308279697, Val Loss: 0.47156016286511093\n",
      "Window 2 Epoch 5 Train Loss: -1.44070497817879, Val Loss: -1.3212171596200646\n",
      "Window 2 Epoch 10 Train Loss: -1.6599748507077323, Val Loss: -1.545323441279235\n",
      "Window 3 Epoch 0 Train Loss: 0.2747260652517759, Val Loss: 0.36156145455420896\n",
      "Window 3 Epoch 5 Train Loss: -1.281975065152871, Val Loss: -0.6084911495473051\n",
      "Window 3 Epoch 10 Train Loss: -1.6123341737687156, Val Loss: -1.4419286808275742\n",
      "Window 4 Epoch 0 Train Loss: 0.415521920311459, Val Loss: -0.12590495637455368\n",
      "Window 4 Epoch 5 Train Loss: -1.287852818008048, Val Loss: -1.33781577130176\n",
      "Window 4 Epoch 10 Train Loss: -1.8675671736453046, Val Loss: -1.9394756976052225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:46:15,783] Trial 44 finished with value: -1.2802263907313587 and parameters: {'lstm_hidden_layer_size': 92, 'mlp_hidden_dim': 6, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 5, 'patience': 10}. Best is trial 43 with value: -1.6260697724135271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.017443296602690922, Val Loss: 0.5333172992765127\n",
      "Window 0 Epoch 5 Train Loss: -1.0767321255580677, Val Loss: -0.05772325166498678\n",
      "Window 0 Epoch 10 Train Loss: -1.5052434764360039, Val Loss: -1.6052597808796463\n",
      "Window 1 Epoch 0 Train Loss: 0.34354485165080684, Val Loss: 0.30349264048577185\n",
      "Window 1 Epoch 5 Train Loss: -1.3155044964569076, Val Loss: -1.4737042917778551\n",
      "Window 1 Epoch 10 Train Loss: -1.5754856173568819, Val Loss: -1.6717544023520423\n",
      "Window 2 Epoch 0 Train Loss: 0.501668485979828, Val Loss: 0.8468896489263513\n",
      "Window 2 Epoch 5 Train Loss: -1.229346549601885, Val Loss: -0.9274274527146235\n",
      "Window 2 Epoch 10 Train Loss: -1.5811147770504586, Val Loss: -1.319360965650875\n",
      "Window 3 Epoch 0 Train Loss: 0.3154331430313704, Val Loss: 0.36842458658276384\n",
      "Window 3 Epoch 5 Train Loss: -1.0861159302707897, Val Loss: 0.5519427593172788\n",
      "Window 3 Epoch 10 Train Loss: -1.491224030655554, Val Loss: 0.2258462946405626\n",
      "Window 4 Epoch 0 Train Loss: 0.19727641694694456, Val Loss: 0.027655729417123555\n",
      "Window 4 Epoch 5 Train Loss: -1.4020715331184113, Val Loss: -0.9521913811189003\n",
      "Window 4 Epoch 10 Train Loss: -1.9076010314403289, Val Loss: -1.8289872885371787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:57:05,255] Trial 45 finished with value: -1.4192855010365286 and parameters: {'lstm_hidden_layer_size': 107, 'mlp_hidden_dim': 12, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 10}. Best is trial 43 with value: -1.6260697724135271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.8446299446196563, Val Loss: 0.9724122930049482\n",
      "Window 0 Epoch 5 Train Loss: 0.11003141249338033, Val Loss: 0.14960873361958513\n",
      "Window 0 Epoch 10 Train Loss: -0.11450004685902855, Val Loss: 0.29763388809797353\n",
      "Window 1 Epoch 0 Train Loss: 1.9638594164516379, Val Loss: 0.8647738084080527\n",
      "Window 1 Epoch 5 Train Loss: -0.14944496215615619, Val Loss: 1.5570278761181802\n",
      "Window 1 Epoch 10 Train Loss: -0.3647504938498213, Val Loss: 2.001750905445407\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 2 Epoch 0 Train Loss: 0.865660757232129, Val Loss: 0.462631261964967\n",
      "Window 2 Epoch 5 Train Loss: -0.30412579049782784, Val Loss: 0.06503772909075772\n",
      "Window 2 Epoch 10 Train Loss: -0.49157764565890577, Val Loss: 0.12606427261523326\n",
      "Window 3 Epoch 0 Train Loss: 1.1205567260374143, Val Loss: 0.6687789260046467\n",
      "Window 3 Epoch 5 Train Loss: -0.17918155353490803, Val Loss: 0.21074762385011653\n",
      "Window 3 Epoch 10 Train Loss: -0.43700747085582153, Val Loss: 0.5182439722153127\n",
      "Window 4 Epoch 0 Train Loss: 17.089047152206245, Val Loss: 1.0366634859612047\n",
      "Window 4 Epoch 5 Train Loss: 2.157942694334078, Val Loss: 0.8850780779853477\n",
      "Window 4 Epoch 10 Train Loss: 1.767411854847916, Val Loss: 0.8630862259326242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 18:59:24,289] Trial 46 finished with value: 0.898383672117255 and parameters: {'lstm_hidden_layer_size': 95, 'mlp_hidden_dim': 15, 'learning_rate': 0.0001, 'dropout': 0.4, 'batch_size': 64, 'num_gaussians': 2, 'patience': 10}. Best is trial 43 with value: -1.6260697724135271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.8938184291731498, Val Loss: 0.4141995181320648\n",
      "Window 0 Epoch 5 Train Loss: -0.17683388049424448, Val Loss: 0.5645153302922651\n",
      "Window 0 Epoch 10 Train Loss: -0.6118138902054061, Val Loss: -0.013545947138067954\n",
      "Window 1 Epoch 0 Train Loss: 0.688979428191739, Val Loss: 0.18397262650618829\n",
      "Window 1 Epoch 5 Train Loss: -0.4236090222133153, Val Loss: 0.9511616014067139\n",
      "Window 1 Epoch 10 Train Loss: -0.9022658455495014, Val Loss: -0.8601828995836392\n",
      "Window 2 Epoch 0 Train Loss: 1.627858258811873, Val Loss: 0.8621114509505463\n",
      "Window 2 Epoch 5 Train Loss: -0.1708948460669318, Val Loss: -0.07568225509233831\n",
      "Window 2 Epoch 10 Train Loss: -1.009286705034401, Val Loss: -0.8807016075123506\n",
      "Window 3 Epoch 0 Train Loss: 0.7848960829452162, Val Loss: 0.15183848797705357\n",
      "Window 3 Epoch 5 Train Loss: -0.5674922980488273, Val Loss: 0.868831725559682\n",
      "Window 3 Epoch 10 Train Loss: -0.9111959619435539, Val Loss: 1.1263380456654328\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 4 Epoch 0 Train Loss: 1.9571156787794046, Val Loss: 1.0049089009507028\n",
      "Window 4 Epoch 5 Train Loss: -0.4112812339787641, Val Loss: 0.08787782862458822\n",
      "Window 4 Epoch 10 Train Loss: 0.0807290985235045, Val Loss: -1.073524883889199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 19:01:13,550] Trial 47 finished with value: -0.3934699911644692 and parameters: {'lstm_hidden_layer_size': 106, 'mlp_hidden_dim': 13, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 128, 'num_gaussians': 3, 'patience': 10}. Best is trial 43 with value: -1.6260697724135271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 0.4929084793571985, Val Loss: 0.9371043441090555\n",
      "Window 0 Epoch 5 Train Loss: -0.8464156477863614, Val Loss: -0.5864435071845763\n",
      "Window 0 Epoch 10 Train Loss: -1.4918904397620465, Val Loss: -1.5506363067287243\n",
      "Window 1 Epoch 0 Train Loss: 0.05632288478752977, Val Loss: 0.8495604025602962\n",
      "Window 1 Epoch 5 Train Loss: -0.9931830848357939, Val Loss: -1.1593167149015968\n",
      "Window 1 Epoch 10 Train Loss: -1.512389201207247, Val Loss: -1.5966848390812878\n",
      "Window 2 Epoch 0 Train Loss: 0.15435347943113983, Val Loss: 0.6839247104605833\n",
      "Window 2 Epoch 5 Train Loss: -0.42583144561968406, Val Loss: 0.34094827239612824\n",
      "Window 2 Epoch 10 Train Loss: -0.621474071072487, Val Loss: 0.5815872706660594\n",
      "Early stopping triggered\n",
      "Stopping early due to increasing validation loss.\n",
      "Window 3 Epoch 0 Train Loss: 0.25256627434939277, Val Loss: 0.3847323311193418\n",
      "Window 3 Epoch 5 Train Loss: -0.939592753297357, Val Loss: -0.7446399325396474\n",
      "Window 3 Epoch 10 Train Loss: -1.6824595351770277, Val Loss: -1.7245116369502633\n",
      "Window 4 Epoch 0 Train Loss: 0.19683422565322084, Val Loss: 0.04599609903725824\n",
      "Window 4 Epoch 5 Train Loss: -1.6570708526312252, Val Loss: -1.7839447681433631\n",
      "Window 4 Epoch 10 Train Loss: -1.9546848132917178, Val Loss: -2.019234825796298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 19:05:58,366] Trial 48 finished with value: -1.5134637315973076 and parameters: {'lstm_hidden_layer_size': 107, 'mlp_hidden_dim': 8, 'learning_rate': 0.001, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 10}. Best is trial 43 with value: -1.6260697724135271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total windows created: 1\n",
      "Total windows created: 2\n",
      "Total windows created: 3\n",
      "Total windows created: 4\n",
      "Total windows created: 5\n",
      "Window 0 Epoch 0 Train Loss: 1.8538585129398355, Val Loss: 1.6399137207365988\n",
      "Window 0 Epoch 5 Train Loss: 0.46309958782632965, Val Loss: 0.7654020250309663\n",
      "Window 0 Epoch 10 Train Loss: 0.12912992987466315, Val Loss: 0.43707191030115383\n",
      "Window 1 Epoch 0 Train Loss: 2.1263256976764913, Val Loss: 1.1481503569282312\n",
      "Window 1 Epoch 5 Train Loss: 0.43164412730378027, Val Loss: 0.6224610496354456\n",
      "Window 1 Epoch 10 Train Loss: 0.09119146796420147, Val Loss: 0.27264398056771005\n",
      "Window 2 Epoch 0 Train Loss: 1.5128442583321673, Val Loss: 1.6259629640446653\n",
      "Window 2 Epoch 5 Train Loss: 0.5090236060088973, Val Loss: 0.8041341938110769\n",
      "Window 2 Epoch 10 Train Loss: 0.2601989348908816, Val Loss: 0.5964069934019723\n",
      "Window 3 Epoch 0 Train Loss: 1.0907238329816211, Val Loss: 0.3288614586267546\n",
      "Window 3 Epoch 5 Train Loss: 0.3204912580848258, Val Loss: 0.2962696534669679\n",
      "Window 3 Epoch 10 Train Loss: 0.16592793904645592, Val Loss: 0.18695877184306509\n",
      "Window 4 Epoch 0 Train Loss: 3.7679841153534426, Val Loss: 2.243264542777677\n",
      "Window 4 Epoch 5 Train Loss: 0.49007195667075504, Val Loss: 0.7773847864256228\n",
      "Window 4 Epoch 10 Train Loss: 0.191413546828295, Val Loss: 0.6066295409026506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-18 19:11:34,808] Trial 49 finished with value: 0.8552428821998852 and parameters: {'lstm_hidden_layer_size': 121, 'mlp_hidden_dim': 8, 'learning_rate': 1e-05, 'dropout': 0.4, 'batch_size': 32, 'num_gaussians': 4, 'patience': 10}. Best is trial 43 with value: -1.6260697724135271.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: -1.6260697724135271\n",
      "  Params: \n",
      "    lstm_hidden_layer_size: 88\n",
      "    mlp_hidden_dim: 5\n",
      "    learning_rate: 0.001\n",
      "    dropout: 0.4\n",
      "    batch_size: 32\n",
      "    num_gaussians: 5\n",
      "    patience: 10\n"
     ]
    }
   ],
   "source": [
    "from train import train_model\n",
    "from test import test_model\n",
    "import torch\n",
    "from model import LSTMWithMLP\n",
    "import optuna\n",
    "\n",
    "def main():\n",
    "\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(train_model, n_trials=50)\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    # model = train_model()\n",
    "\n",
    "    # model = LSTMWithMLP(lstm_input_size=1, output_size=1, num_gaussians=5, mlp_input_dim=11)\n",
    "    # state_path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\4. Deep learning part\\\\final_model_state.pth\"\n",
    "    # model.load_state_dict(torch.load(state_path))\n",
    "\n",
    "    # Test the model\n",
    "    # average_nll_loss, average_mae_loss, average_mape_loss, average_r2_score = test_model(model)\n",
    "\n",
    "    # # # Output the average losses and R^2 score\n",
    "    # print(f'Average NLL Loss on Validation Set: {average_nll_loss:.4f}')\n",
    "    # # print(f'Average RMSE on Test Set: {average_rmse_loss:.4f}')\n",
    "    # print(f'Average MAE on Validation Set: {average_mae_loss:.4f}')\n",
    "    # print(f'Average MAPE on Validation Set: {average_mape_loss:.4f}')\n",
    "    # print(f'R^2 Score on Validation Set: {average_r2_score:.4f}')\n",
    "\n",
    "    # # Save the model state\n",
    "    # state_path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\4. Deep learning part\\\\final_model_state.pth\"\n",
    "    # torch.save(model.state_dict(), state_path)\n",
    "    # print(\"Model state saved successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
