[MODEL]
# Data parameter
seq_length = 24

# Model parameters
batch_size = 32
epochs = 15
learning_rate = 0.001
num_gaussians = 5

# LSTM parameters
lstm_hidden_layer_size = 88
dropout = 0.4

# MLP parameters
mlp_hidden_dim = 5

# EarlyStopping
patience = 10
delta = 0.05

# L2 regularization 
l2_lambda = 0.01

# Entropy regularization weight
entropy_weight = 0.03