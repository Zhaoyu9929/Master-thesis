{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this part, we do some data cleaning and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the data that travel distance = 0, beacasue we don't consider the situation where trips in the same zone. This data still need to be reconsidered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the location id to filter the trip that pick up and dropoff only in Manhatton island \n",
    "location_ids = [\n",
    "    4, 12, 13, 24, 41, 42, 43, 45, 48, 50, 68, 74, 75, 79, 87, 88, 90, 100, 107, 113, 114, 116,\n",
    "    120, 125, 127, 128, 137, 140, 141, 142, 143, 144, 148, 151, 152, 153, 158, 161, 162, 163,\n",
    "    164, 166, 170, 186, 194, 209, 211, 224, 229, 230, 231, 232, 233, 234, 236, 237, 238, 239,\n",
    "    243, 244, 246, 249, 261, 262, 263\n",
    "]\n",
    "\n",
    "# Make a file pattern to match the CSV files\n",
    "file_pattern = r\"C:\\Users\\yanzh\\Desktop\\Code\\archive\\2019\\yellow_tripdata_2019-*.csv\"\n",
    "\n",
    "# Get a list of all CSV files in a directory\n",
    "\n",
    "# Initialize an empty dictionary to store filtered DataFrames\n",
    "dfs = {}\n",
    "\n",
    "csv_files = glob.glob(file_pattern)\n",
    "\n",
    "# Loop through the list of file paths\n",
    "for i, file_path in enumerate(csv_files, start=1):\n",
    "    # Read the CSV file into a Dataframe\n",
    "    Before_filter_df = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter the Dataframe\n",
    "    df = Before_filter_df[Before_filter_df['PULocationID'].isin(location_ids) & Before_filter_df['DOLocationID'].isin(location_ids)]\n",
    "\n",
    "    # Drop the data from useless columns\n",
    "    df = df.drop(columns=['VendorID', 'RatecodeID', 'store_and_fwd_flag', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'congestion_surcharge'])\n",
    "\n",
    "    # Delete the data that travel distance = 0, beacasue we don't consider the situation where trips in the same zone. This data still need to be reconsidered.\n",
    "    df = df[df['PULocationID'] != df['DOLocationID']]\n",
    "    \n",
    "    # Delete the data that fare amount is negative.\n",
    "    df = df[df['fare_amount'] >= 0]\n",
    "\n",
    "    # Store the filtered DataFrame in the dictionary\n",
    "    dfs[f'df{i}'] = df\n",
    "\n",
    "    '''\n",
    "    dfs is the dictonary that used to store each filtered Dataframe. The use of a dictionary allows us to assoicate each Dataframe with a unique key\n",
    "    that can retrieve the Dataframe later on.\n",
    "\n",
    "    f'df{i}' can be regarded as a key. \n",
    "\n",
    "    So 'df1', 'df2' are the keys in the dictionary, each assoicated with its repective filtered DataFrame\n",
    "\n",
    "    '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = dfs['df1']\n",
    "df1 = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfs['df1']['total_amount'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
