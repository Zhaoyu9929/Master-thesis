{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import gurobipy as gp\n",
    "import os \n",
    "from gurobipy import Model, GRB, quicksum\n",
    "import nbformat\n",
    "import nbimporter\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import glob\n",
    "from scipy.sparse import coo_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the trip csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2019-6.3_6.9.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarios definition\n",
    "\n",
    "note that here we divide demand level into three levels: low demand ( lower than 5 trips), medium demand(6 trips to 70 trips), and high demand (larger than 70 trips). \n",
    "\n",
    "Now we can have 24 * 3939 * 3 = 283608 scenarios, and **subsequent reductions** may occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = df.groupby(['origin_ID', 'destination_ID', 'hour']).size().reset_index(name='count')\n",
    "def demand_category(x):\n",
    "    if x < 6:\n",
    "        return 'low demand'\n",
    "    elif 6 <= x <= 70:\n",
    "        return 'medium demand'\n",
    "    else:\n",
    "        return 'high demand'\n",
    "        \n",
    "\n",
    "demand_df['demand_level'] = demand_df['count'].apply(demand_category)\n",
    "demand_df = demand_df.drop(['count'], axis=1)\n",
    "\n",
    "\n",
    "existing_trips_df = df.groupby(['origin_ID', 'destination_ID']).size().reset_index(name='count')\n",
    "# Create a new list of scenario\n",
    "scenarios = []\n",
    "\n",
    "for hour in range(24):\n",
    "    for index, row in existing_trips_df.iterrows():\n",
    "        scenarios.append((hour, row['origin_ID'], row['destination_ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the speed and graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Manhattan network and change node labels to integers\n",
    "G = ox.graph_from_place('Manhattan, New York, USA', network_type='drive')\n",
    "\n",
    "# If a node cannot access at least 10% of other nodes, delete it (isolated points are not considered)\n",
    "remove_list = []\n",
    "num_nodes = len(G.nodes)\n",
    "for node in G.nodes:  \n",
    "    reach = len(nx.descendants(G, node))\n",
    "    if reach < num_nodes / 10:\n",
    "        remove_list.append(node)\n",
    "\n",
    "for node in remove_list:\n",
    "    G.remove_node(node)\n",
    "\n",
    "# The node labels of the graph are converted to integers for easier handling and reference, \n",
    "G = nx.convert_node_labels_to_integers(G, label_attribute='old_node_ID')\n",
    "G = ox.add_edge_speeds(G)\n",
    "\n",
    "speed_df_path = r\"C:\\Users\\yanzh\\Desktop\\code_and_data\\archive\\nyc_avg_speeds_2019-06.csv\"\n",
    "speed_df = pd.read_csv(speed_df_path)\n",
    "speed_df = speed_df[['osm_way_id', 'hour', 'speed']]\n",
    "G = ox.add_edge_travel_times(G, precision=1)\n",
    "\n",
    "\n",
    "# Load the graphs data with speed in the file\n",
    "def load_graph_from_pkl(file_path):\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "# The graphs holds a list of graph objects for each hour, here is 24 hour\n",
    "graphs = load_graph_from_pkl(\"graphs_list.pkl\")\n",
    "\n",
    "def process_graphs(graphs):\n",
    "    # Verify if each graph is an instance of MultiGraph\n",
    "    for hour, graph in enumerate(graphs):\n",
    "        if isinstance(graph, nx.MultiGraph):\n",
    "            update_graph_edges(graph, hour)\n",
    "        else:\n",
    "            print(f\"Graph for hour {hour} is not a MultiGraph.\")\n",
    "\n",
    "def update_graph_edges(graph, hour):\n",
    "    travel_time_key = f'travel_time_hour_{hour}'\n",
    "    for u, v, key, data in graph.edges(keys=True, data=True):\n",
    "        if travel_time_key not in data:\n",
    "            # Safely access the travel time in a multigraph structure\n",
    "            freeflow_travel_time = graph[u][v][key].get('travel_time', None)\n",
    "            if freeflow_travel_time is not None:\n",
    "                graph[u][v][key][travel_time_key] = freeflow_travel_time\n",
    "\n",
    "process_graphs(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the travel time function using Dijkstra algorithm\n",
    "def travel_time_func(G_hour, point1, point2, hour):\n",
    "    # Define the weight key for the specific hour\n",
    "    weight_key = f'travel_time_hour_{hour}'\n",
    "\n",
    "    # Use Dijkstra's algorithm to find the shortest path length and path\n",
    "    # This function returns both the length of the path and the actual path as a list of nodes\n",
    "    travel_time, path = nx.single_source_dijkstra(G_hour, source=point1, target=point2, weight=weight_key)\n",
    "\n",
    "    # Round the travel time to 2 decimal places\n",
    "    travel_time = round(travel_time, 4)\n",
    "\n",
    "    return travel_time, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of scenarios\n",
    "S = len(scenarios)\n",
    "\n",
    "# number of trips\n",
    "K = len(df)\n",
    "\n",
    "# number of poential charging staion locations\n",
    "I = 65\n",
    "\n",
    "# number of cars \n",
    "H = 50\n",
    "\n",
    "# Time periods from 0h to 23h\n",
    "T = 24\n",
    "\n",
    "# fixed cost of each charging station, here we assmue 150000 dollars, but here because we only use 10000 cars, so we need reduce the cost\n",
    "station_cost = 150000\n",
    "\n",
    "# Purchasing cost of each car\n",
    "car_cost = 15000 # Here we use 15000 dollars\n",
    "\n",
    "# Income of each accepted trip\n",
    "income_per_car = 50 # assume here is 50 dollars\n",
    "\n",
    "# Capacity of each charging station, i.e. number of charging slots can be built at each charging station\n",
    "capacity = 5\n",
    "\n",
    "# p_s is a dictionary containing the profit weights for each scenario\n",
    "# Here assume equal probability for each scenario\n",
    "p_s = 1 / len(scenarios)\n",
    "# Assuming i_k is a dictionary or a function that provides income for each trip k in scenario s ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-expanded location graphs  G=(V, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are Duplicate travel arcs which means some cars have same trips at the same scenario, location and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "# Read the csv file of coordinatate of charging station\n",
    "df_charging_station_location = pd.read_csv('coordinates of charging station.csv')\n",
    "location_id_to_index = df_charging_station_location.set_index('Location_id')['index'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the nodes in the graph\n",
    "root = 'root'\n",
    "sink = 'sink'\n",
    "\n",
    "# Here V is described as a set of tuples, with each tuple contains two integers\n",
    "#Plus the root and sink \n",
    "\n",
    "grid = np.array(np.meshgrid(range(S), range(I), range(T), indexing='ij'))\n",
    "grid_shape = grid.shape[1:]\n",
    "\n",
    "V_grid = grid.reshape(3, -1).T\n",
    "# V_tuples = [tuple(x) for x in V_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Waiting arcs\n",
    "# waiting_arcs = [(s, (i, t), (i, t+1)) for s, i, t in product(range(S), range(I), range(23))]\n",
    "\n",
    "# The traveling arcs \n",
    "\n",
    "# travel_arcs = []\n",
    "\n",
    "# for s in S:\n",
    "#     for k in range(trips_each_scenario):\n",
    "\n",
    "#         # Select the specific row\n",
    "#         row = Ks[s].iloc[k]\n",
    "        \n",
    "        \n",
    "#         # change the starting point id to index (from 0 to 65)\n",
    "#         starting_point_id = row['origin_ID']\n",
    "#         if starting_point_id in location_id_to_index:\n",
    "#             starting_point = location_id_to_index[starting_point_id]\n",
    "\n",
    "#         # Convert time to hour    \n",
    "#         starting_time = row['starting_time'].hour\n",
    "        \n",
    "#         # Change the destination point id to index (from 0 to 65)\n",
    "#         ending_point_id = row['destination_ID']\n",
    "#         if ending_point_id in location_id_to_index:\n",
    "#             ending_point = location_id_to_index[ending_point_id]\n",
    "        \n",
    "#         # Convert time to hour    \n",
    "#         ending_time = row['ending_time'].hour\n",
    "\n",
    "#         arcs = (s, k, (starting_point, starting_time), (ending_point, ending_time))\n",
    "#         travel_arcs.append(arcs)\n",
    "\n",
    "\n",
    "# # Initial allocation arcs\n",
    "# initial_allocation_arcs = [(s, root, (i, 0)) for s in S for i in I ]\n",
    "\n",
    "# final_collection_arcs = [(s, (i, 23), sink) for s in S for i in I ]\n",
    "\n",
    "# # Define arcs excluding travel arcs\n",
    "# arcs_exclduing_travel_arcs = waiting_arcs + initial_allocation_arcs + final_collection_arcs\n",
    "\n",
    "# all_arcs = initial_allocation_arcs + waiting_arcs + travel_arcs + final_collection_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First stage variable (Strategical layer)\n",
    "$$\n",
    "y_i=1 \\ \\text{if the charging station is built at $i$ point}, \\forall i \\in I\n",
    "$$\n",
    "$$\n",
    "L_i= \\ \\text{initial number of EVs at station i}, \\forall i \\in I\n",
    "$$\n",
    "\n",
    "Second stage variable(Operational layer)\n",
    "$$\n",
    "x_k=1 \\ \\text{if the $k$ trip is accepted}, k \\in K^s, \\forall s\\in S\n",
    "$$\n",
    "$$\n",
    "x_k^h = 1 \\ \\text{if and only if an accepted trip $k$ of scenario $s$ will be realized by purchased car $h$}\n",
    "$$\n",
    "$$\n",
    "f_a^h = 1 \\ \\text{if the car $h$ travels from station $i$ at time $t$ to station $j$ at time $t^{\\prime}$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "m = Model('CSLP')\n",
    "\n",
    "# m.setParam('NodefileStart', 0.5)\n",
    "\n",
    "# First stage decision variable\n",
    "y_i = m.addVars(range(65), vtype=GRB.BINARY, name='build_variable')\n",
    "L_i = m.addVars(range(65), vtype=GRB.INTEGER, name='purchased_car', lb=0, ub=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the running process, we have created a sparse matrix below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df = pd.DataFrame(scenarios, columns=['hour', 'origin_ID', 'destination_ID'])\n",
    "\n",
    "# Initialize the row and col arrays for COO matrix\n",
    "rows = np.arange(len(df))\n",
    "cols = []\n",
    "\n",
    "# For each trip in df, find the index of the matching scenario\n",
    "for index, trip in df.iterrows():\n",
    "        # Finding the matching scenario index\n",
    "    matching_scenario = scenarios_df[(scenarios_df['hour'] == trip['hour']) &(scenarios_df['origin_ID'] == trip['origin_ID']) & (scenarios_df['destination_ID'] == trip['destination_ID'])].index\n",
    "\n",
    "    if not matching_scenario.empty:\n",
    "        cols.append(matching_scenario[0])\n",
    "    else:\n",
    "        # Handle the case where no matching scenario is found\n",
    "        cols.append(np.nan)  # Or however you'd like to handle this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df = pd.DataFrame(scenarios, columns=['hour', 'origin_ID', 'destination_ID'])\n",
    "\n",
    "# Initialize the row and col arrays for COO matrix\n",
    "rows = np.arange(len(df))\n",
    "cols = []\n",
    "\n",
    "# Code below is the used for calculating the cols process.\n",
    "\"\"\"  \n",
    "    # # For each trip in df, find the index of the matching scenario\n",
    "    # for index, trip in df.iterrows():\n",
    "    #     # Finding the matching scenario index\n",
    "    #     matching_scenario = scenarios_df[\n",
    "    #         (scenarios_df['hour'] == trip['hour']) &\n",
    "    #         (scenarios_df['origin_ID'] == trip['origin_ID']) &\n",
    "    #         (scenarios_df['destination_ID'] == trip['destination_ID'])\n",
    "    #     ].index\n",
    "\n",
    "    #     if not matching_scenario.empty:\n",
    "    #         cols.append(matching_scenario[0])\n",
    "    #     else:\n",
    "    #         # Handle the case where no matching scenario is found\n",
    "    #         cols.append(np.nan)  # Or however you'd like to handle this case\n",
    "\n",
    "    \"\"\"\n",
    "cols_df = pd.read_csv('cols_df_one_week.csv')\n",
    "cols = cols_df['0'].tolist()\n",
    "\n",
    "\n",
    "# Data for the COO matrix will be all ones\n",
    "data_coo_matrix = np.ones_like(rows)\n",
    "\n",
    "# Create the COO sparse matrix\n",
    "x_k_sparse = coo_matrix((data_coo_matrix, (rows, cols)), shape=(len(df), len(scenarios_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the decision variables in the **second** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the row and column indices for the x_k variables\n",
    "rows = x_k_sparse.row\n",
    "cols = x_k_sparse.col\n",
    "\n",
    "# Use NumPy's broadcasting to create all combinations of non-zero indices and car indices for x_hk\n",
    "rows_x_hk = np.repeat(rows, H)\n",
    "cols_x_hk = np.repeat(cols, H)\n",
    "cars_x_hk = np.tile(np.arange(H), len(rows))\n",
    "\n",
    "# Combine rows and cols into a single NumPy array of tuples for x_k\n",
    "x_k_keys = np.vstack((rows, cols)).T\n",
    "\n",
    "# Combine rows_x_hk, cols_x_hk, and cars_x_hk into a single NumPy array of tuples for x_hk\n",
    "x_hk_keys = np.vstack((rows_x_hk, cols_x_hk, cars_x_hk)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use chunks processing. It is a method to covert all keys at onece, process the keys in smaller batcher. This approach reduces the peak memory usage and can make problem more manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we add x_k variables with chunks procssing\n",
    "\n",
    "# Function to add variables in chunks\n",
    "def add_variables_in_chunks(keys, chunk_size, name_prefix):\n",
    "    num_chunks = len(keys) // chunk_size + (1 if len(keys) % chunk_size != 0 else 0)\n",
    "    for i in range(num_chunks):\n",
    "        start_index = i * chunk_size\n",
    "        end_index = min((i + 1) * chunk_size, len(keys))\n",
    "        tuple_keys = [tuple(key) for key in keys[start_index:end_index]]\n",
    "        vars_chunk = m.addVars(tuple_keys, vtype=GRB.BINARY, name=f'{name_prefix}{i}')\n",
    "        print(f'Chunk {i+1}/{num_chunks} processed.')\n",
    "m.update() # Final update after all variables are added\n",
    "\n",
    "# Process the keys in chunks\n",
    "add_variables_in_chunks(x_k_keys, 100000, 'accpted_trip_')\n",
    "add_variables_in_chunks(x_hk_keys, 100000, 'trip_realized_by_car')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow variable in the second stage\n",
    "f_ha = m.addVars(range(len(all_arcs)), vtype=GRB.BINARY, name='flow') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Max\\ \\sum_{s\\in S}p_s\\sum_{k\\in K^s}{i_kx_k\\ -\\ \\sum_{i\\in I}{f_iy_i-c\\sum_{i\\in I}L_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function: maximize profit\n",
    "m.setObjective(\n",
    "    quicksum(p_s[s] * income_per_car * quicksum(x_k[s, k] for k in range(trips_each_scenario)) for s in S) -\n",
    "    station_cost * quicksum(y_i[i] for i in range(n_locations)) -\n",
    "    car_cost * quicksum(L_i[i] for i in range(n_locations)),\n",
    "    GRB.MAXIMIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some mandatory requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least 5 stations should be built\n",
    "m.addConstr(quicksum(y_i[i] for i in I) >= 5, name=\"at_least_five_stations\")\n",
    "\n",
    "# Total number of cars should be fixed as 50 cars\n",
    "m.addConstr(quicksum(L_i[i] for i in I) == 50, name='total_number_of_cars')\n",
    "\n",
    "# If the station is built in i, L_[i] should more than 0.\n",
    "for i in I:\n",
    "    m.addConstr(L_i[i] >= 1 - 1000 * (1 - y_i[i]), name=f'min_cars_if_station_{i}')\n",
    "\n",
    "# Initil capacity limitation\n",
    "for i in I:\n",
    "    m.addConstr(L_i[i] <= capacity, name=f'initial capacity limitation_{i}') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constarints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraint 1\n",
    "$$\\sum_{i\\in I}{f_i y_i - c\\sum_{i\\in I} L_i} \\leq W$$\n",
    "\n",
    "This is the budget constraint, $W$ is the limited budget for all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Budget constraints\n",
    "budget = 10000000\n",
    "m.addConstr(station_cost * quicksum(y_i[i] for i in range(n_locations)) + \n",
    "            car_cost * quicksum(L_i[i] for i in range(n_locations)) <= budget, \n",
    "            name='budge_constraint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 2\n",
    "\n",
    "$$0< t^s_k x_k \\leq T^{max}\\qquad\\forall s \\in S, k \\in K^s$$\n",
    "\n",
    "The travel time of the $k$ trip should not exceed the maximum travel time of the car due to battery limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery limitation\n",
    "\n",
    "# The maximum operational time is 60 minutes\n",
    "T_max = 60 \n",
    "\n",
    "# Create a mapping from Location id to networkx point, here I create a dictionary\n",
    "location_id_to_networkx_point = df_charging_station_location.set_index('Location_id')['networkx_point'].to_dict()\n",
    "\n",
    "for s in S:\n",
    "    for k in range(K):\n",
    "\n",
    "        # Get the orgin_id value right now\n",
    "        origin_id = Ks[s]['origin_ID'].iloc[k]\n",
    "        \n",
    "\n",
    "        if origin_id in location_id_to_networkx_point:\n",
    "            origin = location_id_to_networkx_point[origin_id]\n",
    "        \n",
    "        # Get the destination_id value right now\n",
    "        destination_id = Ks[s]['destination_ID'].iloc[k]\n",
    "        \n",
    "        if destination_id in location_id_to_networkx_point:\n",
    "            destination = location_id_to_networkx_point[destination_id]\n",
    "\n",
    "        hour = Ks[s]['starting_time'].dt.hour.iloc[k]\n",
    "        G_hour = graphs[hour]\n",
    "\n",
    "        #Calculate travel time for this trip\n",
    "        travel_time, _ = travel_time_func(G_hour, origin, destination, hour)\n",
    "\n",
    "        # # Check for NaN or Inf values\n",
    "        # if np.isnan(travel_time) or np.isinf(travel_time):\n",
    "        #     print(f\"Invalid travel time detected: Scenario {s}, Trip {k}, Origin {origin}, Destination {destination}, Hour {hour}, Travel Time {travel_time}\")\n",
    "        #     continue\n",
    "\n",
    "        # Only apply the constraint if the trip is accepted\n",
    "        m.addConstr(travel_time * x_k[s, k] <= T_max, name=f\"Battery limitation_s{s}_k{k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 3\n",
    "\n",
    "$$\\sum_{h=1}^H x_k^h = x_k, \\qquad\\forall s \\in S, k \\in K^s $$\n",
    "\n",
    "It ensures that exactly one car is assigned to each accepted trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        m.addConstr(quicksum(x_hk[s, h, k] for h in H) == x_k[s, k], name=f\"one_car_per_accepted_trip_s{s}_k{k}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrain 4\n",
    "\n",
    "$$\\sum_{h=1}^H \\sum_{a \\in \\delta^{+}\\left(i_t\\right) \\cap\\left(A_W^s \\cup A_C^s\\right)} f_a^h \\leq C_i y_i \\qquad \\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that the quantity of vehicles concurrently parked at station $i$ does not surpass the available number of charging slots at said station.\n",
    "Observe that final collection arcs need to be considered on the left-hand side to ensure that the capacity constraints are also met at the end of the planning period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity constraints\n",
    "\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        # Directly handling the final collection arcs to 'sink' \n",
    "        final_arc_key = (s, (i, 23), 'sink')\n",
    "        m.addConstr(quicksum(f_ha[s, h, final_arc_key] for h in H if final_arc_key in f_ha) <= capacity * y_i[i], name=f'final_capacity_s{s}_i{i}')\n",
    "        \n",
    "        for t in T:         \n",
    "            # Filter and append arcs relevant to the current (s, i, t)\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "        \n",
    "            # Add constraint            \n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in outgoing_waiting_arcs if arc in f_ha) <= capacity * y_i[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 5\n",
    "\n",
    "$$    f^h[\\delta^{-}\\left(i_t\\right)] \\leq y_i \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that car can only enter the built station. It includes waiting arcs (cars only car wait at the built station), and traveling arcs (cars can only park at the built station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 5\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific waiting arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_waiting_arcs if arc in f_ha) <= y_i[i])\n",
    "\n",
    "            # Next is travel arc\n",
    "\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_travel_arcs if arc in f_ha) <= y_i[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 6\n",
    "\n",
    "$$f^h\\left[\\delta^{-}\\left(i_t\\right)\\right]=f^h\\left[\\delta^{+}\\left(i_t\\right)\\right] \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad\\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "Flow conservation ensures that the route of each car must correspond to a path through the time-expanded location graph for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific incoming  arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_arcs = incoming_travel_arcs + incoming_waiting_arcs\n",
    "\n",
    "            # Given s, i, t, a specific outgoing  arc can be identified\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_arcs = outgoing_travel_arcs + outgoing_waiting_arcs\n",
    "\n",
    "            for h in H:\n",
    "                # Add constraints\n",
    "                m.addConstr(\n",
    "                    quicksum(f_ha[s, h, arc] for arc in incoming_arcs if arc in f_ha) ==\n",
    "                    quicksum(f_ha[s, h, arc] for arc in outgoing_arcs if arc in f_ha),\n",
    "                    name=f\"flow_conservation_s{s}_i{i}_t{t}_h{h}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 7 \n",
    "\n",
    "$$\\sum_{a \\in A_{T}^s(k)} f_a^h=x_k^h \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall k \\in K^s$$\n",
    "\n",
    "This equation illustrates all action of one car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute travel arcs for each scenario and trip\n",
    "travel_arcs_per_scenario_trip = {\n",
    "    (s, k): [arc for arc in travel_arcs if arc[0] == s and arc[1] == k]\n",
    "    for s in S\n",
    "    for k in range(trips_each_scenario)\n",
    "}\n",
    "\n",
    "# Now add constraints using the precomputed arcs\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        for h in H:\n",
    "            relevant_arcs = travel_arcs_per_scenario_trip[(s, k)]\n",
    "            sum_f_ha_for_travel_arcs = quicksum(f_ha[arc] for arc in relevant_arcs)\n",
    "            m.addConstr(sum_f_ha_for_travel_arcs == x_hk[s, h, k], name=f'all_action_one_car_s{s}_h{h}_k{k}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in S:\n",
    "#     for k in range(trips_each_scenario):\n",
    "#         for h in H:\n",
    "#             # Calculate the sum of f_ha for all travel arcs for a specific scenario s, car h and trip k\n",
    "#             sum_f_ha_for_travel_arcs = quicksum(f_ha[s, k, h, arc] for arc in travel_arcs if arc in f_ha)\n",
    "#             m.addConstr(sum_f_ha_for_travel_arcs == x_hk[s, h, k], name=f'all_action_one_car_s{s}_i{i}_t{t}_h{h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 8\n",
    "\n",
    "$$ f_a^h \\leq f_{a^{\\prime}}^h \\\\\n",
    "\n",
    "\\forall h \\in\\{1,2, \\ldots, H\\}, \\forall s \\in S, \\forall k \\in K^s, \\\\\n",
    "\\forall a=\\left(i_{s_k}, j_{e_k}\\right) \\in A_{\\mathrm{T}}^s(k), \\\\\n",
    "\\forall a^{\\prime}=\\left(j_t, j_{t^{\\prime}}\\right) \\in A_{W}^s, \\\\\n",
    "t = e_k, t^{\\prime} = e_k+\\left\\lceil\\frac{b_k}{\\rho}\\right\\rceil $$\n",
    "\n",
    "This equation force each car must fully charge the battery after completing the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume fully charging time is 60 mins\n",
    "fully_charging_time = 1\n",
    "\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        \n",
    "        # Define AI_arcs considering all travel arcs for services s.\n",
    "        AT_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s ] \n",
    "        if AT_arcs:\n",
    "            for h in H:\n",
    "                \n",
    "                at_arc = AT_arcs[k]\n",
    "                st = at_arc[2][1]\n",
    "                et = at_arc[3][1]\n",
    "\n",
    "                t = et\n",
    "                t_prime = t + fully_charging_time\n",
    "\n",
    "                # Finding the corresponding AW_arcs with the updated time t_prime\n",
    "                AW_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src[1] == t and dst[1] == t_prime]\n",
    "                    \n",
    "                    \n",
    "                # Now, add the constraint for each matching arc, ensuring we use the unique arc identifiers from all_unique_arcs\n",
    "                for aw_arc in AW_arcs:\n",
    "                    if (s, h, at_arc) in f_ha and (s, h, aw_arc) in f_ha:\n",
    "                        m.addConstr(f_ha[s, h, at_arc] <= f_ha[s, h, aw_arc], f\"charging_constraint_{s}_{k}_{h}_{at_arc}_{aw_arc}\")\n",
    "                        print(f'finding the corresponding matching arc_s{s}_h{h}_k{k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Solve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the model\n",
    "m.optimize()\n",
    "\n",
    "# Directly check the optimization status\n",
    "if m.Status == GRB.OPTIMAL:\n",
    "    print(\"Optimization was successful. Printing results.\")\n",
    "    for i in range(n_locations):  # Ensure n_locations is correctly set\n",
    "        if y_i[i].X > 0.5:\n",
    "            print(f\"Build a charging station at location {i} with {L_i[i].X} cars.\")\n",
    "else:\n",
    "    print(f\"Optimization issue with status code: {m.Status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
