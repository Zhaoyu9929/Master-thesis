{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import gurobipy as gp\n",
    "import os \n",
    "from gurobipy import Model, GRB, quicksum\n",
    "import nbformat\n",
    "import nbimporter\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import glob\n",
    "from scipy.sparse import coo_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the trip csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>origin_ID</th>\n",
       "      <th>destination_ID</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>starting_time</th>\n",
       "      <th>ending_time</th>\n",
       "      <th>duration_time</th>\n",
       "      <th>day_type</th>\n",
       "      <th>hour</th>\n",
       "      <th>time_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>262</td>\n",
       "      <td>263</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2019-06-01 00:06:31</td>\n",
       "      <td>2019-06-01 00:06:52</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.70</td>\n",
       "      <td>113</td>\n",
       "      <td>148</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.95</td>\n",
       "      <td>2019-06-01 00:03:25</td>\n",
       "      <td>2019-06-01 00:15:42</td>\n",
       "      <td>12.283333</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.60</td>\n",
       "      <td>79</td>\n",
       "      <td>125</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2019-06-01 00:28:31</td>\n",
       "      <td>2019-06-01 00:39:23</td>\n",
       "      <td>10.866667</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>2019-06-01 00:46:46</td>\n",
       "      <td>2019-06-01 00:50:55</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.20</td>\n",
       "      <td>79</td>\n",
       "      <td>249</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2019-06-01 00:54:49</td>\n",
       "      <td>2019-06-01 01:02:57</td>\n",
       "      <td>8.133333</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458387</th>\n",
       "      <td>0.90</td>\n",
       "      <td>68</td>\n",
       "      <td>158</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.80</td>\n",
       "      <td>2019-06-30 23:23:03</td>\n",
       "      <td>2019-06-30 23:39:48</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458388</th>\n",
       "      <td>0.50</td>\n",
       "      <td>246</td>\n",
       "      <td>90</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.80</td>\n",
       "      <td>2019-06-30 23:50:22</td>\n",
       "      <td>2019-06-30 23:57:01</td>\n",
       "      <td>6.650000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458389</th>\n",
       "      <td>0.20</td>\n",
       "      <td>90</td>\n",
       "      <td>186</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2019-06-30 23:58:32</td>\n",
       "      <td>2019-07-01 00:00:42</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458390</th>\n",
       "      <td>1.38</td>\n",
       "      <td>140</td>\n",
       "      <td>163</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.56</td>\n",
       "      <td>2019-06-30 23:23:10</td>\n",
       "      <td>2019-06-30 23:30:45</td>\n",
       "      <td>7.583333</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458391</th>\n",
       "      <td>1.77</td>\n",
       "      <td>142</td>\n",
       "      <td>151</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2019-06-30 23:39:13</td>\n",
       "      <td>2019-06-30 23:44:56</td>\n",
       "      <td>5.716667</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5458392 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         trip_distance  origin_ID  destination_ID  fare_amount  total_amount  \\\n",
       "0                 0.00        262             263          2.5          6.30   \n",
       "1                 1.70        113             148          9.5         15.95   \n",
       "2                 1.60         79             125          9.5         14.30   \n",
       "3                 0.60        211             148          4.5          8.30   \n",
       "4                 1.20         79             249          7.5         12.30   \n",
       "...                ...        ...             ...          ...           ...   \n",
       "5458387           0.90         68             158         11.0         16.80   \n",
       "5458388           0.50        246              90          6.0          9.80   \n",
       "5458389           0.20         90             186          3.5          8.75   \n",
       "5458390           1.38        140             163          7.5         13.56   \n",
       "5458391           1.77        142             151          7.0         11.80   \n",
       "\n",
       "               starting_time          ending_time  duration_time day_type  \\\n",
       "0        2019-06-01 00:06:31  2019-06-01 00:06:52       0.350000  weekend   \n",
       "1        2019-06-01 00:03:25  2019-06-01 00:15:42      12.283333  weekend   \n",
       "2        2019-06-01 00:28:31  2019-06-01 00:39:23      10.866667  weekend   \n",
       "3        2019-06-01 00:46:46  2019-06-01 00:50:55       4.150000  weekend   \n",
       "4        2019-06-01 00:54:49  2019-06-01 01:02:57       8.133333  weekend   \n",
       "...                      ...                  ...            ...      ...   \n",
       "5458387  2019-06-30 23:23:03  2019-06-30 23:39:48      16.750000  weekend   \n",
       "5458388  2019-06-30 23:50:22  2019-06-30 23:57:01       6.650000  weekend   \n",
       "5458389  2019-06-30 23:58:32  2019-07-01 00:00:42       2.166667  weekend   \n",
       "5458390  2019-06-30 23:23:10  2019-06-30 23:30:45       7.583333  weekend   \n",
       "5458391  2019-06-30 23:39:13  2019-06-30 23:44:56       5.716667  weekend   \n",
       "\n",
       "         hour time_category  \n",
       "0           0       weekend  \n",
       "1           0       weekend  \n",
       "2           0       weekend  \n",
       "3           0       weekend  \n",
       "4           0       weekend  \n",
       "...       ...           ...  \n",
       "5458387    23       weekend  \n",
       "5458388    23       weekend  \n",
       "5458389    23       weekend  \n",
       "5458390    23       weekend  \n",
       "5458391    23       weekend  \n",
       "\n",
       "[5458392 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2019-6_after_filtering.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarios definition\n",
    "\n",
    "note that here we divide demand level into three levels: low demand ( lower than 5 trips), medium demand(6 trips to 70 trips), and high demand (larger than 70 trips). \n",
    "\n",
    "Now we can have 24 * 3939 * 3 = 283608 scenarios, and **subsequent reductions** may occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = df.groupby(['origin_ID', 'destination_ID', 'hour']).size().reset_index(name='count')\n",
    "def demand_category(x):\n",
    "    if x < 6:\n",
    "        return 'low demand'\n",
    "    elif 6 <= x <= 70:\n",
    "        return 'medium demand'\n",
    "    else:\n",
    "        return 'high demand'\n",
    "        \n",
    "\n",
    "demand_df['demand_level'] = demand_df['count'].apply(demand_category)\n",
    "demand_df = demand_df.drop(['count'], axis=1)\n",
    "\n",
    "\n",
    "existing_trips_df = df.groupby(['origin_ID', 'destination_ID']).size().reset_index(name='count')\n",
    "# Create a new list of scenario\n",
    "scenarios = []\n",
    "\n",
    "for hour in range(24):\n",
    "    for index, row in existing_trips_df.iterrows():\n",
    "        scenarios.append((hour, row['origin_ID'], row['destination_ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the speed and graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:737\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 737\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 862\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:845\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 845\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1314\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1312\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1314\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\ssl.py:1166\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTimeoutError\u001b[0m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    815\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 816\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:1043\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1043\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1045\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:935\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 935\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    937\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:861\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    859\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 861\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_catcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfp_closed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\urllib3\\response.py:742\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[0;32m    741\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n\u001b[1;32m--> 742\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m BaseSSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;66;03m# FIXME: Is there a better way to differentiate between SSLErrors?\u001b[39;00m\n",
      "\u001b[1;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import Manhattan network and change node labels to integers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_from_place\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mManhattan, New York, USA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# If a node cannot access at least 10% of other nodes, delete it (isolated points are not considered)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m remove_list \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\osmnx\\graph.py:379\u001b[0m, in \u001b[0;36mgraph_from_place\u001b[1;34m(query, network_type, simplify, retain_all, truncate_by_edge, which_result, buffer_dist, clean_periphery, custom_filter)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;66;03m# create a GeoDataFrame with the spatial boundaries of the place(s)\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m)):\n\u001b[0;32m    377\u001b[0m     \u001b[38;5;66;03m# if it is a string (place name) or dict (structured place query),\u001b[39;00m\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;66;03m# then it is a single place\u001b[39;00m\n\u001b[1;32m--> 379\u001b[0m     gdf_place \u001b[38;5;241m=\u001b[39m \u001b[43mgeocoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeocode_to_gdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhich_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_dist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_dist\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;66;03m# if it is a list, it contains multiple places to get\u001b[39;00m\n\u001b[0;32m    384\u001b[0m     gdf_place \u001b[38;5;241m=\u001b[39m geocoder\u001b[38;5;241m.\u001b[39mgeocode_to_gdf(query, buffer_dist\u001b[38;5;241m=\u001b[39mbuffer_dist)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\osmnx\\geocoder.py:138\u001b[0m, in \u001b[0;36mgeocode_to_gdf\u001b[1;34m(query, which_result, by_osmid, buffer_dist)\u001b[0m\n\u001b[0;32m    136\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame()\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m q, wr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(query, which_result):\n\u001b[1;32m--> 138\u001b[0m     gdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([gdf, \u001b[43m_geocode_query_to_gdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_osmid\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# reset GeoDataFrame index and set its CRS\u001b[39;00m\n\u001b[0;32m    141\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\osmnx\\geocoder.py:179\u001b[0m, in \u001b[0;36m_geocode_query_to_gdf\u001b[1;34m(query, which_result, by_osmid)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;124;03mGeocode a single place query to a GeoDataFrame.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    a GeoDataFrame with one row containing the result of geocoding\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m which_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m which_result\n\u001b[1;32m--> 179\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43m_nominatim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_nominatim_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_osmid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_osmid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# choose the right result from the JSON response\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m results:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# if no results were returned, raise error\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\osmnx\\_nominatim.py:64\u001b[0m, in \u001b[0;36m_download_nominatim_element\u001b[1;34m(query, by_osmid, limit, polygon_geojson)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# request the URL, return the JSON\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nominatim_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\osmnx\\_nominatim.py:106\u001b[0m, in \u001b[0;36m_nominatim_request\u001b[1;34m(params, request_type, pause, error_pause)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# transmit the HTTP GET request\u001b[39;00m\n\u001b[0;32m    105\u001b[0m utils\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGet \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprepared_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msettings\u001b[38;5;241m.\u001b[39mtimeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 106\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_downloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_http_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequests_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# handle 429 and 504 errors by pausing then recursively re-trying request\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m429\u001b[39m, \u001b[38;5;241m504\u001b[39m}:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:73\u001b[0m, in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\sessions.py:747\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[1;32m--> 747\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:899\u001b[0m, in \u001b[0;36mResponse.content\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 899\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\requests\\models.py:822\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ContentDecodingError(e)\n\u001b[0;32m    821\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 822\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsSSLError(e)\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='nominatim.openstreetmap.org', port=443): Read timed out."
     ]
    }
   ],
   "source": [
    "# Import Manhattan network and change node labels to integers\n",
    "G = ox.graph_from_place('Manhattan, New York, USA', network_type='drive')\n",
    "\n",
    "# If a node cannot access at least 10% of other nodes, delete it (isolated points are not considered)\n",
    "remove_list = []\n",
    "num_nodes = len(G.nodes)\n",
    "for node in G.nodes:  \n",
    "    reach = len(nx.descendants(G, node))\n",
    "    if reach < num_nodes / 10:\n",
    "        remove_list.append(node)\n",
    "\n",
    "for node in remove_list:\n",
    "    G.remove_node(node)\n",
    "\n",
    "# The node labels of the graph are converted to integers for easier handling and reference, \n",
    "G = nx.convert_node_labels_to_integers(G, label_attribute='old_node_ID')\n",
    "G = ox.add_edge_speeds(G)\n",
    "speed_df_path = r\"C:\\Users\\yanzh\\Desktop\\Code\\archive\\nyc_avg_speeds_2019-06.csv\"\n",
    "speed_df = pd.read_csv(speed_df_path)\n",
    "speed_df = speed_df[['osm_way_id', 'hour', 'speed']]\n",
    "G = ox.add_edge_travel_times(G, precision=1)\n",
    "\n",
    "\n",
    "# Load the graphs data with speed in the file\n",
    "def load_graph_from_pkl(file_path):\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "# The graphs holds a list of graph objects for each hour, here is 24 hour\n",
    "graphs = load_graph_from_pkl(\"graphs_list.pkl\")\n",
    "\n",
    "# Go through the graph in each hour\n",
    "for hour in range(24):\n",
    "    for u, v, data in graphs[hour].edges(data=True):\n",
    "        travel_time_key = f'travel_time_hour_{hour}'\n",
    "\n",
    "        if travel_time_key not in data:\n",
    "           freeflow_travel_time = G[u][v][0].get('travel_time', None)\n",
    "           if freeflow_travel_time is not None:\n",
    "               graphs[hour][u][v][0][travel_time_key] = freeflow_travel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_graph_from_pkl(file_path):\n",
    "#     with open(file_path, \"rb\") as f:\n",
    "#         graphs = pickle.load(f)\n",
    "#     return graphs\n",
    "\n",
    "# def process_graphs(graphs):\n",
    "#     # Verify if each graph is an instance of MultiGraph\n",
    "#     for hour, graph in enumerate(graphs):\n",
    "#         if isinstance(graph, nx.MultiGraph):\n",
    "#             update_graph_edges(graph, hour)\n",
    "#         else:\n",
    "#             print(f\"Graph for hour {hour} is not a MultiGraph.\")\n",
    "\n",
    "# def update_graph_edges(graph, hour):\n",
    "#     travel_time_key = f'travel_time_hour_{hour}'\n",
    "#     for u, v, key, data in graph.edges(keys=True, data=True):\n",
    "#         if travel_time_key not in data:\n",
    "#             # Safely access the travel time in a multigraph structure\n",
    "#             freeflow_travel_time = graph[u][v][key].get('travel_time', None)\n",
    "#             if freeflow_travel_time is not None:\n",
    "#                 graph[u][v][key][travel_time_key] = freeflow_travel_time\n",
    "\n",
    "# # Load and process the graphs\n",
    "# graphs = load_graph_from_pkl(\"/content/drive/MyDrive/graphs_list.pkl\")\n",
    "# process_graphs(graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the travel time function using Dijkstra algorithm\n",
    "def travel_time_func(G_hour, point1, point2, hour):\n",
    "    # Define the weight key for the specific hour\n",
    "    weight_key = f'travel_time_hour_{hour}'\n",
    "\n",
    "    # Use Dijkstra's algorithm to find the shortest path length and path\n",
    "    # This function returns both the length of the path and the actual path as a list of nodes\n",
    "    travel_time, path = nx.single_source_dijkstra(G_hour, source=point1, target=point2, weight=weight_key)\n",
    "\n",
    "    # Round the travel time to 2 decimal places\n",
    "    travel_time = round(travel_time, 4)\n",
    "\n",
    "    return travel_time, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of scenarios\n",
    "S = len(scenarios)\n",
    "\n",
    "# number of trips\n",
    "K = len(df)\n",
    "\n",
    "# number of poential charging staion locations\n",
    "n_locations = 65 \n",
    "\n",
    "# number of cars \n",
    "n_cars = 50\n",
    "\n",
    "# number of scenarios \n",
    "n_scenarios = 5 \n",
    "\n",
    "# fixed cost of each charging station, here we assmue 150000 dollars, but here because we only use 10000 cars, so we need reduce the cost\n",
    "station_cost = 150000\n",
    "\n",
    "# Purchasing cost of each car\n",
    "car_cost = 15000 # Here we use 15000 dollars\n",
    "\n",
    "# Income of each accepted trip\n",
    "income_per_car = 50 # assume here is 50 dollars\n",
    "\n",
    "# Capacity of each charging station, i.e. number of charging slots can be built at each charging station\n",
    "capacity = 5\n",
    "\n",
    "# p_s is a dictionary containing the profit weights for each scenario\n",
    "# Here assume equal probability for each scenario\n",
    "p_s = 1 / len(scenarios)\n",
    "# Assuming i_k is a dictionary or a function that provides income for each trip k in scenario s ?\n",
    "\n",
    "# Time periods \n",
    "T = 24\n",
    "\n",
    "# Potential location of charging station, and then number them from 0 to 64\n",
    "I = n_locations\n",
    "\n",
    "# Cars\n",
    "H = n_cars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-expanded location graphs  G=(V, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are Duplicate travel arcs which means some cars have same trips at the same scenario, location and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m sink \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msink\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m V0 \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m V \u001b[38;5;241m=\u001b[39m [root] \u001b[38;5;241m+\u001b[39m [(s, i, t) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m S \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m T] \u001b[38;5;241m+\u001b[39m [sink] \u001b[38;5;66;03m# Here V is described as a set of tuples, with each tuple contains two integers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                                                      \u001b[38;5;66;03m#Plus the root and sink  \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Waiting arcs\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Read the csv file of coordinatate of charging station\n",
    "df_charging_station_location = pd.read_csv('coordinates of charging station.csv')\n",
    "\n",
    "# First is V, set of nodes in the graph\n",
    "root = 'root'\n",
    "sink = 'sink'\n",
    "\n",
    "V0 = [(s, i, t) for s in S for i in I for t in T]\n",
    "V = [root] + [(s, i, t) for s in S for i in I for t in T] + [sink] # Here V is described as a set of tuples, with each tuple contains two integers\n",
    "                                                     #Plus the root and sink  \n",
    "\n",
    "# Waiting arcs\n",
    "waiting_arcs = [(s, (i, t), (i, t+1)) for s in S for i in I for t in list(range(23))]\n",
    "\n",
    "# The traveling arcs \n",
    "location_id_to_index = df_charging_station_location.set_index('Location_id')['index'].to_dict()\n",
    "travel_arcs = []\n",
    "\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "\n",
    "        # Select the specific row\n",
    "        row = Ks[s].iloc[k]\n",
    "        \n",
    "        \n",
    "        # change the starting point id to index (from 0 to 65)\n",
    "        starting_point_id = row['origin_ID']\n",
    "        if starting_point_id in location_id_to_index:\n",
    "            starting_point = location_id_to_index[starting_point_id]\n",
    "\n",
    "        # Convert time to hour    \n",
    "        starting_time = row['starting_time'].hour\n",
    "        \n",
    "        # Change the destination point id to index (from 0 to 65)\n",
    "        ending_point_id = row['destination_ID']\n",
    "        if ending_point_id in location_id_to_index:\n",
    "            ending_point = location_id_to_index[ending_point_id]\n",
    "        \n",
    "        # Convert time to hour    \n",
    "        ending_time = row['ending_time'].hour\n",
    "\n",
    "        arcs = (s, k, (starting_point, starting_time), (ending_point, ending_time))\n",
    "        travel_arcs.append(arcs)\n",
    "\n",
    "\n",
    "# Initial allocation arcs\n",
    "initial_allocation_arcs = [(s, root, (i, 0)) for s in S for i in I ]\n",
    "\n",
    "final_collection_arcs = [(s, (i, 23), sink) for s in S for i in I ]\n",
    "\n",
    "# Define arcs excluding travel arcs\n",
    "arcs_exclduing_travel_arcs = waiting_arcs + initial_allocation_arcs + final_collection_arcs\n",
    "\n",
    "all_arcs = initial_allocation_arcs + waiting_arcs + travel_arcs + final_collection_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First stage variable (Strategical layer)\n",
    "$$\n",
    "y_i=1 \\ \\text{if the charging station is built at $i$ point}, \\forall i \\in I\n",
    "$$\n",
    "$$\n",
    "L_i= \\ \\text{initial number of EVs at station i}, \\forall i \\in I\n",
    "$$\n",
    "\n",
    "Second stage variable(Operational layer)\n",
    "$$\n",
    "x_k=1 \\ \\text{if the $k$ trip is accepted}, k \\in K^s, \\forall s\\in S\n",
    "$$\n",
    "$$\n",
    "x_k^h = 1 \\ \\text{if and only if an accepted trip $k$ of scenario $s$ will be realized by purchased car $h$}\n",
    "$$\n",
    "$$\n",
    "f_a^h = 1 \\ \\text{if the car $h$ travels from station $i$ at time $t$ to station $j$ at time $t^{\\prime}$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-04-08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "m = Model('CSLP')\n",
    "\n",
    "# m.setParam('NodefileStart', 0.5)\n",
    "\n",
    "# First stage decision variable\n",
    "y_i = m.addVars(range(n_locations), vtype=GRB.BINARY, name='build_variable')\n",
    "L_i = m.addVars(range(n_locations), vtype=GRB.INTEGER, name='purchased_car', lb=0, ub=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simplify the running process, we have created a sparse matrix below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df = pd.DataFrame(scenarios, columns=['hour', 'origin_ID', 'destination_ID'])\n",
    "\n",
    "# Initialize the row and col arrays for COO matrix\n",
    "rows = np.arange(len(df))\n",
    "cols = []\n",
    "\n",
    "# Code below is the used for calculating the cols process.\n",
    "\"\"\"  \n",
    "    # # For each trip in df, find the index of the matching scenario\n",
    "    # for index, trip in df.iterrows():\n",
    "    #     # Finding the matching scenario index\n",
    "    #     matching_scenario = scenarios_df[\n",
    "    #         (scenarios_df['hour'] == trip['hour']) &\n",
    "    #         (scenarios_df['origin_ID'] == trip['origin_ID']) &\n",
    "    #         (scenarios_df['destination_ID'] == trip['destination_ID'])\n",
    "    #     ].index\n",
    "\n",
    "    #     if not matching_scenario.empty:\n",
    "    #         cols.append(matching_scenario[0])\n",
    "    #     else:\n",
    "    #         # Handle the case where no matching scenario is found\n",
    "    #         cols.append(np.nan)  # Or however you'd like to handle this case\n",
    "\n",
    "    \"\"\"\n",
    "cols_df = pd.read_csv('cols_df.csv')\n",
    "cols = cols_df['0'].tolist()\n",
    "\n",
    "\n",
    "# Data for the COO matrix will be all ones\n",
    "data_coo_matrix = np.ones_like(rows)\n",
    "\n",
    "# Create the COO sparse matrix\n",
    "x_k_sparse = coo_matrix((data_coo_matrix, (rows, cols)), shape=(len(df), len(scenarios_df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the decision variables in the **second** stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the row and column indices for the x_k variables\n",
    "rows = x_k_sparse.row\n",
    "cols = x_k_sparse.col\n",
    "\n",
    "# Use NumPy's broadcasting to create all combinations of non-zero indices and car indices for x_hk\n",
    "rows_x_hk = np.repeat(rows, H)\n",
    "cols_x_hk = np.repeat(cols, H)\n",
    "cars_x_hk = np.tile(np.arange(H), len(rows))\n",
    "\n",
    "# Combine rows and cols into a single NumPy array of tuples for x_k\n",
    "x_k_keys = np.vstack((rows, cols)).T\n",
    "\n",
    "# Combine rows_x_hk, cols_x_hk, and cars_x_hk into a single NumPy array of tuples for x_hk\n",
    "x_hk_keys = np.vstack((rows_x_hk, cols_x_hk, cars_x_hk)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "GurobiError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mGurobiError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Now create the x_k and x_hk variables in Gurobi using the lists of tuples\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_k \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddVars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_k_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGRB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBINARY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccepted_trip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m x_hk \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39maddVars(x_hk_keys, vtype\u001b[38;5;241m=\u001b[39mGRB\u001b[38;5;241m.\u001b[39mBINARY, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrip_realized_by_car\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\model.pxi:2952\u001b[0m, in \u001b[0;36mgurobipy.Model.addVars\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mGurobiError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now create the x_k and x_hk variables in Gurobi using the lists of tuples\n",
    "x_k = m.addVars(x_k_keys, vtype=GRB.BINARY, name='accepted_trip')\n",
    "x_hk = m.addVars(x_hk_keys, vtype=GRB.BINARY, name='trip_realized_by_car')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_arcs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# flow variable in the second stage\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m f_ha \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39maddVars(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mall_arcs\u001b[49m)), vtype\u001b[38;5;241m=\u001b[39mGRB\u001b[38;5;241m.\u001b[39mBINARY, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflow\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_arcs' is not defined"
     ]
    }
   ],
   "source": [
    "# flow variable in the second stage\n",
    "f_ha = m.addVars(range(len(all_arcs)), vtype=GRB.BINARY, name='flow') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Max\\ \\sum_{s\\in S}p_s\\sum_{k\\in K^s}{i_kx_k\\ -\\ \\sum_{i\\in I}{f_iy_i-c\\sum_{i\\in I}L_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function: maximize profit\n",
    "m.setObjective(\n",
    "    quicksum(p_s[s] * income_per_car * quicksum(x_k[s, k] for k in range(trips_each_scenario)) for s in S) -\n",
    "    station_cost * quicksum(y_i[i] for i in range(n_locations)) -\n",
    "    car_cost * quicksum(L_i[i] for i in range(n_locations)),\n",
    "    GRB.MAXIMIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some mandatory requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least 5 stations should be built\n",
    "m.addConstr(quicksum(y_i[i] for i in I) >= 5, name=\"at_least_five_stations\")\n",
    "\n",
    "# Total number of cars should be fixed as 50 cars\n",
    "m.addConstr(quicksum(L_i[i] for i in I) == 50, name='total_number_of_cars')\n",
    "\n",
    "# If the station is built in i, L_[i] should more than 0.\n",
    "for i in I:\n",
    "    m.addConstr(L_i[i] >= 1 - 1000 * (1 - y_i[i]), name=f'min_cars_if_station_{i}')\n",
    "\n",
    "# Initil capacity limitation\n",
    "for i in I:\n",
    "    m.addConstr(L_i[i] <= capacity, name=f'initial capacity limitation_{i}') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constarints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraint 1\n",
    "$$\\sum_{i\\in I}{f_i y_i - c\\sum_{i\\in I} L_i} \\leq W$$\n",
    "\n",
    "This is the budget constraint, $W$ is the limited budget for all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Budget constraints\n",
    "budget = 10000000\n",
    "m.addConstr(station_cost * quicksum(y_i[i] for i in range(n_locations)) + \n",
    "            car_cost * quicksum(L_i[i] for i in range(n_locations)) <= budget, \n",
    "            name='budge_constraint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 2\n",
    "\n",
    "$$0< t^s_k x_k \\leq T^{max}\\qquad\\forall s \\in S, k \\in K^s$$\n",
    "\n",
    "The travel time of the $k$ trip should not exceed the maximum travel time of the car due to battery limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery limitation\n",
    "\n",
    "# The maximum operational time is 60 minutes\n",
    "T_max = 60 \n",
    "\n",
    "# Create a mapping from Location id to networkx point, here I create a dictionary\n",
    "location_id_to_networkx_point = df_charging_station_location.set_index('Location_id')['networkx_point'].to_dict()\n",
    "\n",
    "for s in S:\n",
    "    for k in range(K):\n",
    "\n",
    "        # Get the orgin_id value right now\n",
    "        origin_id = Ks[s]['origin_ID'].iloc[k]\n",
    "        \n",
    "\n",
    "        if origin_id in location_id_to_networkx_point:\n",
    "            origin = location_id_to_networkx_point[origin_id]\n",
    "        \n",
    "        # Get the destination_id value right now\n",
    "        destination_id = Ks[s]['destination_ID'].iloc[k]\n",
    "        \n",
    "        if destination_id in location_id_to_networkx_point:\n",
    "            destination = location_id_to_networkx_point[destination_id]\n",
    "\n",
    "        hour = Ks[s]['starting_time'].dt.hour.iloc[k]\n",
    "        G_hour = graphs[hour]\n",
    "\n",
    "        #Calculate travel time for this trip\n",
    "        travel_time, _ = travel_time_func(G_hour, origin, destination, hour)\n",
    "\n",
    "        # # Check for NaN or Inf values\n",
    "        # if np.isnan(travel_time) or np.isinf(travel_time):\n",
    "        #     print(f\"Invalid travel time detected: Scenario {s}, Trip {k}, Origin {origin}, Destination {destination}, Hour {hour}, Travel Time {travel_time}\")\n",
    "        #     continue\n",
    "\n",
    "        # Only apply the constraint if the trip is accepted\n",
    "        m.addConstr(travel_time * x_k[s, k] <= T_max, name=f\"Battery limitation_s{s}_k{k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 3\n",
    "\n",
    "$$\\sum_{h=1}^H x_k^h = x_k, \\qquad\\forall s \\in S, k \\in K^s $$\n",
    "\n",
    "It ensures that exactly one car is assigned to each accepted trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        m.addConstr(quicksum(x_hk[s, h, k] for h in H) == x_k[s, k], name=f\"one_car_per_accepted_trip_s{s}_k{k}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrain 4\n",
    "\n",
    "$$\\sum_{h=1}^H \\sum_{a \\in \\delta^{+}\\left(i_t\\right) \\cap\\left(A_W^s \\cup A_C^s\\right)} f_a^h \\leq C_i y_i \\qquad \\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that the quantity of vehicles concurrently parked at station $i$ does not surpass the available number of charging slots at said station.\n",
    "Observe that final collection arcs need to be considered on the left-hand side to ensure that the capacity constraints are also met at the end of the planning period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity constraints\n",
    "\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        # Directly handling the final collection arcs to 'sink' \n",
    "        final_arc_key = (s, (i, 23), 'sink')\n",
    "        m.addConstr(quicksum(f_ha[s, h, final_arc_key] for h in H if final_arc_key in f_ha) <= capacity * y_i[i], name=f'final_capacity_s{s}_i{i}')\n",
    "        \n",
    "        for t in T:         \n",
    "            # Filter and append arcs relevant to the current (s, i, t)\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "        \n",
    "            # Add constraint            \n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in outgoing_waiting_arcs if arc in f_ha) <= capacity * y_i[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 5\n",
    "\n",
    "$$    f^h[\\delta^{-}\\left(i_t\\right)] \\leq y_i \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that car can only enter the built station. It includes waiting arcs (cars only car wait at the built station), and traveling arcs (cars can only park at the built station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 5\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific waiting arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_waiting_arcs if arc in f_ha) <= y_i[i])\n",
    "\n",
    "            # Next is travel arc\n",
    "\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_travel_arcs if arc in f_ha) <= y_i[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 6\n",
    "\n",
    "$$f^h\\left[\\delta^{-}\\left(i_t\\right)\\right]=f^h\\left[\\delta^{+}\\left(i_t\\right)\\right] \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad\\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "Flow conservation ensures that the route of each car must correspond to a path through the time-expanded location graph for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific incoming  arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_arcs = incoming_travel_arcs + incoming_waiting_arcs\n",
    "\n",
    "            # Given s, i, t, a specific outgoing  arc can be identified\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_arcs = outgoing_travel_arcs + outgoing_waiting_arcs\n",
    "\n",
    "            for h in H:\n",
    "                # Add constraints\n",
    "                m.addConstr(\n",
    "                    quicksum(f_ha[s, h, arc] for arc in incoming_arcs if arc in f_ha) ==\n",
    "                    quicksum(f_ha[s, h, arc] for arc in outgoing_arcs if arc in f_ha),\n",
    "                    name=f\"flow_conservation_s{s}_i{i}_t{t}_h{h}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 7 \n",
    "\n",
    "$$\\sum_{a \\in A_{T}^s(k)} f_a^h=x_k^h \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall k \\in K^s$$\n",
    "\n",
    "This equation illustrates all action of one car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 0, (18, 0), (20, 0))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[167], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m H:\n\u001b[0;32m     12\u001b[0m     relevant_arcs \u001b[38;5;241m=\u001b[39m travel_arcs_per_scenario_trip[(s, k)]\n\u001b[1;32m---> 13\u001b[0m     sum_f_ha_for_travel_arcs \u001b[38;5;241m=\u001b[39m \u001b[43mquicksum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_ha\u001b[49m\u001b[43m[\u001b[49m\u001b[43marc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrelevant_arcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     m\u001b[38;5;241m.\u001b[39maddConstr(sum_f_ha_for_travel_arcs \u001b[38;5;241m==\u001b[39m x_hk[s, h, k], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_action_one_car_s\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_h\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\gurobi.pxi:3842\u001b[0m, in \u001b[0;36mgurobipy.quicksum\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[167], line 13\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m H:\n\u001b[0;32m     12\u001b[0m     relevant_arcs \u001b[38;5;241m=\u001b[39m travel_arcs_per_scenario_trip[(s, k)]\n\u001b[1;32m---> 13\u001b[0m     sum_f_ha_for_travel_arcs \u001b[38;5;241m=\u001b[39m quicksum(\u001b[43mf_ha\u001b[49m\u001b[43m[\u001b[49m\u001b[43marc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arc \u001b[38;5;129;01min\u001b[39;00m relevant_arcs)\n\u001b[0;32m     14\u001b[0m     m\u001b[38;5;241m.\u001b[39maddConstr(sum_f_ha_for_travel_arcs \u001b[38;5;241m==\u001b[39m x_hk[s, h, k], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_action_one_car_s\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_h\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 0, (18, 0), (20, 0))"
     ]
    }
   ],
   "source": [
    "# Precompute travel arcs for each scenario and trip\n",
    "travel_arcs_per_scenario_trip = {\n",
    "    (s, k): [arc for arc in travel_arcs if arc[0] == s and arc[1] == k]\n",
    "    for s in S\n",
    "    for k in range(trips_each_scenario)\n",
    "}\n",
    "\n",
    "# Now add constraints using the precomputed arcs\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        for h in H:\n",
    "            relevant_arcs = travel_arcs_per_scenario_trip[(s, k)]\n",
    "            sum_f_ha_for_travel_arcs = quicksum(f_ha[arc] for arc in relevant_arcs)\n",
    "            m.addConstr(sum_f_ha_for_travel_arcs == x_hk[s, h, k], name=f'all_action_one_car_s{s}_h{h}_k{k}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in S:\n",
    "#     for k in range(trips_each_scenario):\n",
    "#         for h in H:\n",
    "#             # Calculate the sum of f_ha for all travel arcs for a specific scenario s, car h and trip k\n",
    "#             sum_f_ha_for_travel_arcs = quicksum(f_ha[s, k, h, arc] for arc in travel_arcs if arc in f_ha)\n",
    "#             m.addConstr(sum_f_ha_for_travel_arcs == x_hk[s, h, k], name=f'all_action_one_car_s{s}_i{i}_t{t}_h{h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 8\n",
    "\n",
    "$$ f_a^h \\leq f_{a^{\\prime}}^h \\\\\n",
    "\n",
    "\\forall h \\in\\{1,2, \\ldots, H\\}, \\forall s \\in S, \\forall k \\in K^s, \\\\\n",
    "\\forall a=\\left(i_{s_k}, j_{e_k}\\right) \\in A_{\\mathrm{T}}^s(k), \\\\\n",
    "\\forall a^{\\prime}=\\left(j_t, j_{t^{\\prime}}\\right) \\in A_{W}^s, \\\\\n",
    "t = e_k, t^{\\prime} = e_k+\\left\\lceil\\frac{b_k}{\\rho}\\right\\rceil $$\n",
    "\n",
    "This equation force each car must fully charge the battery after completing the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume fully charging time is 60 mins\n",
    "fully_charging_time = 1\n",
    "\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        \n",
    "        # Define AI_arcs considering all travel arcs for services s.\n",
    "        AT_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s ] \n",
    "        if AT_arcs:\n",
    "            for h in H:\n",
    "                \n",
    "                at_arc = AT_arcs[k]\n",
    "                st = at_arc[2][1]\n",
    "                et = at_arc[3][1]\n",
    "\n",
    "                t = et\n",
    "                t_prime = t + fully_charging_time\n",
    "\n",
    "                # Finding the corresponding AW_arcs with the updated time t_prime\n",
    "                AW_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src[1] == t and dst[1] == t_prime]\n",
    "                    \n",
    "                    \n",
    "                # Now, add the constraint for each matching arc, ensuring we use the unique arc identifiers from all_unique_arcs\n",
    "                for aw_arc in AW_arcs:\n",
    "                    if (s, h, at_arc) in f_ha and (s, h, aw_arc) in f_ha:\n",
    "                        m.addConstr(f_ha[s, h, at_arc] <= f_ha[s, h, aw_arc], f\"charging_constraint_{s}_{k}_{h}_{at_arc}_{aw_arc}\")\n",
    "                        print(f'finding the corresponding matching arc_s{s}_h{h}_k{k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Solve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (win64 - Windows 11+.0 (22631.2))\n",
      "\n",
      "CPU model: AMD Ryzen 9 7945HX with Radeon Graphics, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 16 physical cores, 32 logical processors, using up to 32 threads\n",
      "\n",
      "Optimize a model with 132 rows, 528255 columns and 325 nonzeros\n",
      "Model fingerprint: 0x6c834621\n",
      "Variable types: 0 continuous, 528255 integer (528190 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [2e+01, 2e+03]\n",
      "  Bounds range     [1e+00, 1e+01]\n",
      "  RHS range        [5e+00, 1e+03]\n",
      "Found heuristic solution: objective 185000.00000\n",
      "Presolve removed 65 rows and 528125 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 67 rows, 130 columns, 260 nonzeros\n",
      "Variable types: 0 continuous, 130 integer (65 binary)\n",
      "\n",
      "Root relaxation: cutoff, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0      185000.000 185000.000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.10 seconds (0.04 work units)\n",
      "Thread count was 32 (of 32 available processors)\n",
      "\n",
      "Solution count 1: 185000 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.850000000000e+05, best bound 1.850000000000e+05, gap 0.0000%\n",
      "Optimization was successful. Printing results.\n",
      "Build a charging station at location 8 with 1.0 cars.\n",
      "Build a charging station at location 12 with 1.0 cars.\n",
      "Build a charging station at location 48 with 1.0 cars.\n",
      "Build a charging station at location 50 with 1.0 cars.\n",
      "Build a charging station at location 61 with 1.0 cars.\n"
     ]
    }
   ],
   "source": [
    "# Solve the model\n",
    "m.optimize()\n",
    "\n",
    "# Directly check the optimization status\n",
    "if m.Status == GRB.OPTIMAL:\n",
    "    print(\"Optimization was successful. Printing results.\")\n",
    "    for i in range(n_locations):  # Ensure n_locations is correctly set\n",
    "        if y_i[i].X > 0.5:\n",
    "            print(f\"Build a charging station at location {i} with {L_i[i].X} cars.\")\n",
    "else:\n",
    "    print(f\"Optimization issue with status code: {m.Status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
