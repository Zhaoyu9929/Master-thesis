{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import gurobipy as gp\n",
    "import os \n",
    "from gurobipy import Model, GRB, quicksum\n",
    "import nbformat\n",
    "import nbimporter\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import glob\n",
    "from scipy.sparse import lil_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the trip csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>origin_ID</th>\n",
       "      <th>destination_ID</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>starting_time</th>\n",
       "      <th>ending_time</th>\n",
       "      <th>duration_time</th>\n",
       "      <th>day_type</th>\n",
       "      <th>hour</th>\n",
       "      <th>time_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>262</td>\n",
       "      <td>263</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.30</td>\n",
       "      <td>2019-06-01 00:06:31</td>\n",
       "      <td>2019-06-01 00:06:52</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.70</td>\n",
       "      <td>113</td>\n",
       "      <td>148</td>\n",
       "      <td>9.5</td>\n",
       "      <td>15.95</td>\n",
       "      <td>2019-06-01 00:03:25</td>\n",
       "      <td>2019-06-01 00:15:42</td>\n",
       "      <td>12.283333</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.60</td>\n",
       "      <td>79</td>\n",
       "      <td>125</td>\n",
       "      <td>9.5</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2019-06-01 00:28:31</td>\n",
       "      <td>2019-06-01 00:39:23</td>\n",
       "      <td>10.866667</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.60</td>\n",
       "      <td>211</td>\n",
       "      <td>148</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.30</td>\n",
       "      <td>2019-06-01 00:46:46</td>\n",
       "      <td>2019-06-01 00:50:55</td>\n",
       "      <td>4.150000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.20</td>\n",
       "      <td>79</td>\n",
       "      <td>249</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2019-06-01 00:54:49</td>\n",
       "      <td>2019-06-01 01:02:57</td>\n",
       "      <td>8.133333</td>\n",
       "      <td>weekend</td>\n",
       "      <td>0</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458387</th>\n",
       "      <td>0.90</td>\n",
       "      <td>68</td>\n",
       "      <td>158</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.80</td>\n",
       "      <td>2019-06-30 23:23:03</td>\n",
       "      <td>2019-06-30 23:39:48</td>\n",
       "      <td>16.750000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458388</th>\n",
       "      <td>0.50</td>\n",
       "      <td>246</td>\n",
       "      <td>90</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.80</td>\n",
       "      <td>2019-06-30 23:50:22</td>\n",
       "      <td>2019-06-30 23:57:01</td>\n",
       "      <td>6.650000</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458389</th>\n",
       "      <td>0.20</td>\n",
       "      <td>90</td>\n",
       "      <td>186</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.75</td>\n",
       "      <td>2019-06-30 23:58:32</td>\n",
       "      <td>2019-07-01 00:00:42</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458390</th>\n",
       "      <td>1.38</td>\n",
       "      <td>140</td>\n",
       "      <td>163</td>\n",
       "      <td>7.5</td>\n",
       "      <td>13.56</td>\n",
       "      <td>2019-06-30 23:23:10</td>\n",
       "      <td>2019-06-30 23:30:45</td>\n",
       "      <td>7.583333</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458391</th>\n",
       "      <td>1.77</td>\n",
       "      <td>142</td>\n",
       "      <td>151</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2019-06-30 23:39:13</td>\n",
       "      <td>2019-06-30 23:44:56</td>\n",
       "      <td>5.716667</td>\n",
       "      <td>weekend</td>\n",
       "      <td>23</td>\n",
       "      <td>weekend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5458392 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         trip_distance  origin_ID  destination_ID  fare_amount  total_amount  \\\n",
       "0                 0.00        262             263          2.5          6.30   \n",
       "1                 1.70        113             148          9.5         15.95   \n",
       "2                 1.60         79             125          9.5         14.30   \n",
       "3                 0.60        211             148          4.5          8.30   \n",
       "4                 1.20         79             249          7.5         12.30   \n",
       "...                ...        ...             ...          ...           ...   \n",
       "5458387           0.90         68             158         11.0         16.80   \n",
       "5458388           0.50        246              90          6.0          9.80   \n",
       "5458389           0.20         90             186          3.5          8.75   \n",
       "5458390           1.38        140             163          7.5         13.56   \n",
       "5458391           1.77        142             151          7.0         11.80   \n",
       "\n",
       "               starting_time          ending_time  duration_time day_type  \\\n",
       "0        2019-06-01 00:06:31  2019-06-01 00:06:52       0.350000  weekend   \n",
       "1        2019-06-01 00:03:25  2019-06-01 00:15:42      12.283333  weekend   \n",
       "2        2019-06-01 00:28:31  2019-06-01 00:39:23      10.866667  weekend   \n",
       "3        2019-06-01 00:46:46  2019-06-01 00:50:55       4.150000  weekend   \n",
       "4        2019-06-01 00:54:49  2019-06-01 01:02:57       8.133333  weekend   \n",
       "...                      ...                  ...            ...      ...   \n",
       "5458387  2019-06-30 23:23:03  2019-06-30 23:39:48      16.750000  weekend   \n",
       "5458388  2019-06-30 23:50:22  2019-06-30 23:57:01       6.650000  weekend   \n",
       "5458389  2019-06-30 23:58:32  2019-07-01 00:00:42       2.166667  weekend   \n",
       "5458390  2019-06-30 23:23:10  2019-06-30 23:30:45       7.583333  weekend   \n",
       "5458391  2019-06-30 23:39:13  2019-06-30 23:44:56       5.716667  weekend   \n",
       "\n",
       "         hour time_category  \n",
       "0           0       weekend  \n",
       "1           0       weekend  \n",
       "2           0       weekend  \n",
       "3           0       weekend  \n",
       "4           0       weekend  \n",
       "...       ...           ...  \n",
       "5458387    23       weekend  \n",
       "5458388    23       weekend  \n",
       "5458389    23       weekend  \n",
       "5458390    23       weekend  \n",
       "5458391    23       weekend  \n",
       "\n",
       "[5458392 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('2019-6_after_filtering.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenarios definition\n",
    "\n",
    "note that here we divide demand level into three levels: low demand ( lower than 5 trips), medium demand(6 trips to 70 trips), and high demand (larger than 70 trips). \n",
    "\n",
    "Now we can have 24 * 3939 * 3 = 283608 scenarios, and **subsequent reductions** may occur. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_df = df.groupby(['origin_ID', 'destination_ID', 'hour']).size().reset_index(name='count')\n",
    "def demand_category(x):\n",
    "    if x < 6:\n",
    "        return 'low demand'\n",
    "    elif 6 <= x <= 70:\n",
    "        return 'medium demand'\n",
    "    else:\n",
    "        return 'high demand'\n",
    "        \n",
    "\n",
    "demand_df['demand_level'] = demand_df['count'].apply(demand_category)\n",
    "demand_df = demand_df.drop(['count'], axis=1)\n",
    "\n",
    "\n",
    "existing_trips_df = df.groupby(['origin_ID', 'destination_ID']).size().reset_index(name='count')\n",
    "# Create a new list of scenario\n",
    "scenarios = []\n",
    "\n",
    "for hour in range(24):\n",
    "    for index, row in existing_trips_df.iterrows():\n",
    "        scenarios.append((hour, row['origin_ID'], row['destination_ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the speed and graph data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yanzh\\AppData\\Local\\Temp\\ipykernel_15220\\1008873551.py:21: FutureWarning: The `precision` parameter is deprecated and will be removed in the v2.0.0 release.\n",
      "  G = ox.add_edge_travel_times(G, precision=1)\n"
     ]
    }
   ],
   "source": [
    "# Import Manhattan network and change node labels to integers\n",
    "G = ox.graph_from_place('Manhattan, New York, USA', network_type='drive')\n",
    "\n",
    "# If a node cannot access at least 10% of other nodes, delete it (isolated points are not considered)\n",
    "remove_list = []\n",
    "num_nodes = len(G.nodes)\n",
    "for node in G.nodes:  \n",
    "    reach = len(nx.descendants(G, node))\n",
    "    if reach < num_nodes / 10:\n",
    "        remove_list.append(node)\n",
    "\n",
    "for node in remove_list:\n",
    "    G.remove_node(node)\n",
    "\n",
    "# The node labels of the graph are converted to integers for easier handling and reference, \n",
    "G = nx.convert_node_labels_to_integers(G, label_attribute='old_node_ID')\n",
    "G = ox.add_edge_speeds(G)\n",
    "speed_df_path = r\"C:\\Users\\yanzh\\Desktop\\Code\\archive\\nyc_avg_speeds_2019-06.csv\"\n",
    "speed_df = pd.read_csv(speed_df_path)\n",
    "speed_df = speed_df[['osm_way_id', 'hour', 'speed']]\n",
    "G = ox.add_edge_travel_times(G, precision=1)\n",
    "\n",
    "\n",
    "# Load the graphs data with speed in the file\n",
    "def load_graph_from_pkl(file_path):\n",
    "\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph\n",
    "\n",
    "# The graphs holds a list of graph objects for each hour, here is 24 hour\n",
    "graphs = load_graph_from_pkl(\"graphs_list.pkl\")\n",
    "\n",
    "# Go through the graph in each hour\n",
    "for hour in range(24):\n",
    "    for u, v, data in graphs[hour].edges(data=True):\n",
    "        travel_time_key = f'travel_time_hour_{hour}'\n",
    "\n",
    "        if travel_time_key not in data:\n",
    "           freeflow_travel_time = G[u][v][0].get('travel_time', None)\n",
    "           if freeflow_travel_time is not None:\n",
    "               graphs[hour][u][v][0][travel_time_key] = freeflow_travel_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_graph_from_pkl(file_path):\n",
    "#     with open(file_path, \"rb\") as f:\n",
    "#         graphs = pickle.load(f)\n",
    "#     return graphs\n",
    "\n",
    "# def process_graphs(graphs):\n",
    "#     # Verify if each graph is an instance of MultiGraph\n",
    "#     for hour, graph in enumerate(graphs):\n",
    "#         if isinstance(graph, nx.MultiGraph):\n",
    "#             update_graph_edges(graph, hour)\n",
    "#         else:\n",
    "#             print(f\"Graph for hour {hour} is not a MultiGraph.\")\n",
    "\n",
    "# def update_graph_edges(graph, hour):\n",
    "#     travel_time_key = f'travel_time_hour_{hour}'\n",
    "#     for u, v, key, data in graph.edges(keys=True, data=True):\n",
    "#         if travel_time_key not in data:\n",
    "#             # Safely access the travel time in a multigraph structure\n",
    "#             freeflow_travel_time = graph[u][v][key].get('travel_time', None)\n",
    "#             if freeflow_travel_time is not None:\n",
    "#                 graph[u][v][key][travel_time_key] = freeflow_travel_time\n",
    "\n",
    "# # Load and process the graphs\n",
    "# graphs = load_graph_from_pkl(\"/content/drive/MyDrive/graphs_list.pkl\")\n",
    "# process_graphs(graphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the travel time function using Dijkstra algorithm\n",
    "def travel_time_func(G_hour, point1, point2, hour):\n",
    "    # Define the weight key for the specific hour\n",
    "    weight_key = f'travel_time_hour_{hour}'\n",
    "\n",
    "    # Use Dijkstra's algorithm to find the shortest path length and path\n",
    "    # This function returns both the length of the path and the actual path as a list of nodes\n",
    "    travel_time, path = nx.single_source_dijkstra(G_hour, source=point1, target=point2, weight=weight_key)\n",
    "\n",
    "    # Round the travel time to 2 decimal places\n",
    "    travel_time = round(travel_time, 4)\n",
    "\n",
    "    return travel_time, path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of scenarios\n",
    "S = len(scenarios)\n",
    "\n",
    "# number of trips\n",
    "K = len(df)\n",
    "\n",
    "# number of poential charging staion locations\n",
    "n_locations = 65 \n",
    "\n",
    "# number of cars \n",
    "n_cars = 50\n",
    "\n",
    "# number of scenarios \n",
    "n_scenarios = 5 \n",
    "\n",
    "# fixed cost of each charging station, here we assmue 150000 dollars, but here because we only use 10000 cars, so we need reduce the cost\n",
    "station_cost = 150000\n",
    "\n",
    "# Purchasing cost of each car\n",
    "car_cost = 15000 # Here we use 15000 dollars\n",
    "\n",
    "# Income of each accepted trip\n",
    "income_per_car = 50 # assume here is 50 dollars\n",
    "\n",
    "# Capacity of each charging station, i.e. number of charging slots can be built at each charging station\n",
    "capacity = 5\n",
    "\n",
    "# p_s is a dictionary containing the profit weights for each scenario\n",
    "# Here assume equal probability for each scenario\n",
    "p_s = 1 / len(scenarios)\n",
    "# Assuming i_k is a dictionary or a function that provides income for each trip k in scenario s ?\n",
    "\n",
    "# Time periods \n",
    "T = 24\n",
    "\n",
    "# Potential location of charging station, and then number them from 0 to 64\n",
    "I = n_locations\n",
    "\n",
    "# Cars\n",
    "H = n_cars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time-expanded location graphs  G=(V, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there are Duplicate travel arcs which means some cars have same trips at the same scenario, location and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m sink \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msink\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 8\u001b[0m V0 \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      9\u001b[0m V \u001b[38;5;241m=\u001b[39m [root] \u001b[38;5;241m+\u001b[39m [(s, i, t) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m S \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m I \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m T] \u001b[38;5;241m+\u001b[39m [sink] \u001b[38;5;66;03m# Here V is described as a set of tuples, with each tuple contains two integers\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                                                      \u001b[38;5;66;03m#Plus the root and sink  \u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Waiting arcs\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# Read the csv file of coordinatate of charging station\n",
    "df_charging_station_location = pd.read_csv('coordinates of charging station.csv')\n",
    "\n",
    "# First is V, set of nodes in the graph\n",
    "root = 'root'\n",
    "sink = 'sink'\n",
    "\n",
    "V0 = [(s, i, t) for s in S for i in I for t in T]\n",
    "V = [root] + [(s, i, t) for s in S for i in I for t in T] + [sink] # Here V is described as a set of tuples, with each tuple contains two integers\n",
    "                                                     #Plus the root and sink  \n",
    "\n",
    "# Waiting arcs\n",
    "waiting_arcs = [(s, (i, t), (i, t+1)) for s in S for i in I for t in list(range(23))]\n",
    "\n",
    "# The traveling arcs \n",
    "location_id_to_index = df_charging_station_location.set_index('Location_id')['index'].to_dict()\n",
    "travel_arcs = []\n",
    "\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "\n",
    "        # Select the specific row\n",
    "        row = Ks[s].iloc[k]\n",
    "        \n",
    "        \n",
    "        # change the starting point id to index (from 0 to 65)\n",
    "        starting_point_id = row['origin_ID']\n",
    "        if starting_point_id in location_id_to_index:\n",
    "            starting_point = location_id_to_index[starting_point_id]\n",
    "\n",
    "        # Convert time to hour    \n",
    "        starting_time = row['starting_time'].hour\n",
    "        \n",
    "        # Change the destination point id to index (from 0 to 65)\n",
    "        ending_point_id = row['destination_ID']\n",
    "        if ending_point_id in location_id_to_index:\n",
    "            ending_point = location_id_to_index[ending_point_id]\n",
    "        \n",
    "        # Convert time to hour    \n",
    "        ending_time = row['ending_time'].hour\n",
    "\n",
    "        arcs = (s, k, (starting_point, starting_time), (ending_point, ending_time))\n",
    "        travel_arcs.append(arcs)\n",
    "\n",
    "\n",
    "# Initial allocation arcs\n",
    "initial_allocation_arcs = [(s, root, (i, 0)) for s in S for i in I ]\n",
    "\n",
    "final_collection_arcs = [(s, (i, 23), sink) for s in S for i in I ]\n",
    "\n",
    "# Define arcs excluding travel arcs\n",
    "arcs_exclduing_travel_arcs = waiting_arcs + initial_allocation_arcs + final_collection_arcs\n",
    "\n",
    "all_arcs = initial_allocation_arcs + waiting_arcs + travel_arcs + final_collection_arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First stage variable (Strategical layer)\n",
    "$$\n",
    "y_i=1 \\ \\text{if the charging station is built at $i$ point}, \\forall i \\in I\n",
    "$$\n",
    "$$\n",
    "L_i= \\ \\text{initial number of EVs at station i}, \\forall i \\in I\n",
    "$$\n",
    "\n",
    "Second stage variable(Operational layer)\n",
    "$$\n",
    "x_k=1 \\ \\text{if the $k$ trip is accepted}, k \\in K^s, \\forall s\\in S\n",
    "$$\n",
    "$$\n",
    "x_k^h = 1 \\ \\text{if and only if an accepted trip $k$ of scenario $s$ will be realized by purchased car $h$}\n",
    "$$\n",
    "$$\n",
    "f_a^h = 1 \\ \\text{if the car $h$ travels from station $i$ at time $t$ to station $j$ at time $t^{\\prime}$}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-04-08\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "m = Model('CSLP')\n",
    "\n",
    "# m.setParam('NodefileStart', 0.5)\n",
    "\n",
    "# First stage decision variable\n",
    "y_i = m.addVars(range(n_locations), vtype=GRB.BINARY, name='build_variable')\n",
    "L_i = m.addVars(range(n_locations), vtype=GRB.INTEGER, name='purchased_car', lb=0, ub=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios_df = pd.DataFrame(scenarios, columns=['hour', 'origin_ID', 'destination_ID'])\n",
    "\n",
    "# Merge 'df' with 'scenarios_df' to find the corresponding scenario for each trip\n",
    "merged_df = df.merge(scenarios_df, on=['hour', 'origin_ID', 'destination_ID'], how='inner')\n",
    "\n",
    "# The row indices for the sparse matrix are the index of the trips\n",
    "rows = merged_df.index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'index'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cols \u001b[38;5;241m=\u001b[39m \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m      3\u001b[0m cols\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'index'"
     ]
    }
   ],
   "source": [
    "cols = merged_df['index'].to_numpy()\n",
    "\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a matrix of zeros with the dimensions of (len(df), len(scenarios))\n",
    "x_k_matrix = np.zeros((len(df), len(scenarios)), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second stage decision variale\n",
    "indices = [(k, s) for k in K for s in S if x_k[k, s] == 1]\n",
    "x_vars = m.addVars(indices, vtype=GRB.BINARY, name='whether trip is accepted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only creat the (k, s, h) only for valid (k, s) pairs\n",
    "valid_ks = [(k, s) for k, s in indices]\n",
    "valid_ksh = [(k, s, h) for k, s in valid_ks for h in H]\n",
    "\n",
    "x_hk = m.addVars(valid_ksh, vtype=GRB.BINARY, name='trip_realized_by_car')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow variable in the second stage\n",
    "f_ha = m.addVars(range(len(all_arcs)), vtype=GRB.BINARY, name='flow') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Max\\ \\sum_{s\\in S}p_s\\sum_{k\\in K^s}{i_kx_k\\ -\\ \\sum_{i\\in I}{f_iy_i-c\\sum_{i\\in I}L_i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function: maximize profit\n",
    "m.setObjective(\n",
    "    quicksum(p_s[s] * income_per_car * quicksum(x_k[s, k] for k in range(trips_each_scenario)) for s in S) -\n",
    "    station_cost * quicksum(y_i[i] for i in range(n_locations)) -\n",
    "    car_cost * quicksum(L_i[i] for i in range(n_locations)),\n",
    "    GRB.MAXIMIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some mandatory requirments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At least 5 stations should be built\n",
    "m.addConstr(quicksum(y_i[i] for i in I) >= 5, name=\"at_least_five_stations\")\n",
    "\n",
    "# Total number of cars should be fixed as 50 cars\n",
    "m.addConstr(quicksum(L_i[i] for i in I) == 50, name='total_number_of_cars')\n",
    "\n",
    "# If the station is built in i, L_[i] should more than 0.\n",
    "for i in I:\n",
    "    m.addConstr(L_i[i] >= 1 - 1000 * (1 - y_i[i]), name=f'min_cars_if_station_{i}')\n",
    "\n",
    "# Initil capacity limitation\n",
    "for i in I:\n",
    "    m.addConstr(L_i[i] <= capacity, name=f'initial capacity limitation_{i}') \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constarints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constraint 1\n",
    "$$\\sum_{i\\in I}{f_i y_i - c\\sum_{i\\in I} L_i} \\leq W$$\n",
    "\n",
    "This is the budget constraint, $W$ is the limited budget for all costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gurobi.Constr *Awaiting Model Update*>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Budget constraints\n",
    "budget = 10000000\n",
    "m.addConstr(station_cost * quicksum(y_i[i] for i in range(n_locations)) + \n",
    "            car_cost * quicksum(L_i[i] for i in range(n_locations)) <= budget, \n",
    "            name='budge_constraint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 2\n",
    "\n",
    "$$0< t^s_k x_k \\leq T^{max}\\qquad\\forall s \\in S, k \\in K^s$$\n",
    "\n",
    "The travel time of the $k$ trip should not exceed the maximum travel time of the car due to battery limitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Battery limitation\n",
    "\n",
    "# The maximum operational time is 60 minutes\n",
    "T_max = 60 \n",
    "\n",
    "# Create a mapping from Location id to networkx point, here I create a dictionary\n",
    "location_id_to_networkx_point = df_charging_station_location.set_index('Location_id')['networkx_point'].to_dict()\n",
    "\n",
    "for s in S:\n",
    "    for k in range(K):\n",
    "\n",
    "        # Get the orgin_id value right now\n",
    "        origin_id = Ks[s]['origin_ID'].iloc[k]\n",
    "        \n",
    "\n",
    "        if origin_id in location_id_to_networkx_point:\n",
    "            origin = location_id_to_networkx_point[origin_id]\n",
    "        \n",
    "        # Get the destination_id value right now\n",
    "        destination_id = Ks[s]['destination_ID'].iloc[k]\n",
    "        \n",
    "        if destination_id in location_id_to_networkx_point:\n",
    "            destination = location_id_to_networkx_point[destination_id]\n",
    "\n",
    "        hour = Ks[s]['starting_time'].dt.hour.iloc[k]\n",
    "        G_hour = graphs[hour]\n",
    "\n",
    "        #Calculate travel time for this trip\n",
    "        travel_time, _ = travel_time_func(G_hour, origin, destination, hour)\n",
    "\n",
    "        # # Check for NaN or Inf values\n",
    "        # if np.isnan(travel_time) or np.isinf(travel_time):\n",
    "        #     print(f\"Invalid travel time detected: Scenario {s}, Trip {k}, Origin {origin}, Destination {destination}, Hour {hour}, Travel Time {travel_time}\")\n",
    "        #     continue\n",
    "\n",
    "        # Only apply the constraint if the trip is accepted\n",
    "        m.addConstr(travel_time * x_k[s, k] <= T_max, name=f\"Battery limitation_s{s}_k{k}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 3\n",
    "\n",
    "$$\\sum_{h=1}^H x_k^h = x_k, \\qquad\\forall s \\in S, k \\in K^s $$\n",
    "\n",
    "It ensures that exactly one car is assigned to each accepted trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        m.addConstr(quicksum(x_hk[s, h, k] for h in H) == x_k[s, k], name=f\"one_car_per_accepted_trip_s{s}_k{k}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrain 4\n",
    "\n",
    "$$\\sum_{h=1}^H \\sum_{a \\in \\delta^{+}\\left(i_t\\right) \\cap\\left(A_W^s \\cup A_C^s\\right)} f_a^h \\leq C_i y_i \\qquad \\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that the quantity of vehicles concurrently parked at station $i$ does not surpass the available number of charging slots at said station.\n",
    "Observe that final collection arcs need to be considered on the left-hand side to ensure that the capacity constraints are also met at the end of the planning period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capacity constraints\n",
    "\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        # Directly handling the final collection arcs to 'sink' \n",
    "        final_arc_key = (s, (i, 23), 'sink')\n",
    "        m.addConstr(quicksum(f_ha[s, h, final_arc_key] for h in H if final_arc_key in f_ha) <= capacity * y_i[i], name=f'final_capacity_s{s}_i{i}')\n",
    "        \n",
    "        for t in T:         \n",
    "            # Filter and append arcs relevant to the current (s, i, t)\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "        \n",
    "            # Add constraint            \n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in outgoing_waiting_arcs if arc in f_ha) <= capacity * y_i[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints 5\n",
    "\n",
    "$$    f^h[\\delta^{-}\\left(i_t\\right)] \\leq y_i \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "It ensures that car can only enter the built station. It includes waiting arcs (cars only car wait at the built station), and traveling arcs (cars can only park at the built station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 5\n",
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific waiting arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_waiting_arcs if arc in f_ha) <= y_i[i])\n",
    "\n",
    "            # Next is travel arc\n",
    "\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "\n",
    "            # Add the constraint\n",
    "            m.addConstr(quicksum(f_ha[s, h, arc] for h in H for arc in incoming_travel_arcs if arc in f_ha) <= y_i[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 6\n",
    "\n",
    "$$f^h\\left[\\delta^{-}\\left(i_t\\right)\\right]=f^h\\left[\\delta^{+}\\left(i_t\\right)\\right] \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad\\forall s \\in S, \\quad\\forall i_t \\in V^s \\backslash\\left\\{r^s, s^s\\right\\}$$\n",
    "\n",
    "Flow conservation ensures that the route of each car must correspond to a path through the time-expanded location graph for each scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in S:\n",
    "    for i in I:\n",
    "        for t in T:\n",
    "            \n",
    "            # Given s, i, t, a specific incoming  arc can be identified\n",
    "            incoming_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and dst == (i, t)]\n",
    "            incoming_arcs = incoming_travel_arcs + incoming_waiting_arcs\n",
    "\n",
    "            # Given s, i, t, a specific outgoing  arc can be identified\n",
    "            outgoing_waiting_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_travel_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s and src == (i, t)]\n",
    "            outgoing_arcs = outgoing_travel_arcs + outgoing_waiting_arcs\n",
    "\n",
    "            for h in H:\n",
    "                # Add constraints\n",
    "                m.addConstr(\n",
    "                    quicksum(f_ha[s, h, arc] for arc in incoming_arcs if arc in f_ha) ==\n",
    "                    quicksum(f_ha[s, h, arc] for arc in outgoing_arcs if arc in f_ha),\n",
    "                    name=f\"flow_conservation_s{s}_i{i}_t{t}_h{h}\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 7 \n",
    "\n",
    "$$\\sum_{a \\in A_{T}^s(k)} f_a^h=x_k^h \\quad \\forall h \\in\\{1,2, \\ldots, H\\}, \\quad \\forall s \\in S, \\quad \\forall k \\in K^s$$\n",
    "\n",
    "This equation illustrates all action of one car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "(0, 0, (18, 0), (20, 0))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[167], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m H:\n\u001b[0;32m     12\u001b[0m     relevant_arcs \u001b[38;5;241m=\u001b[39m travel_arcs_per_scenario_trip[(s, k)]\n\u001b[1;32m---> 13\u001b[0m     sum_f_ha_for_travel_arcs \u001b[38;5;241m=\u001b[39m \u001b[43mquicksum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_ha\u001b[49m\u001b[43m[\u001b[49m\u001b[43marc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrelevant_arcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     m\u001b[38;5;241m.\u001b[39maddConstr(sum_f_ha_for_travel_arcs \u001b[38;5;241m==\u001b[39m x_hk[s, h, k], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_action_one_car_s\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_h\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\gurobi.pxi:3842\u001b[0m, in \u001b[0;36mgurobipy.quicksum\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[167], line 13\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m H:\n\u001b[0;32m     12\u001b[0m     relevant_arcs \u001b[38;5;241m=\u001b[39m travel_arcs_per_scenario_trip[(s, k)]\n\u001b[1;32m---> 13\u001b[0m     sum_f_ha_for_travel_arcs \u001b[38;5;241m=\u001b[39m quicksum(\u001b[43mf_ha\u001b[49m\u001b[43m[\u001b[49m\u001b[43marc\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arc \u001b[38;5;129;01min\u001b[39;00m relevant_arcs)\n\u001b[0;32m     14\u001b[0m     m\u001b[38;5;241m.\u001b[39maddConstr(sum_f_ha_for_travel_arcs \u001b[38;5;241m==\u001b[39m x_hk[s, h, k], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_action_one_car_s\u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_h\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_k\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: (0, 0, (18, 0), (20, 0))"
     ]
    }
   ],
   "source": [
    "# Precompute travel arcs for each scenario and trip\n",
    "travel_arcs_per_scenario_trip = {\n",
    "    (s, k): [arc for arc in travel_arcs if arc[0] == s and arc[1] == k]\n",
    "    for s in S\n",
    "    for k in range(trips_each_scenario)\n",
    "}\n",
    "\n",
    "# Now add constraints using the precomputed arcs\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        for h in H:\n",
    "            relevant_arcs = travel_arcs_per_scenario_trip[(s, k)]\n",
    "            sum_f_ha_for_travel_arcs = quicksum(f_ha[arc] for arc in relevant_arcs)\n",
    "            m.addConstr(sum_f_ha_for_travel_arcs == x_hk[s, h, k], name=f'all_action_one_car_s{s}_h{h}_k{k}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in S:\n",
    "#     for k in range(trips_each_scenario):\n",
    "#         for h in H:\n",
    "#             # Calculate the sum of f_ha for all travel arcs for a specific scenario s, car h and trip k\n",
    "#             sum_f_ha_for_travel_arcs = quicksum(f_ha[s, k, h, arc] for arc in travel_arcs if arc in f_ha)\n",
    "#             m.addConstr(sum_f_ha_for_travel_arcs == x_hk[s, h, k], name=f'all_action_one_car_s{s}_i{i}_t{t}_h{h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraint 8\n",
    "\n",
    "$$ f_a^h \\leq f_{a^{\\prime}}^h \\\\\n",
    "\n",
    "\\forall h \\in\\{1,2, \\ldots, H\\}, \\forall s \\in S, \\forall k \\in K^s, \\\\\n",
    "\\forall a=\\left(i_{s_k}, j_{e_k}\\right) \\in A_{\\mathrm{T}}^s(k), \\\\\n",
    "\\forall a^{\\prime}=\\left(j_t, j_{t^{\\prime}}\\right) \\in A_{W}^s, \\\\\n",
    "t = e_k, t^{\\prime} = e_k+\\left\\lceil\\frac{b_k}{\\rho}\\right\\rceil $$\n",
    "\n",
    "This equation force each car must fully charge the battery after completing the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume fully charging time is 60 mins\n",
    "fully_charging_time = 1\n",
    "\n",
    "for s in S:\n",
    "    for k in range(trips_each_scenario):\n",
    "        \n",
    "        # Define AI_arcs considering all travel arcs for services s.\n",
    "        AT_arcs = [(s_arc, k, src, dst) for s_arc, k, src, dst in travel_arcs if s_arc == s ] \n",
    "        if AT_arcs:\n",
    "            for h in H:\n",
    "                \n",
    "                at_arc = AT_arcs[k]\n",
    "                st = at_arc[2][1]\n",
    "                et = at_arc[3][1]\n",
    "\n",
    "                t = et\n",
    "                t_prime = t + fully_charging_time\n",
    "\n",
    "                # Finding the corresponding AW_arcs with the updated time t_prime\n",
    "                AW_arcs = [(s_arc, src, dst) for s_arc, src, dst in waiting_arcs if s_arc == s and src[1] == t and dst[1] == t_prime]\n",
    "                    \n",
    "                    \n",
    "                # Now, add the constraint for each matching arc, ensuring we use the unique arc identifiers from all_unique_arcs\n",
    "                for aw_arc in AW_arcs:\n",
    "                    if (s, h, at_arc) in f_ha and (s, h, aw_arc) in f_ha:\n",
    "                        m.addConstr(f_ha[s, h, at_arc] <= f_ha[s, h, aw_arc], f\"charging_constraint_{s}_{k}_{h}_{at_arc}_{aw_arc}\")\n",
    "                        print(f'finding the corresponding matching arc_s{s}_h{h}_k{k}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Solve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 11.0.0 build v11.0.0rc2 (win64 - Windows 11+.0 (22631.2))\n",
      "\n",
      "CPU model: AMD Ryzen 9 7945HX with Radeon Graphics, instruction set [SSE2|AVX|AVX2|AVX512]\n",
      "Thread count: 16 physical cores, 32 logical processors, using up to 32 threads\n",
      "\n",
      "Optimize a model with 132 rows, 528255 columns and 325 nonzeros\n",
      "Model fingerprint: 0x6c834621\n",
      "Variable types: 0 continuous, 528255 integer (528190 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+03]\n",
      "  Objective range  [2e+01, 2e+03]\n",
      "  Bounds range     [1e+00, 1e+01]\n",
      "  RHS range        [5e+00, 1e+03]\n",
      "Found heuristic solution: objective 185000.00000\n",
      "Presolve removed 65 rows and 528125 columns\n",
      "Presolve time: 0.03s\n",
      "Presolved: 67 rows, 130 columns, 260 nonzeros\n",
      "Variable types: 0 continuous, 130 integer (65 binary)\n",
      "\n",
      "Root relaxation: cutoff, 2 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0     cutoff    0      185000.000 185000.000  0.00%     -    0s\n",
      "\n",
      "Explored 1 nodes (2 simplex iterations) in 0.10 seconds (0.04 work units)\n",
      "Thread count was 32 (of 32 available processors)\n",
      "\n",
      "Solution count 1: 185000 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.850000000000e+05, best bound 1.850000000000e+05, gap 0.0000%\n",
      "Optimization was successful. Printing results.\n",
      "Build a charging station at location 8 with 1.0 cars.\n",
      "Build a charging station at location 12 with 1.0 cars.\n",
      "Build a charging station at location 48 with 1.0 cars.\n",
      "Build a charging station at location 50 with 1.0 cars.\n",
      "Build a charging station at location 61 with 1.0 cars.\n"
     ]
    }
   ],
   "source": [
    "# Solve the model\n",
    "m.optimize()\n",
    "\n",
    "# Directly check the optimization status\n",
    "if m.Status == GRB.OPTIMAL:\n",
    "    print(\"Optimization was successful. Printing results.\")\n",
    "    for i in range(n_locations):  # Ensure n_locations is correctly set\n",
    "        if y_i[i].X > 0.5:\n",
    "            print(f\"Build a charging station at location {i} with {L_i[i].X} cars.\")\n",
    "else:\n",
    "    print(f\"Optimization issue with status code: {m.Status}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
